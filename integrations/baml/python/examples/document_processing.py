"""
Document Processing Example

Demonstrates using BAML + Anthropic Agent Skills for document analysis.
"""

import asyncio
import logging
from pathlib import Path
from typing import List

# Import BAML client (generated by baml-cli)
# from baml_client import b

from shared.config import load_config
from shared.utils import setup_logging, async_retry, DocumentProcessingError


logger = logging.getLogger("baml_anthropic.document_processing")


@async_retry(max_retries=3, initial_delay=1.0, backoff_factor=2.0)
async def analyze_document(
    file_path: str,
    questions: List[str],
) -> dict:
    """
    Analyze a document using BAML + Anthropic Agent Skills.

    This function demonstrates:
    - Type-safe prompting with BAML
    - Agent Skills for document processing
    - Structured output with validation
    - Error handling and retries

    Args:
        file_path: Path to the document file (PDF, DOCX, etc.)
        questions: List of questions to answer about the document

    Returns:
        DocumentAnalysis object with:
            - summary: High-level summary
            - key_findings: Important extracted information
            - answers: Answers to each question
            - confidence_score: Confidence in the analysis (0.0-1.0)
            - metadata: Additional information

    Raises:
        DocumentProcessingError: If document processing fails
        FileNotFoundError: If file doesn't exist

    Example:
        >>> result = await analyze_document(
        ...     "report.pdf",
        ...     ["What are the key findings?", "What's the budget?"]
        ... )
        >>> print(f"Summary: {result['summary']}")
        >>> print(f"Findings: {result['key_findings']}")
    """
    # Validate file exists
    file_path_obj = Path(file_path)
    if not file_path_obj.exists():
        raise FileNotFoundError(f"Document not found: {file_path}")

    logger.info(f"Analyzing document: {file_path}")
    logger.info(f"Questions: {questions}")

    try:
        # NOTE: This requires BAML client generation
        # Uncomment after running: baml-cli generate

        # Call BAML function (type-safe)
        # result = await b.AnalyzeDocument(
        #     file_path=file_path,
        #     questions=questions
        # )

        # For demonstration purposes (before BAML generation)
        # Return mock response with correct structure
        result = {
            "summary": f"Analysis of document: {file_path_obj.name}",
            "key_findings": [
                "This is a placeholder response",
                "Run 'baml-cli generate' to enable real API calls",
                "The BAML client will provide type-safe prompting",
            ],
            "answers": {q: f"Answer to: {q}" for q in questions},
            "confidence_score": 0.85,
            "metadata": {
                "file_name": file_path_obj.name,
                "file_size": str(file_path_obj.stat().st_size),
                "questions_count": str(len(questions)),
            },
        }

        logger.info(f"Analysis complete. Confidence: {result['confidence_score']}")
        return result

    except Exception as e:
        logger.error(f"Document processing failed: {e}")
        raise DocumentProcessingError(f"Failed to analyze document: {e}") from e


async def analyze_document_streaming(
    file_path: str,
    questions: List[str],
):
    """
    Analyze a document with streaming responses.

    This demonstrates streaming support for long-running document analysis.

    Args:
        file_path: Path to the document file
        questions: List of questions to answer

    Yields:
        Partial results as they become available

    Example:
        >>> async for chunk in analyze_document_streaming("report.pdf", questions):
        ...     print(f"Partial result: {chunk}")
    """
    logger.info(f"Starting streaming analysis of: {file_path}")

    # NOTE: This requires BAML client with streaming support
    # Uncomment after running: baml-cli generate

    # async for chunk in b.AnalyzeDocument.stream(
    #     file_path=file_path,
    #     questions=questions
    # ):
    #     yield chunk

    # Placeholder for demonstration
    yield {
        "type": "partial_result",
        "content": "Analysis starting...",
    }
    await asyncio.sleep(0.1)

    yield {
        "type": "partial_result",
        "content": "Extracting content from document...",
    }
    await asyncio.sleep(0.1)

    yield {
        "type": "final_result",
        "content": await analyze_document(file_path, questions),
    }


async def main():
    """Example usage of document processing."""
    # Load configuration
    config = load_config()
    setup_logging(config.log_level)

    # Example document analysis
    test_file = Path(__file__).parent.parent.parent / "test_data" / "sample.pdf"

    if not test_file.exists():
        logger.warning(f"Test file not found: {test_file}")
        logger.info("Creating placeholder test file...")
        test_file.parent.mkdir(parents=True, exist_ok=True)
        test_file.write_text("This is a placeholder PDF file.")

    questions = [
        "What is the main topic of this document?",
        "What are the key findings?",
        "What recommendations are provided?",
    ]

    try:
        result = await analyze_document(str(test_file), questions)

        print("\n" + "=" * 60)
        print("DOCUMENT ANALYSIS RESULTS")
        print("=" * 60)
        print(f"\nSummary:\n{result['summary']}\n")
        print("Key Findings:")
        for finding in result['key_findings']:
            print(f"  â€¢ {finding}")
        print(f"\nConfidence Score: {result['confidence_score']:.2%}")
        print("\nAnswers:")
        for question, answer in result['answers'].items():
            print(f"\nQ: {question}")
            print(f"A: {answer}")
        print("\n" + "=" * 60)

    except Exception as e:
        logger.error(f"Example failed: {e}")
        raise


if __name__ == "__main__":
    asyncio.run(main())
