"""
Dual-Provider Example

Demonstrates using both Anthropic (Claude) and OpenAI (GPT-4o-mini) together
with BAML for optimal cost/quality tradeoffs.

Key Concepts:
- Use Claude for complex tasks requiring Agent Skills
- Use OpenAI for simple, cost-effective tasks
- Choose provider based on task complexity
"""

import asyncio
import logging
from typing import List

# Import BAML client (generated by baml-cli)
# from baml_client import b

from shared.config import load_config
from shared.utils import setup_logging

logger = logging.getLogger("baml_anthropic.dual_provider")


async def cost_comparison_demo():
    """
    Demonstrate cost differences between providers.

    This shows real-world cost calculations for different tasks.
    """
    logger.info("=== Cost Comparison Demo ===")

    # Example task: Summarize 10K tokens of text
    example_tokens = 10000

    # Claude 3.5 Sonnet pricing
    claude_input_cost = (example_tokens / 1_000_000) * 3.00
    claude_output_cost = (2000 / 1_000_000) * 15.00  # Assume 2K output
    claude_total = claude_input_cost + claude_output_cost

    # GPT-4o-mini pricing
    openai_input_cost = (example_tokens / 1_000_000) * 0.15
    openai_output_cost = (2000 / 1_000_000) * 0.60
    openai_total = openai_input_cost + openai_output_cost

    logger.info(f"Task: Summarize 10K tokens → 2K tokens")
    logger.info(f"Claude cost: ${claude_total:.4f}")
    logger.info(f"OpenAI cost: ${openai_total:.4f}")
    logger.info(f"Savings: ${claude_total - openai_total:.4f} ({((claude_total - openai_total) / claude_total * 100):.1f}%)")


async def generate_summary_example():
    """
    Example: Use OpenAI for simple summarization (cost-effective).

    Perfect for:
    - Blog post summaries
    - Email condensation
    - Quick content digests
    """
    logger.info("=== Generate Summary (OpenAI) ===")

    sample_text = """
    Artificial intelligence has made remarkable progress in recent years.
    Large language models like GPT-4 and Claude can now understand context,
    generate coherent text, and even write code. However, challenges remain
    in areas like reasoning, factual accuracy, and handling ambiguity.
    Researchers continue to explore new architectures and training methods
    to address these limitations.
    """

    try:
        # NOTE: Requires BAML generation with OpenAI client configured
        # Uncomment after running: baml-cli generate

        # result = await b.GenerateSummary(
        #     text=sample_text,
        #     max_sentences=2
        # )

        # Placeholder response
        result = {
            "summary": "AI has advanced significantly with models like GPT-4 and Claude. "
                      "Challenges remain in reasoning and accuracy that researchers are addressing.",
            "sentence_count": 2,
            "key_points": [
                "AI progress in recent years",
                "Challenges in reasoning and accuracy"
            ],
            "compression_ratio": 0.25
        }

        logger.info(f"Summary: {result['summary']}")
        logger.info(f"Compression: {result['compression_ratio']:.0%}")
        logger.info(f"Provider: OpenAI (cost-effective)")

        return result

    except Exception as e:
        logger.error(f"Summarization failed: {e}")
        raise


async def document_analysis_example():
    """
    Example: Use Claude for complex document analysis (Agent Skills).

    Perfect for:
    - PDF extraction
    - DOCX parsing
    - Structured document analysis
    """
    logger.info("=== Document Analysis (Claude + Agent Skills) ===")

    try:
        # NOTE: Requires BAML generation
        # Uncomment after running: baml-cli generate

        # result = await b.AnalyzeDocument(
        #     file_path="report.pdf",
        #     questions=["What are the key findings?", "What's the budget?"]
        # )

        # Placeholder response
        result = {
            "summary": "Q4 financial report with budget analysis",
            "key_findings": [
                "Revenue increased 15% YoY",
                "Operating expenses decreased 8%"
            ],
            "answers": {
                "What are the key findings?": "Strong revenue growth with cost reduction",
                "What's the budget?": "$2.5M for Q1 2025"
            },
            "confidence_score": 0.92
        }

        logger.info(f"Document: report.pdf")
        logger.info(f"Findings: {result['key_findings']}")
        logger.info(f"Provider: Claude (Agent Skills for PDF processing)")

        return result

    except Exception as e:
        logger.error(f"Document analysis failed: {e}")
        raise


async def smart_provider_selection():
    """
    Demonstrate intelligent provider selection based on task complexity.

    Strategy:
    - Simple tasks → OpenAI (save money)
    - Complex tasks → Claude (better quality + Agent Skills)
    """
    logger.info("=== Smart Provider Selection ===")

    tasks = [
        {
            "description": "Summarize this article",
            "complexity": "simple",
            "recommended_provider": "OpenAI",
            "reason": "Basic text generation, no special skills needed"
        },
        {
            "description": "Extract data from this PDF invoice",
            "complexity": "complex",
            "recommended_provider": "Claude",
            "reason": "Requires PDF processing Agent Skill"
        },
        {
            "description": "Classify this email as spam or not",
            "complexity": "simple",
            "recommended_provider": "OpenAI",
            "reason": "Simple classification, high-volume task"
        },
        {
            "description": "Analyze this legal contract for compliance issues",
            "complexity": "complex",
            "recommended_provider": "Claude",
            "reason": "Complex reasoning, document understanding"
        }
    ]

    for task in tasks:
        logger.info(f"\nTask: {task['description']}")
        logger.info(f"Complexity: {task['complexity']}")
        logger.info(f"Recommended: {task['recommended_provider']}")
        logger.info(f"Reason: {task['reason']}")


async def batch_processing_example():
    """
    Example: Process 1000 items with cost-effective provider.

    Scenario: You have 1000 customer reviews to classify.

    Cost comparison:
    - Claude: ~$30 ($0.03 per review)
    - OpenAI: ~$1.50 ($0.0015 per review)
    - Savings: $28.50 (95% cheaper!)
    """
    logger.info("=== Batch Processing (High-Volume) ===")

    num_reviews = 1000
    avg_tokens_per_review = 100

    # Cost calculation
    total_tokens = num_reviews * avg_tokens_per_review

    claude_cost = (total_tokens / 1_000_000) * 3.00 + \
                  (total_tokens / 1_000_000) * 15.00  # Input + output

    openai_cost = (total_tokens / 1_000_000) * 0.15 + \
                  (total_tokens / 1_000_000) * 0.60

    logger.info(f"Processing {num_reviews} customer reviews")
    logger.info(f"Total tokens: {total_tokens:,}")
    logger.info(f"Claude cost: ${claude_cost:.2f}")
    logger.info(f"OpenAI cost: ${openai_cost:.2f}")
    logger.info(f"Savings: ${claude_cost - openai_cost:.2f}")
    logger.info(f"Recommendation: Use OpenAI for 95% cost reduction")


async def main():
    """
    Run all dual-provider examples.
    """
    # Setup
    setup_logging()
    load_config()

    print("\n" + "="*70)
    print("BAML DUAL-PROVIDER INTEGRATION EXAMPLES")
    print("="*70 + "\n")

    # Run examples
    await cost_comparison_demo()
    print("\n" + "-"*70 + "\n")

    await generate_summary_example()
    print("\n" + "-"*70 + "\n")

    await document_analysis_example()
    print("\n" + "-"*70 + "\n")

    await smart_provider_selection()
    print("\n" + "-"*70 + "\n")

    await batch_processing_example()

    print("\n" + "="*70)
    print("KEY TAKEAWAYS")
    print("="*70)
    print("✓ Use OpenAI for simple, high-volume tasks (95% cost savings)")
    print("✓ Use Claude for complex tasks requiring Agent Skills")
    print("✓ Same BAML code works with both providers")
    print("✓ Choose provider per-function based on requirements")
    print("="*70 + "\n")


if __name__ == "__main__":
    asyncio.run(main())
