<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Technical FAQ | Context Foundry Documentation</title>
  <meta name="description" content="For Software Developers, Architects, and AI Engineers">

  <!-- Open Graph -->
  <meta property="og:type" content="article">
  <meta property="og:url" content="https://contextfoundry.dev/docs/reference/technical-faq">
  <meta property="og:title" content="Technical FAQ">
  <meta property="og:description" content="For Software Developers, Architects, and AI Engineers">
  <meta property="og:image" content="https://contextfoundry.dev/images/banner-1280x320-dark.png">

  <!-- Twitter Card -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="Technical FAQ">
  <meta name="twitter:description" content="For Software Developers, Architects, and AI Engineers">
  <meta name="twitter:image" content="https://contextfoundry.dev/images/banner-1280x320-dark.png">

  <!-- Canonical URL -->
  <link rel="canonical" href="https://contextfoundry.dev/docs/reference/technical-faq">

  <!-- Stylesheets -->
  <link rel="stylesheet" href="/css/reset.css">
  <link rel="stylesheet" href="/css/variables.css">
  <link rel="stylesheet" href="/css/styles.css">
  <link rel="stylesheet" href="/docs/assets/docs.css">

  <!-- Prism.js theme for syntax highlighting -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@1/themes/prism-tomorrow.min.css">

  <!-- Dark mode support -->
  <meta name="color-scheme" content="light dark">
</head>
<body class="docs-page">

  <header class="docs-header" role="banner">
    <div class="docs-header-container">
  
      <!-- Logo and Site Title -->
      <div class="docs-header-logo">
        <a href="/docs/" class="docs-logo-link" aria-label="Context Foundry Documentation Home">
          <svg class="docs-logo-icon" width="32" height="32" viewBox="0 0 32 32" fill="none" xmlns="http://www.w3.org/2000/svg" aria-hidden="true">
            <rect width="32" height="32" rx="6" fill="currentColor"/>
            <path d="M8 16L14 10L20 16L14 22L8 16Z" fill="white"/>
            <path d="M14 10L20 16L24 12L18 6L14 10Z" fill="white" opacity="0.7"/>
          </svg>
          <span class="docs-logo-text">Context Foundry</span>
        </a>
      </div>
  
      <!-- Main Navigation -->
      <nav class="docs-header-nav" role="navigation" aria-label="Main navigation">
        <ul class="docs-nav-list">
          <li class="docs-nav-item">
            <a href="/" class="docs-nav-link">Home</a>
          </li>
          <li class="docs-nav-item">
            <a href="/docs/getting-started/" class="docs-nav-link">Getting Started</a>
          </li>
          <li class="docs-nav-item">
            <a href="/docs/guides/" class="docs-nav-link">Guides</a>
          </li>
          <li class="docs-nav-item">
            <a href="/docs/technical/" class="docs-nav-link">Technical</a>
          </li>
          <li class="docs-nav-item">
            <a href="/docs/reference/" class="docs-nav-link">Reference</a>
          </li>
        </ul>
      </nav>
  
      <!-- Search and Actions -->
      <div class="docs-header-actions">
  
        <!-- Search Input -->
        <div class="docs-search-container">
          <label for="search-input" class="visually-hidden">Search documentation</label>
          <input
            type="search"
            id="search-input"
            class="docs-search-input"
            placeholder="Search docs..."
            aria-label="Search documentation"
            autocomplete="off"
          />
          <kbd class="docs-search-hint" aria-hidden="true">⌘K</kbd>
  
          <!-- Search Results Dropdown -->
          <div id="search-results" class="docs-search-results" role="listbox" aria-label="Search results"></div>
        </div>
  
        <!-- Dark Mode Toggle -->
        <button
          type="button"
          class="docs-theme-toggle"
          id="theme-toggle"
          aria-label="Toggle dark mode"
          title="Toggle dark mode"
        >
          <svg class="docs-theme-icon docs-theme-icon-light" width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg" aria-hidden="true">
            <circle cx="10" cy="10" r="4" stroke="currentColor" stroke-width="2"/>
            <path d="M10 2V4M10 16V18M18 10H16M4 10H2M15.66 4.34L14.24 5.76M5.76 14.24L4.34 15.66M15.66 15.66L14.24 14.24M5.76 5.76L4.34 4.34" stroke="currentColor" stroke-width="2" stroke-linecap="round"/>
          </svg>
          <svg class="docs-theme-icon docs-theme-icon-dark" width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg" aria-hidden="true">
            <path d="M17 10.5C16 14.5 12.5 17 9 17C5.5 17 2 14.5 2 10C2 5.5 5.5 3 9 3C9.5 3 10 3 10.5 3.5C8.5 4.5 7 6.5 7 9C7 12 9.5 14.5 12.5 14.5C14 14.5 15.5 14 16.5 13C16.8 13.8 17 14.4 17 15V10.5Z" fill="currentColor"/>
          </svg>
        </button>
  
        <!-- Mobile Menu Toggle -->
        <button
          type="button"
          class="mobile-menu-toggle"
          id="mobile-menu-toggle"
          aria-expanded="false"
          aria-controls="docs-sidebar"
          aria-label="Toggle navigation menu"
        >
          <svg class="mobile-menu-icon" width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" aria-hidden="true">
            <path d="M3 6H21M3 12H21M3 18H21" stroke="currentColor" stroke-width="2" stroke-linecap="round"/>
          </svg>
        </button>
  
      </div>
  
    </div>
  </header>

  <div class="docs-layout">

    <!-- Sidebar Navigation -->
    <aside class="docs-sidebar" id="docs-sidebar" role="navigation" aria-label="Documentation navigation">
      <nav class="sidebar-nav" aria-label="Documentation sidebar">
      
          <div class="sidebar-category" data-category="">
      
            <!-- Category Header -->
            <button
              type="button"
              class="sidebar-category-toggle"
              aria-expanded="true"
              aria-controls="sidebar-category-"
            >
              <svg class="sidebar-category-icon" width="16" height="16" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg" aria-hidden="true">
                <path d="M6 4L10 8L6 12" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
              </svg>
              <h2 class="sidebar-category-title"></h2>
            </button>
      
            <!-- Category Links -->
            <ul class="sidebar-category-list" id="sidebar-category-">
            </ul>
      
          </div>
          <div class="sidebar-category" data-category="">
      
            <!-- Category Header -->
            <button
              type="button"
              class="sidebar-category-toggle"
              aria-expanded="true"
              aria-controls="sidebar-category-"
            >
              <svg class="sidebar-category-icon" width="16" height="16" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg" aria-hidden="true">
                <path d="M6 4L10 8L6 12" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
              </svg>
              <h2 class="sidebar-category-title"></h2>
            </button>
      
            <!-- Category Links -->
            <ul class="sidebar-category-list" id="sidebar-category-">
            </ul>
      
          </div>
      
      </nav>
    </aside>

    <!-- Main Content -->
    <main class="docs-content" role="main">

      <!-- Breadcrumbs -->
      <nav class="breadcrumbs" aria-label="Breadcrumb">
        <ol class="breadcrumbs-list" itemscope itemtype="https://schema.org/BreadcrumbList">
            <li class="breadcrumbs-item" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
                <a href="/docs" class="breadcrumbs-link" itemprop="item">
                  <span itemprop="name"></span>
                </a>
              <meta itemprop="position" content="0" />
            </li>
            <li class="breadcrumbs-item" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
                <a href="/docs/reference" class="breadcrumbs-link" itemprop="item">
                  <span itemprop="name"></span>
                </a>
              <meta itemprop="position" content="1" />
            </li>
            <li class="breadcrumbs-item" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
                <span class="breadcrumbs-current" itemprop="name" aria-current="page"></span>
              <meta itemprop="position" content="2" />
            </li>
        </ol>
      </nav>

      <!-- Document Content -->
      <article class="doc-article">
        <h1 class="doc-title">Technical FAQ</h1>

        <div class="doc-body">
          <h1 id="context-foundry-technical-faq">Context Foundry Technical FAQ</h1>
<p><strong>For Software Developers, Architects, and AI Engineers</strong></p>
<blockquote><p>Last Updated: 2025-01-23<br>Audience: Technical users familiar with distributed systems, AI agents, and software architecture</p>
</blockquote>
<blockquote><p><strong>Looking for user-friendly answers?</strong> If you&#39;re new to Context Foundry or want quick, accessible answers about how it works, see the <strong><a href="../FAQ.md">Main FAQ</a></strong> which focuses on transparency and demystifying the system.</p>
</blockquote>
<hr>
<h2 id="table-of-contents">Table of Contents</h2>
<ol>
<li><a href="#1-file-management--architecture">File Management &amp; Architecture</a></li>
<li><a href="#2-the-secret-sauce---prompt-engineering">The &quot;Secret Sauce&quot; - Prompt Engineering</a></li>
<li><a href="#3-agent-architecture--lifecycle">Agent Architecture &amp; Lifecycle</a></li>
<li><a href="#4-token-management--context-windows">Token Management &amp; Context Windows</a></li>
<li><a href="#5-parallelization--coordination">Parallelization &amp; Coordination</a></li>
<li><a href="#6-authentication--api-usage">Authentication &amp; API Usage</a></li>
<li><a href="#7-mcp-server-architecture--context-management">MCP Server Architecture &amp; Context Management</a></li>
<li><a href="#8-performance--scaling">Performance &amp; Scaling</a></li>
<li><a href="#9-error-handling--self-healing">Error Handling &amp; Self-Healing</a></li>
<li><a href="#10-pattern-learning-system">Pattern Learning System</a></li>
<li><a href="#11-advanced-technical-topics">Advanced Technical Topics</a></li>
<li><a href="#12-practical-usage--limitations">Practical Usage &amp; Limitations</a></li>
<li><a href="#13-comparisons--philosophy">Comparisons &amp; Philosophy</a></li>
</ol>
<hr>
<h2 id="1-file-management-architecture">1. File Management &amp; Architecture</h2>
<h3 id="q1-where-are-the-context-foundry-files-stored">Q1: Where are the <code>.context-foundry/</code> files stored?</h3>
<p><strong>A:</strong> In the <strong>project directory</strong>, not in the Context Foundry installation directory.</p>
<pre><code class="">your-project/
├── .context-foundry/          # Created in YOUR project
│   ├── scout-report.md
│   ├── architecture.md
│   ├── build-log.md
│   ├── build-tasks.json
│   ├── current-phase.json
│   ├── builder-logs/
│   └── test-logs/
├── src/                       # Your source code
└── package.json</code></pre>
<p><strong>Why this matters:</strong></p>
<ul>
<li>Each project has its own <code>.context-foundry/</code> directory</li>
<li>Files persist across builds (useful for debugging)</li>
<li>Can be version controlled (add to <code>.gitignore</code> if preferred)</li>
<li>No interference between different projects</li>
</ul>
<p><strong>Global patterns</strong> are stored separately at <code>~/.context-foundry/patterns/</code> for cross-project learning.</p>
<hr>
<h3 id="q2-why-md-files-instead-of-json-for-core-architecture">Q2: Why <code>.md</code> files instead of JSON for core architecture?</h3>
<p><strong>A:</strong> Markdown files are the <strong>backbone of Context Foundry</strong> for several critical reasons:</p>
<p><strong>1. Agent-Friendly Format</strong></p>
<ul>
<li>LLMs like Claude are trained heavily on markdown documentation</li>
<li>Natural language + structure = better comprehension</li>
<li>Code blocks with syntax highlighting improve parsing</li>
</ul>
<p><strong>2. Human-Readable</strong></p>
<ul>
<li>Developers can read <code>scout-report.md</code> to understand what the Scout discovered</li>
<li>Architects can review <code>architecture.md</code> to verify the design</li>
<li>No need to parse JSON to understand build decisions</li>
</ul>
<p><strong>3. Git-Diffable</strong></p>
<ul>
<li>Meaningful diffs when architecture changes</li>
<li>Can track evolution of design across iterations</li>
<li>Comments and explanations included inline</li>
</ul>
<p><strong>4. Context Efficiency</strong></p>
<ul>
<li>Prose is more token-efficient than structured data for complex ideas</li>
<li>&quot;Create a React app with Zustand state management&quot; (8 tokens) vs extensive JSON schema</li>
<li>Agents can summarize and reference instead of including full content</li>
</ul>
<p><strong>5. Self-Documenting</strong></p>
<ul>
<li>Architecture decisions explained in-place</li>
<li>Future agents (in self-healing loop) understand <em>why</em> choices were made</li>
<li>Serves as project documentation after build completes</li>
</ul>
<p><strong>Example:</strong> <code>architecture.md</code> isn&#39;t just a file list—it explains the <em>why</em> behind each component.</p>
<hr>
<h3 id="q3-whats-in-each-md-file-whats-their-purpose">Q3: What&#39;s in each <code>.md</code> file? What&#39;s their purpose?</h3>
<p><strong>A:</strong> Each file serves a specific phase in the workflow:</p>
<div class="table-wrapper">
  <table>
    <thead><tr>
<th>File</th>
<th>Phase</th>
<th>Purpose</th>
<th>Typical Size</th>
</tr>
</thead>
    <tbody><tr>
<td><code>scout-report.md</code></td>
<td>Phase 1: Scout</td>
<td>Requirements analysis, tech stack decisions, risk identification</td>
<td>5-10 KB</td>
</tr>
<tr>
<td><code>architecture.md</code></td>
<td>Phase 2: Architect</td>
<td>Complete system design, file structure, implementation plan, test strategy</td>
<td>15-30 KB</td>
</tr>
<tr>
<td><code>build-log.md</code></td>
<td>Phase 3: Builder</td>
<td>Files created, implementation notes, deviations from architecture</td>
<td>5-15 KB</td>
</tr>
<tr>
<td><code>test-results-iteration-N.md</code></td>
<td>Phase 4: Test</td>
<td>Test failures, root cause analysis, fix recommendations</td>
<td>10-20 KB</td>
</tr>
<tr>
<td><code>fixes-iteration-N.md</code></td>
<td>Self-Healing</td>
<td>Fix strategy for failed tests</td>
<td>5-10 KB</td>
</tr>
<tr>
<td><code>test-final-report.md</code></td>
<td>Phase 4: Test</td>
<td>Final test results (pass or fail after all iterations)</td>
<td>5-10 KB</td>
</tr>
<tr>
<td><code>session-summary.json</code></td>
<td>Phase 8: Feedback</td>
<td>Build summary (JSON for MCP parsing)</td>
<td>2-5 KB</td>
</tr>
</tbody>
  </table>
</div>
<p><strong>JSON Files</strong> (structured data for parsing):</p>
<ul>
<li><code>build-tasks.json</code>: Parallel task breakdown with dependencies (Phase 2.5)</li>
<li><code>current-phase.json</code>: Real-time phase tracking for TUI monitoring</li>
<li><code>session-summary.json</code>: Final build results for MCP server</li>
</ul>
<p><strong>Log Directories:</strong></p>
<ul>
<li><code>builder-logs/task-{ID}.log</code>: Individual builder agent outputs (Phase 2.5)</li>
<li><code>test-logs/{type}.log</code>: Individual test agent outputs (Phase 4.5)</li>
</ul>
<hr>
<h3 id="q4-how-do-files-persist-across-phases-if-agents-die-after-each-phase">Q4: How do files persist across phases if agents die after each phase?</h3>
<p><strong>A:</strong> <strong>Filesystem is the shared memory.</strong> This is a core design principle.</p>
<p><strong>The Flow:</strong></p>
<ol>
<li><strong>Phase 1 (Scout):</strong> Agent researches, writes <code>scout-report.md</code>, then dies</li>
<li><strong>Phase 2 (Architect):</strong> New agent spawned, <em>reads</em> <code>scout-report.md</code>, writes <code>architecture.md</code>, dies</li>
<li><strong>Phase 3 (Builder):</strong> New agent spawned, <em>reads</em> <code>architecture.md</code>, writes code files + <code>build-log.md</code>, dies</li>
<li><strong>Phase 4 (Tester):</strong> New agent spawned, <em>reads</em> <code>architecture.md</code> and code, runs tests, writes results</li>
</ol>
<p><strong>Why this works:</strong></p>
<ul>
<li>Files are durable (survive process termination)</li>
<li>Each agent starts with fresh 200K context window</li>
<li>Agent only loads what it needs (Scout report is 5-10KB, not 150KB of code)</li>
<li>No context pollution from previous phases</li>
</ul>
<p><strong>This is fundamentally different from Cursor/Copilot</strong> which maintain long-lived sessions.</p>
<hr>
<h3 id="q5-can-i-version-control-the-context-foundry-directory">Q5: Can I version control the <code>.context-foundry/</code> directory?</h3>
<p><strong>A:</strong> <strong>Yes, and you probably should!</strong></p>
<p><strong>Recommended <code>.gitignore</code> strategy:</strong></p>
<pre><code class="language-gitignore"># Keep architecture and design docs
# .context-foundry/scout-report.md
# .context-foundry/architecture.md

# Ignore build artifacts and logs
.context-foundry/builder-logs/
.context-foundry/test-logs/
.context-foundry/current-phase.json
.context-foundry/test-iteration-count.txt

# Keep task breakdown (helps understand build decisions)
# .context-foundry/build-tasks.json</code></pre>
<p><strong>Benefits of versioning:</strong></p>
<ul>
<li>Track architecture evolution across builds</li>
<li>Understand why design decisions were made</li>
<li>Reproduce builds if needed</li>
<li>Share architecture with team</li>
</ul>
<p><strong>Alternative:</strong> Add entire <code>.context-foundry/</code> to <code>.gitignore</code> if you don&#39;t want build artifacts in repo.</p>
<hr>
<h3 id="q6-what-happens-to-context-foundry-files-after-a-successful-build">Q6: What happens to <code>.context-foundry/</code> files after a successful build?</h3>
<p><strong>A:</strong> They <strong>persist permanently</strong> (until you delete them).</p>
<p><strong>Lifecycle:</strong></p>
<ol>
<li>First build: <code>.context-foundry/</code> created, all phase files written</li>
<li>Subsequent builds: Files may be overwritten or appended</li>
<li>After deployment: Files remain for historical reference</li>
</ol>
<p><strong>Cleanup strategies:</strong></p>
<pre><code class="language-bash"># Clean all build artifacts (keeps architecture docs)
rm -rf .context-foundry/builder-logs .context-foundry/test-logs

# Clean everything (fresh start)
rm -rf .context-foundry/

# Archive before cleaning
tar -czf context-foundry-$(date +%Y%m%d).tar.gz .context-foundry/</code></pre>
<p><strong>Best practice:</strong> Keep <code>.context-foundry/</code> for at least one successful build cycle—it&#39;s invaluable for debugging.</p>
<hr>
<h2 id="2-the-secret-sauce-prompt-engineering">2. The &quot;Secret Sauce&quot; - Prompt Engineering</h2>
<h3 id="q7-where-are-the-core-prompts-that-make-context-foundry-work">Q7: Where are the core prompts that make Context Foundry work?</h3>
<p><strong>A:</strong> The &quot;magic&quot; is in three main prompt files:</p>
<div class="table-wrapper">
  <table>
    <thead><tr>
<th>Prompt File</th>
<th>Purpose</th>
<th>Line Count</th>
<th>Link</th>
</tr>
</thead>
    <tbody><tr>
<td><strong><code>tools/orchestrator_prompt.txt</code></strong></td>
<td>Main 8-phase orchestrator</td>
<td>~1200 lines</td>
<td><a href="https://github.com/context-foundry/context-foundry/blob/main/tools/orchestrator_prompt.txt" target="_blank" rel="noopener noreferrer">View on GitHub <svg class="external-link-icon" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line></svg></a></td>
</tr>
<tr>
<td><strong><code>tools/builder_task_prompt.txt</code></strong></td>
<td>Parallel builder agent (Phase 2.5)</td>
<td>~161 lines</td>
<td><a href="https://github.com/context-foundry/context-foundry/blob/main/tools/builder_task_prompt.txt" target="_blank" rel="noopener noreferrer">View on GitHub <svg class="external-link-icon" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line></svg></a></td>
</tr>
<tr>
<td><strong><code>tools/test_task_prompt.txt</code></strong></td>
<td>Parallel test agent (Phase 4.5)</td>
<td>~208 lines</td>
<td><a href="https://github.com/context-foundry/context-foundry/blob/main/tools/test_task_prompt.txt" target="_blank" rel="noopener noreferrer">View on GitHub <svg class="external-link-icon" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line></svg></a></td>
</tr>
</tbody>
  </table>
</div>
<p><strong>Supporting prompts:</strong></p>
<ul>
<li><code>ace/scouts/scout_subagent.py</code>: Scout agent configuration</li>
<li><code>ace/architects/architect_subagent.py</code>: Architect agent configuration</li>
<li><code>ace/builders/builder_subagent.py</code>: Builder agent configuration (deprecated in favor of parallel)</li>
</ul>
<hr>
<h3 id="q8-how-does-orchestrator-prompttxt-coordinate-the-entire-build">Q8: How does <code>orchestrator_prompt.txt</code> coordinate the entire build?</h3>
<p><strong>A:</strong> It&#39;s a <strong>single, massive prompt</strong> that defines all 8 phases sequentially with strict instructions:</p>
<p><strong>Structure:</strong></p>
<pre><code class="">╔═══════════════════════════════════╗
║   CONTEXT FOUNDRY ORCHESTRATOR    ║
╚═══════════════════════════════════╝

YOU ARE AN AUTONOMOUS ORCHESTRATOR AGENT
Mission: Complete software development tasks fully autonomously...

═══════════════════════════════════
PHASE 1: SCOUT (Research &amp; Context Gathering)
═══════════════════════════════════
⚠️  CRITICAL: PHASE TRACKING (MANDATORY FIRST ACTION) ⚠️
Step 1: Create .context-foundry/current-phase.json
Step 2: Verify file was created
Step 3: Broadcast to livestream

1. Check for Past Learnings (Self-Learning System)...
2. Create Scout agent: Type: /agents...
3. Activate Scout and research...
4. Save Scout findings: .context-foundry/scout-report.md

⚠️  CRITICAL: UPDATE PHASE TRACKING TO &quot;completed&quot;

═══════════════════════════════════
PHASE 2: ARCHITECT (Design &amp; Planning)
═══════════════════════════════════
[... detailed Architect instructions ...]

═══════════════════════════════════
PHASE 2.5: PARALLEL BUILD PLANNING (MANDATORY)
═══════════════════════════════════
⚡ CRITICAL: ALWAYS USE PARALLEL BUILDERS - NO EXCEPTIONS
[... bash spawning instructions with examples ...]

[... continues for all 8 phases ...]</code></pre>
<p><strong>Key Techniques:</strong></p>
<ol>
<li><strong>Imperative Commands:</strong> &quot;You MUST&quot;, &quot;CRITICAL&quot;, &quot;MANDATORY&quot;</li>
<li><strong>Step-by-Step Instructions:</strong> Numbered lists for each phase</li>
<li><strong>Concrete Examples:</strong> Actual bash commands to execute</li>
<li><strong>Self-Verification:</strong> &quot;Execute: cat file.json | grep status&quot;</li>
<li><strong>Error Handling:</strong> &quot;If X fails, do Y&quot;</li>
<li><strong>Phase Transitions:</strong> Explicit &quot;Proceed to PHASE N&quot; statements</li>
</ol>
<p><strong>Why this works:</strong> Claude follows procedural instructions extremely well when they&#39;re explicit and sequential.</p>
<hr>
<h3 id="q9-how-do-parallel-builder-agents-coordinate-without-talking-to-each-other">Q9: How do parallel builder agents coordinate without talking to each other?</h3>
<p><strong>A:</strong> Via <strong><code>builder_task_prompt.txt</code></strong> and filesystem synchronization.</p>
<p><strong>The Prompt Structure:</strong></p>
<pre><code class="">YOU ARE A SPECIALIZED BUILDER AGENT (PARALLEL EXECUTION MODE)

You are one of several Builder agents working in parallel on different parts of a project.
Your job is to implement a SINGLE, SPECIFIC task from the architecture specification.

═══════════════════════════════════
CRITICAL RULES FOR PARALLEL EXECUTION
═══════════════════════════════════

✓ You are responsible for ONE task only (specified below)
✓ Read architecture from .context-foundry/architecture.md
✓ Read your specific task from .context-foundry/build-tasks.json
✓ Other builders are working on other tasks simultaneously
✓ Write your code files directly - no conflicts (each task has unique files)
✓ Use /agents command for implementation (REQUIRED)
✓ Log your progress to .context-foundry/builder-logs/task-{ID}.log
✓ Mark task complete by creating .context-foundry/builder-logs/task-{ID}.done</code></pre>
<p><strong>Coordination Mechanism:</strong></p>
<ol>
<li><p><strong>Input:</strong> Orchestrator passes task via command line:</p>
<pre><code class="language-bash">claude --system-prompt builder_task_prompt.txt \
  &quot;TASK_ID: task-3 | DESCRIPTION: Build player system | FILES: player.js, input.js&quot;</code></pre>
</li>
<li><p><strong>Shared Context:</strong> All builders read same <code>architecture.md</code> (read-only)</p>
</li>
<li><p><strong>File Isolation:</strong> Architect ensures each task has <strong>unique files</strong> (no write conflicts)</p>
</li>
<li><p><strong>Completion Signal:</strong> Creates <code>.done</code> file when finished</p>
</li>
<li><p><strong>No IPC:</strong> Agents never communicate directly—orchestrator coordinates</p>
</li>
</ol>
<p><strong>Why this works:</strong> No shared memory = no race conditions. Filesystem is atomic.</p>
<hr>
<h3 id="q10-what-makes-these-prompts-effective-can-i-learn-from-them">Q10: What makes these prompts effective? Can I learn from them?</h3>
<p><strong>A:</strong> Several advanced prompt engineering techniques:</p>
<p><strong>1. Role Clarity</strong></p>
<pre><code class="">YOU ARE A SPECIALIZED BUILDER AGENT (PARALLEL EXECUTION MODE)

You are one of several Builder agents working in parallel...</code></pre>
<ul>
<li>Establishes agent identity immediately</li>
<li>Sets expectations for behavior</li>
<li>Clarifies constraints (parallel, not sequential)</li>
</ul>
<p><strong>2. Structured Sections with Visual Separators</strong></p>
<pre><code class="">═══════════════════════════════════
CRITICAL RULES FOR PARALLEL EXECUTION
═══════════════════════════════════</code></pre>
<ul>
<li>Visual hierarchy helps Claude parse structure</li>
<li>CRITICAL/MANDATORY keywords trigger higher attention</li>
<li>Boxed sections improve scannability</li>
</ul>
<p><strong>3. Concrete Examples Over Abstractions</strong></p>
<pre><code class="language-bash"># DON&#039;T: &quot;Spawn parallel processes&quot;
# DO:
claude --print --system-prompt &quot;$(cat &quot;$BUILDER_PROMPT&quot;)&quot; \
  &quot;TASK_ID: task-1 | FILES: game.js, engine.js&quot; &amp;
PID_1=$!</code></pre>
<ul>
<li>Actual bash commands to execute</li>
<li>No ambiguity about implementation</li>
</ul>
<p><strong>4. Success Criteria</strong></p>
<pre><code class="">✅ If successful: Proceed to Phase 5
❌ If failed: Debug and retry (do NOT fall back to sequential)</code></pre>
<ul>
<li>Clear decision points</li>
<li>Explicit error handling paths</li>
</ul>
<p><strong>5. Self-Verification</strong></p>
<pre><code class="">Step 2: Verify file was created
Execute: cat .context-foundry/current-phase.json
Confirm you see the JSON content above.</code></pre>
<ul>
<li>Agent validates its own work</li>
<li>Catches issues before proceeding</li>
</ul>
<p><strong>You can absolutely learn from these!</strong> They&#39;re open source for this reason.</p>
<hr>
<h3 id="q11-can-i-customize-the-prompts-for-my-specific-use-case">Q11: Can I customize the prompts for my specific use case?</h3>
<p><strong>A:</strong> <strong>Yes!</strong> Prompts are just text files. Here&#39;s how:</p>
<p><strong>Safe Customizations:</strong></p>
<ol>
<li><p><strong>Add Domain-Specific Patterns</strong></p>
<pre><code class=""># Add to Phase 1 (Scout):
- For blockchain projects: Check for Web3 security patterns
- For ML projects: Verify GPU/CPU resource requirements</code></pre>
</li>
<li><p><strong>Adjust Parallelism Thresholds</strong></p>
<pre><code class=""># In Phase 2.5:
- If tasks &lt; 4: Use 2 parallel builders  # Change this
- If tasks 4-8: Use 6 parallel builders  # Change this</code></pre>
</li>
<li><p><strong>Add Custom Test Types</strong></p>
<pre><code class=""># In Phase 4.5:
- Spawn security tests: claude --system-prompt test_task_prompt.txt &quot;TEST_TYPE: security&quot;</code></pre>
</li>
</ol>
<p><strong>Dangerous Customizations (avoid):</strong></p>
<ul>
<li>❌ Removing phase tracking (breaks TUI monitoring)</li>
<li>❌ Removing <code>.done</code> file creation (breaks coordination)</li>
<li>❌ Changing the &quot;use <code>/agents</code>&quot; instruction (breaks auth inheritance)</li>
<li>❌ Removing error handling sections (reduces reliability)</li>
</ul>
<p><strong>Testing Custom Prompts:</strong></p>
<pre><code class="language-bash"># Test custom orchestrator on small project
claude --system-prompt custom_orchestrator.txt \
  &quot;Build a simple to-do list app&quot;</code></pre>
<hr>
<h2 id="3-agent-architecture-lifecycle">3. Agent Architecture &amp; Lifecycle</h2>
<h3 id="q12-how-many-agents-are-created-in-a-typical-build-session">Q12: How many agents are created in a typical build session?</h3>
<p><strong>A:</strong> Depends on project size and parallel execution.</p>
<p><strong>Small Project (2-5 files):</strong></p>
<ul>
<li>1 Scout agent (Phase 1)</li>
<li>1 Architect agent (Phase 2)</li>
<li>2 Builder agents (Phase 2.5 parallel - minimum 2)</li>
<li>1-2 Test agents (Phase 4 or 4.5)</li>
<li>1 Documentation agent (Phase 5)</li>
<li>1 Deployer agent (Phase 6-7)</li>
<li><strong>Total: ~8-10 agents</strong></li>
</ul>
<p><strong>Medium Project (6-15 files):</strong></p>
<ul>
<li>1 Scout</li>
<li>1 Architect</li>
<li>4 Builder agents (Phase 2.5 parallel)</li>
<li>3 Test agents (Phase 4.5: unit + e2e + lint)</li>
<li>1 Documentation</li>
<li>1 Deployer</li>
<li><strong>Total: ~11-15 agents</strong></li>
<li><strong>Self-healing iteration:</strong> +3 agents (Architect + Builder + Tester) per iteration</li>
</ul>
<p><strong>Large Project (16+ files):</strong></p>
<ul>
<li>1 Scout</li>
<li>1 Architect</li>
<li>8 Builder agents (Phase 2.5 parallel - maximum recommended)</li>
<li>3 Test agents (Phase 4.5)</li>
<li>1 Screenshot agent (Phase 4.75)</li>
<li>1 Documentation</li>
<li>1 Deployer</li>
<li><strong>Total: ~16-20 agents</strong></li>
<li><strong>Self-healing (up to 3 iterations):</strong> +9 agents per iteration</li>
<li><strong>Worst case (3 fix iterations):</strong> ~45 agents total</li>
</ul>
<p><strong>Why these numbers matter for cost/performance calculations.</strong></p>
<hr>
<h3 id="q13-do-agents-share-context-or-run-completely-isolated">Q13: Do agents share context or run completely isolated?</h3>
<p><strong>A:</strong> <strong>Completely isolated.</strong> Each agent is a separate <code>claude</code> process with fresh context.</p>
<p><strong>Isolation Mechanisms:</strong></p>
<ol>
<li><p><strong>Separate Processes</strong></p>
<pre><code class="language-bash"># Each spawns new claude instance
claude --system-prompt builder_task_prompt.txt &quot;task-1&quot; &amp;  # Process 1
claude --system-prompt builder_task_prompt.txt &quot;task-2&quot; &amp;  # Process 2
# No shared memory between these processes</code></pre>
</li>
<li><p><strong>Fresh Context Window</strong></p>
<ul>
<li>Each agent starts with 200,000 token budget</li>
<li>No pollution from previous phases</li>
<li>Can&#39;t see other agents&#39; internal reasoning</li>
</ul>
</li>
<li><p><strong>Filesystem as IPC</strong></p>
<ul>
<li>Agents communicate ONLY via files</li>
<li>Read: <code>architecture.md</code>, <code>scout-report.md</code></li>
<li>Write: task-specific output files</li>
<li>Signal: <code>.done</code> files</li>
</ul>
</li>
</ol>
<p><strong>Benefits:</strong></p>
<ul>
<li>✅ No context bleed between agents</li>
<li>✅ Parallelizable (no shared state)</li>
<li>✅ Fault-tolerant (one agent crash doesn&#39;t affect others)</li>
<li>✅ Debuggable (each agent&#39;s log is independent)</li>
</ul>
<p><strong>Tradeoffs:</strong></p>
<ul>
<li>❌ Can&#39;t share discoveries during execution</li>
<li>❌ May duplicate work if tasks overlap</li>
<li>❌ Requires good upfront planning (Architect phase)</li>
</ul>
<hr>
<h3 id="q14-how-long-does-an-agent-live-when-does-context-get-freed">Q14: How long does an agent live? When does context get freed?</h3>
<p><strong>A:</strong> Agents live <strong>only for their specific task</strong>, then die immediately.</p>
<p><strong>Lifecycle:</strong></p>
<pre><code class="">Orchestrator spawns Scout agent
  ↓
Scout researches (2-5 minutes)
  ↓
Scout writes scout-report.md
  ↓
Scout agent EXITS → 200K context freed
  ↓
Orchestrator reads scout-report.md (10 KB)
  ↓
Orchestrator spawns Architect agent (fresh 200K)
  ↓
Architect reads scout-report.md (10 KB in context)
  ↓
Architect designs system (5-10 minutes)
  ↓
Architect writes architecture.md
  ↓
Architect agent EXITS → 200K context freed
  ↓
[... continues for each phase ...]</code></pre>
<p><strong>Typical Agent Lifespans:</strong></p>
<ul>
<li>Scout: 2-5 minutes</li>
<li>Architect: 5-10 minutes</li>
<li>Builder (parallel): 3-8 minutes each</li>
<li>Tester: 2-5 minutes</li>
<li>Documentation: 3-5 minutes</li>
<li>Deployer: 1-2 minutes</li>
</ul>
<p><strong>Why this matters:</strong></p>
<ul>
<li>Long-running agents accumulate context debt</li>
<li>Killing agents prevents token window overflow</li>
<li>Fresh agents = fresh perspective (reduces fixation errors)</li>
</ul>
<hr>
<h3 id="q15-can-agents-communicate-during-execution-or-only-via-files">Q15: Can agents communicate during execution, or only via files?</h3>
<p><strong>A:</strong> <strong>Only via files.</strong> This is a deliberate architectural constraint.</p>
<p><strong>Communication Patterns:</strong></p>
<p><strong>❌ NOT Possible:</strong></p>
<ul>
<li>Agent A calling Agent B&#39;s API</li>
<li>Shared memory/variables</li>
<li>Message passing queues</li>
<li>Network communication between agents</li>
</ul>
<p><strong>✅ Supported:</strong></p>
<ul>
<li>Agent A writes file → Agent B reads file</li>
<li>Agent A creates <code>.done</code> marker → Orchestrator detects completion</li>
<li>All agents read shared <code>architecture.md</code> (read-only)</li>
</ul>
<p><strong>Example: Builder Coordination</strong></p>
<pre><code class="">Builder 1:
  1. Reads: .context-foundry/architecture.md
  2. Reads: .context-foundry/build-tasks.json (sees task-1 assignment)
  3. Writes: src/game.js, src/engine.js
  4. Writes: .context-foundry/builder-logs/task-1.log
  5. Writes: .context-foundry/builder-logs/task-1.done
  6. Exits

Builder 2 (running simultaneously):
  1. Reads: Same architecture.md (no conflict, read-only)
  2. Reads: Same build-tasks.json (sees task-2 assignment)
  3. Writes: src/player.js, src/input.js (different files, no conflict)
  4. Writes: .context-foundry/builder-logs/task-2.log
  5. Writes: .context-foundry/builder-logs/task-2.done
  6. Exits

Orchestrator (after all builders complete):
  1. Checks: task-1.done exists ✅
  2. Checks: task-2.done exists ✅
  3. Reads: task-1.log, task-2.log (aggregates results)
  4. Proceeds to Phase 4 (Test)</code></pre>
<p><strong>Why this constraint?</strong></p>
<ul>
<li>Simpler reasoning model (no race conditions)</li>
<li>Easier to debug (check log files)</li>
<li>Matches Unix philosophy (files as interfaces)</li>
</ul>
<hr>
<h2 id="4-token-management-context-windows">4. Token Management &amp; Context Windows</h2>
<h3 id="q16-how-does-context-foundry-avoid-exceeding-claudes-200k-token-window">Q16: How does Context Foundry avoid exceeding Claude&#39;s 200K token window?</h3>
<p><strong>A:</strong> Through <strong>aggressive context management</strong> and <strong>agent lifecycle design</strong>.</p>
<p><strong>Strategy 1: Agent Death After Each Phase</strong></p>
<p>Instead of one long-lived agent accumulating context:</p>
<pre><code class="">❌ BAD (Cursor-style):
┌─────────────────────────────────────┐
│ Single Agent Session                │
│ Context: 0K → 50K → 120K → 180K ⚠️  │
│ (approaching limit)                 │
└─────────────────────────────────────┘

✅ GOOD (Context Foundry):
Scout (200K fresh) → dies
  ↓ (passes 10KB file)
Architect (200K fresh) → dies
  ↓ (passes 30KB file)
Builder (200K fresh) → dies
  ↓ (passes 15KB file)
Tester (200K fresh) → dies</code></pre>
<p><strong>Strategy 2: Markdown Summaries Instead of Full Code</strong></p>
<p>Agents don&#39;t load all source files into context:</p>
<pre><code class="language-python"># Architect doesn&#039;t do this:
context = read_all_files(&quot;src/**/*.js&quot;)  # 150KB of code

# Architect does this:
context = read(&quot;architecture.md&quot;)  # 30KB summary
# &quot;The game.js file implements the core game loop using requestAnimationFrame...&quot;</code></pre>
<p><strong>Strategy 3: Parallel Builders Have Narrow Context</strong></p>
<p>Each parallel builder only needs:</p>
<pre><code class="">Builder 1 context:
- builder_task_prompt.txt (5KB)
- architecture.md (30KB) - only relevant sections
- Task assignment (0.5KB): &quot;Build game.js, engine.js&quot;
- Total: ~35KB (83% of context available for generation)

Builder 1 does NOT load:
- src/player.js (being built by Builder 2)
- src/enemy.js (being built by Builder 3)
- Test files
- Documentation</code></pre>
<p><strong>Strategy 4: Incremental Context Loading</strong></p>
<p>Tester agent doesn&#39;t load all code:</p>
<pre><code class="">Tester reads:
1. architecture.md (30KB) - what SHOULD exist
2. Test output logs (10KB) - what FAILED
3. Only failed test files (20KB) - targeted debugging

Tester does NOT read:
- All 50 source files (would be 200KB+)
- Passing test files
- Build logs</code></pre>
<p><strong>Result:</strong> Even large projects stay well under 200K per agent.</p>
<hr>
<h3 id="q17-what-happens-when-a-project-is-so-large-that-even-architecturemd-is-huge">Q17: What happens when a project is so large that even <code>architecture.md</code> is huge?</h3>
<p><strong>A:</strong> The <strong>Architect is trained to be concise</strong>, but there are limits.</p>
<p><strong>Typical <code>architecture.md</code> sizes:</strong></p>
<ul>
<li>Small project: 10-20 KB</li>
<li>Medium project: 20-40 KB</li>
<li>Large project: 40-80 KB</li>
<li><strong>Problematic:</strong> &gt;100 KB (happens with 100+ file projects)</li>
</ul>
<p><strong>Mitigation Strategies:</strong></p>
<p><strong>1. Architect Prompt Includes Conciseness Guidelines:</strong></p>
<pre><code class="">⚠️  KEEP IT CONCISE - Target 5-10KB, not 60KB!

Include:
- Executive summary (2-3 paragraphs max)
- Key requirements (bulleted list, not essay)
- Critical architecture recommendations (top 3-5 items)

DO NOT write exhaustive documentation - Builder will handle details.</code></pre>
<p><strong>2. Multi-Document Strategy (for very large projects):</strong></p>
<pre><code class="">.context-foundry/
├── architecture.md              # High-level (40KB)
├── architecture-frontend.md     # Frontend details (30KB)
├── architecture-backend.md      # Backend details (30KB)
└── architecture-database.md     # Database schema (20KB)</code></pre>
<p>Builders read only relevant sub-documents.</p>
<p><strong>3. Parallel Builders Reduce Per-Agent Context:</strong></p>
<pre><code class="">Sequential Builder:
- Reads: Full architecture.md (80KB)
- Builds: All 50 files
- Total context: ~80KB + generated code

Parallel Builder (task-3):
- Reads: Only &quot;Player System&quot; section (15KB excerpt)
- Builds: 2 files (player.js, input.js)
- Total context: ~15KB + generated code</code></pre>
<p><strong>4. Architecture References Code Comments:</strong></p>
<pre><code class="language-markdown"># Player System Architecture

See `src/player.js` lines 1-20 for initialization logic.
(Architect doesn&#039;t paste the code, just references it)</code></pre>
<p><strong>Current Limitation:</strong> Projects with &gt;200 files may strain even this system. These are rare for autonomous builds.</p>
<hr>
<h3 id="q18-does-parallel-execution-use-more-tokens-overall">Q18: Does parallel execution use MORE tokens overall?</h3>
<p><strong>A:</strong> Yes, but <strong>cost is worth the time savings</strong>, and it&#39;s not 2x-8x multiplier.</p>
<p><strong>Token Usage Comparison:</strong></p>
<p><strong>Sequential Build (OLD):</strong></p>
<pre><code class="">Scout:      20K tokens
Architect:  40K tokens
Builder:    150K tokens (builds all files sequentially)
Tester:     30K tokens
Docs:       20K tokens
Deploy:     10K tokens
───────────────────────
Total:      270K tokens
Time:       28 minutes</code></pre>
<p><strong>Parallel Build (NEW):</strong></p>
<pre><code class="">Scout:      20K tokens
Architect:  40K tokens (+ creates build-tasks.json)
Builders:   4 × 50K = 200K tokens (parallel, each builds subset)
Testers:    3 × 15K = 45K tokens (parallel tests)
Docs:       20K tokens
Deploy:     10K tokens
───────────────────────
Total:      335K tokens (+24%)
Time:       18 minutes (-36%)</code></pre>
<p><strong>Why not 4x token usage for 4 parallel builders?</strong></p>
<ol>
<li><p><strong>Context Overlap Reduction:</strong></p>
<ul>
<li>Each builder reads smaller architecture sections (~15KB vs 40KB)</li>
<li>Builders don&#39;t load each other&#39;s code</li>
</ul>
</li>
<li><p><strong>Coordination Overhead is Minimal:</strong></p>
<ul>
<li>Orchestrator spawning logic: ~2K tokens</li>
<li>Task JSON parsing: ~1K tokens</li>
</ul>
</li>
<li><p><strong>Time Savings Dominate Cost:</strong></p>
<ul>
<li>10 minutes saved × hourly rate = worth extra $0.50 in API costs</li>
</ul>
</li>
</ol>
<p><strong>Real-World Example:</strong></p>
<ul>
<li>Medium project: 335K tokens = ~$1.00 (Claude Sonnet)</li>
<li>Time saved: 10 minutes</li>
<li><strong>ROI:</strong> Massive for professional developers</li>
</ul>
<hr>
<h3 id="q19-can-context-foundry-handle-incremental-builds-to-avoid-context-bloat">Q19: Can Context Foundry handle incremental builds to avoid context bloat?</h3>
<p><strong>A:</strong> <strong>Partial support.</strong> Incremental builds are on the roadmap.</p>
<p><strong>Current State:</strong></p>
<ul>
<li>Each build is <strong>full rebuild</strong> (starts from Scout phase)</li>
<li>Previous <code>.context-foundry/</code> files can be read as reference</li>
<li>Pattern learning provides cross-build continuity</li>
</ul>
<p><strong>Experimental Incremental Support:</strong></p>
<p>In <code>autonomous_build_and_deploy()</code>:</p>
<pre><code class="language-python">def autonomous_build_and_deploy(
    task: str,
    working_directory: str,
    incremental: bool = False,  # NEW parameter
    force_rebuild: bool = False,
    ...
):
    if incremental and not force_rebuild:
        # Check if .context-foundry/architecture.md exists
        # Skip Scout/Architect phases
        # Start from Builder with updated requirements</code></pre>
<p><strong>Challenges:</strong></p>
<ol>
<li><strong>Determining what changed</strong> (requires diffing)</li>
<li><strong>Invalidating dependent components</strong> (dependency graph needed)</li>
<li><strong>Test suite must run fully</strong> (can&#39;t skip tests)</li>
</ol>
<p><strong>Workaround for Now:</strong></p>
<pre><code class="language-bash"># Manual incremental build:
# 1. Keep old .context-foundry/architecture.md
# 2. Tell Context Foundry: &quot;Add user authentication to existing app&quot;
# 3. Architect will read old architecture.md and extend it</code></pre>
<p><strong>Future Enhancement (v3.0 roadmap):</strong></p>
<ul>
<li>Git diff analysis</li>
<li>Dependency graph tracking</li>
<li>Selective rebuilds</li>
<li>70-90% faster for small changes</li>
</ul>
<hr>
<h2 id="5-parallelization-coordination">5. Parallelization &amp; Coordination</h2>
<h3 id="q20-how-does-topological-sort-work-for-task-dependencies">Q20: How does topological sort work for task dependencies?</h3>
<p><strong>A:</strong> The <strong>Architect agent</strong> creates a dependency graph, then Orchestrator executes tasks in sorted levels.</p>
<p><strong>Example Project:</strong> Game with 4 modules</p>
<p><strong>Step 1: Architect Analyzes Dependencies</strong></p>
<pre><code class="language-markdown"># In architecture.md:

Modules:
1. game.js - core game loop (no dependencies)
2. player.js - player logic (depends on game.js for game state)
3. enemy.js - enemy AI (depends on game.js for game state)
4. main.js - entry point (depends on game.js, player.js, enemy.js)</code></pre>
<p><strong>Step 2: Architect Creates <code>build-tasks.json</code></strong></p>
<pre><code class="language-json">{
  &quot;parallel_mode&quot;: true,
  &quot;total_tasks&quot;: 4,
  &quot;tasks&quot;: [
    {
      &quot;id&quot;: &quot;task-1&quot;,
      &quot;description&quot;: &quot;Create game engine core&quot;,
      &quot;files&quot;: [&quot;src/game.js&quot;, &quot;src/engine.js&quot;],
      &quot;dependencies&quot;: []  // Level 0
    },
    {
      &quot;id&quot;: &quot;task-2&quot;,
      &quot;description&quot;: &quot;Create player system&quot;,
      &quot;files&quot;: [&quot;src/player.js&quot;, &quot;src/input.js&quot;],
      &quot;dependencies&quot;: [&quot;task-1&quot;]  // Level 1
    },
    {
      &quot;id&quot;: &quot;task-3&quot;,
      &quot;description&quot;: &quot;Create enemy system&quot;,
      &quot;files&quot;: [&quot;src/enemy.js&quot;, &quot;src/ai.js&quot;],
      &quot;dependencies&quot;: [&quot;task-1&quot;]  // Level 1
    },
    {
      &quot;id&quot;: &quot;task-4&quot;,
      &quot;description&quot;: &quot;Create main entry point&quot;,
      &quot;files&quot;: [&quot;src/main.js&quot;],
      &quot;dependencies&quot;: [&quot;task-1&quot;, &quot;task-2&quot;, &quot;task-3&quot;]  // Level 2
    }
  ]
}</code></pre>
<p><strong>Step 3: Orchestrator Computes Levels</strong></p>
<pre><code class="language-python"># Pseudo-code (actual implementation is in bash):
levels = topological_sort(tasks)

# Result:
# Level 0: [task-1] (no dependencies)
# Level 1: [task-2, task-3] (depend on Level 0)
# Level 2: [task-4] (depends on Level 1)</code></pre>
<p><strong>Step 4: Orchestrator Spawns by Level</strong></p>
<pre><code class="language-bash"># Level 0 (parallel)
claude ... &quot;task-1&quot; &amp;
PID_1=$!
wait $PID_1

# Level 1 (parallel)
claude ... &quot;task-2&quot; &amp;
PID_2=$!
claude ... &quot;task-3&quot; &amp;
PID_3=$!
wait $PID_2 $PID_3

# Level 2 (sequential, only 1 task)
claude ... &quot;task-4&quot;</code></pre>
<p><strong>Actual Bash Implementation (in <code>orchestrator_prompt.txt</code>):</strong></p>
<pre><code class="language-bash"># Read build-tasks.json
tasks=$(cat .context-foundry/build-tasks.json)

# Extract level 0 tasks (dependencies = [])
level_0_tasks=$(echo &quot;$tasks&quot; | jq -r &#039;.tasks[] | select(.dependencies | length == 0) | .id&#039;)

# Spawn all level 0 tasks in parallel
pids=()
for task_id in $level_0_tasks; do
  claude --system-prompt builder_task_prompt.txt &quot;TASK_ID: $task_id ...&quot; &amp;
  pids+=($!)
done

# Wait for all level 0 to complete
wait &quot;${pids[@]}&quot;

# Verify all level 0 .done files exist
for task_id in $level_0_tasks; do
  [ -f &quot;.context-foundry/builder-logs/$task_id.done&quot; ] || exit 1
done

# Now spawn level 1 tasks...</code></pre>
<p><strong>Key Points:</strong></p>
<ul>
<li>DAG (Directed Acyclic Graph) structure</li>
<li>Parallelism within levels, sequential between levels</li>
<li>Architect is responsible for correct dependency analysis</li>
</ul>
<hr>
<h3 id="q21-what-prevents-file-write-conflicts-when-multiple-builders-run-in-parallel">Q21: What prevents file write conflicts when multiple builders run in parallel?</h3>
<p><strong>A:</strong> <strong>Architect guarantees file uniqueness</strong> per task. This is enforced in the prompt.</p>
<p><strong>Enforcement in <code>orchestrator_prompt.txt</code> (Phase 2):</strong></p>
<pre><code class="">4. Activate Architect and design:

   **CRITICAL for Parallel Execution:**
   - Each task MUST have unique files assigned
   - NO file should appear in multiple tasks
   - If file X imports from file Y, Y must be in an earlier task (dependency)
   - Validate: No file appears in &gt;1 task&#039;s &quot;files&quot; array</code></pre>
<p><strong>Architect&#39;s Validation Logic:</strong></p>
<p>When creating <code>build-tasks.json</code>, Architect checks:</p>
<pre><code class="language-python"># Pseudo-code (Architect&#039;s reasoning):
all_files = set()
for task in tasks:
    for file in task.files:
        if file in all_files:
            # CONFLICT DETECTED
            raise ArchitectureError(f&quot;{file} assigned to multiple tasks&quot;)
        all_files.add(file)</code></pre>
<p><strong>Example of Correct Assignment:</strong></p>
<pre><code class="language-json">{
  &quot;tasks&quot;: [
    {&quot;id&quot;: &quot;task-1&quot;, &quot;files&quot;: [&quot;src/game.js&quot;, &quot;src/engine.js&quot;]},
    {&quot;id&quot;: &quot;task-2&quot;, &quot;files&quot;: [&quot;src/player.js&quot;, &quot;src/input.js&quot;]},  // NO overlap
    {&quot;id&quot;: &quot;task-3&quot;, &quot;files&quot;: [&quot;src/enemy.js&quot;, &quot;src/ai.js&quot;]}       // NO overlap
  ]
}</code></pre>
<p><strong>Example of INCORRECT Assignment (Architect would fix this):</strong></p>
<pre><code class="language-json">{
  &quot;tasks&quot;: [
    {&quot;id&quot;: &quot;task-1&quot;, &quot;files&quot;: [&quot;src/game.js&quot;, &quot;src/engine.js&quot;]},
    {&quot;id&quot;: &quot;task-2&quot;, &quot;files&quot;: [&quot;src/game.js&quot;, &quot;src/player.js&quot;]},  // ❌ game.js conflict!
  ]
}</code></pre>
<p><strong>Filesystem-Level Protection:</strong></p>
<p>Even if Architect makes a mistake:</p>
<pre><code class="language-bash"># Both builders try to write src/game.js
Builder 1: echo &quot;code A&quot; &gt; src/game.js  # Writes version A
Builder 2: echo &quot;code B&quot; &gt; src/game.js  # Overwrites with version B (race condition)

# Result: Unpredictable (last write wins)
# Test phase will catch broken code</code></pre>
<p><strong>Self-Healing Catches Mistakes:</strong></p>
<ol>
<li>Builder 2 overwrites Builder 1&#39;s work</li>
<li>Tests fail (broken imports)</li>
<li>Self-healing iteration: Architect analyzes, fixes task assignment</li>
<li>Rebuild with correct file isolation</li>
</ol>
<p><strong>Real-World:</strong> File conflicts are rare because Architect prompts emphasize this heavily.</p>
<hr>
<h3 id="q22-how-is-coordination-achieved-without-shared-memory-or-message-queues">Q22: How is coordination achieved without shared memory or message queues?</h3>
<p><strong>A:</strong> <strong>Filesystem + <code>.done</code> files</strong> act as a coordination primitive.</p>
<p><strong>Coordination Protocol:</strong></p>
<p><strong>1. Task Assignment (via CLI argument):</strong></p>
<pre><code class="language-bash"># Orchestrator tells Builder 1 what to do:
claude --system-prompt builder_task_prompt.txt \
  &quot;TASK_ID: task-1 | DESCRIPTION: Build game engine | FILES: game.js, engine.js&quot;

# Builder 1 parses this string, knows its assignment</code></pre>
<p><strong>2. Shared Read-Only Context:</strong></p>
<pre><code class="">All builders read:
- .context-foundry/architecture.md (shared design doc)
- .context-foundry/build-tasks.json (task definitions)

No locks needed (read-only)</code></pre>
<p><strong>3. Isolated Write Paths:</strong></p>
<pre><code class="">Builder 1 writes:
- src/game.js
- src/engine.js
- .context-foundry/builder-logs/task-1.log

Builder 2 writes:
- src/player.js
- src/input.js
- .context-foundry/builder-logs/task-2.log

No overlap = no conflicts</code></pre>
<p><strong>4. Completion Signaling (<code>.done</code> files):</strong></p>
<pre><code class="language-bash"># Builder 1 finishes:
touch .context-foundry/builder-logs/task-1.done

# Builder 2 finishes:
touch .context-foundry/builder-logs/task-2.done

# Orchestrator waits:
wait $PID_1 $PID_2  # Blocks until both processes exit

# Orchestrator verifies:
[ -f task-1.done ] &amp;&amp; [ -f task-2.done ] &amp;&amp; echo &quot;All complete&quot;</code></pre>
<p><strong>5. Synchronization Barriers:</strong></p>
<pre><code class="language-bash"># Level 0 tasks must ALL complete before Level 1 starts
for task in task-1 task-2 task-3; do
  if [ ! -f &quot;.context-foundry/builder-logs/$task.done&quot; ]; then
    echo &quot;ERROR: $task did not complete&quot;
    exit 1  # Abort build
  fi
done

# Only after all .done files exist:
# Spawn Level 1 tasks...</code></pre>
<p><strong>Why This Works:</strong></p>
<ul>
<li><strong>Atomic file creation:</strong> <code>touch file.done</code> is atomic on modern filesystems</li>
<li><strong>Blocking wait:</strong> <code>wait</code> command blocks until process exit (kernel-level)</li>
<li><strong>File existence check:</strong> <code>[ -f file ]</code> is deterministic</li>
<li><strong>No race conditions:</strong> No shared mutable state</li>
</ul>
<p><strong>This is simpler than:</strong></p>
<ul>
<li>❌ Redis pub/sub</li>
<li>❌ Message queues (RabbitMQ)</li>
<li>❌ Distributed locks (Zookeeper)</li>
<li>❌ Shared memory (semaphores)</li>
</ul>
<p><strong>Unix philosophy:</strong> Files are universal coordination primitive.</p>
<hr>
<h3 id="q23-whats-the-overhead-of-spawning-multiple-claude-processes-vs-using-threads">Q23: What&#39;s the overhead of spawning multiple <code>claude</code> processes vs using threads?</h3>
<p><strong>A:</strong> <strong>Process spawning has higher overhead, but benefits outweigh costs.</strong></p>
<p><strong>Overhead Comparison:</strong></p>
<div class="table-wrapper">
  <table>
    <thead><tr>
<th>Metric</th>
<th>Threads (Python)</th>
<th>Processes (bash)</th>
<th>Winner</th>
</tr>
</thead>
    <tbody><tr>
<td>Spawn time</td>
<td>~10ms</td>
<td>~500ms</td>
<td>Threads</td>
</tr>
<tr>
<td>Memory per worker</td>
<td>~50MB (shared)</td>
<td>~200MB (isolated)</td>
<td>Threads</td>
</tr>
<tr>
<td>Context isolation</td>
<td>❌ Shared</td>
<td>✅ Isolated</td>
<td><strong>Processes</strong></td>
</tr>
<tr>
<td>Debugging</td>
<td>❌ Complex</td>
<td>✅ Separate logs</td>
<td><strong>Processes</strong></td>
</tr>
<tr>
<td>Fault tolerance</td>
<td>❌ One crash = all crash</td>
<td>✅ Isolated crashes</td>
<td><strong>Processes</strong></td>
</tr>
<tr>
<td>Authentication</td>
<td>❌ Needs API keys</td>
<td>✅ Inherits Claude Code auth</td>
<td><strong>Processes</strong></td>
</tr>
</tbody>
  </table>
</div>
<p><strong>Real-World Overhead Measurement:</strong></p>
<pre><code class="language-bash"># Sequential (no spawning):
time: 20 minutes
overhead: 0s

# Parallel (4 processes):
time: 12 minutes
overhead: 4 × 500ms = 2s (spawning) + 10s (coordination)
net savings: 8 minutes - 12s = 7.8 minutes (39% faster)</code></pre>
<p><strong>Why Process Overhead is Acceptable:</strong></p>
<ol>
<li><p><strong>Spawning is one-time cost:</strong></p>
<ul>
<li>500ms to spawn × 4 builders = 2s total</li>
<li>Builders run for 5-10 minutes each</li>
<li>Overhead is &lt;1% of total time</li>
</ul>
</li>
<li><p><strong>Memory usage is temporary:</strong></p>
<ul>
<li>200MB × 4 processes = 800MB peak</li>
<li>Processes exit after completion</li>
<li>Memory freed immediately</li>
</ul>
</li>
<li><p><strong>Benefits are massive:</strong></p>
<ul>
<li>✅ No API key management</li>
<li>✅ Inherits Claude Code auth</li>
<li>✅ Simpler code (bash vs Python threading)</li>
<li>✅ Better error isolation</li>
</ul>
</li>
</ol>
<p><strong>Threading Would Require:</strong></p>
<pre><code class="language-python"># OLD system (deprecated):
from anthropic import Anthropic
client = Anthropic(api_key=os.getenv(&quot;ANTHROPIC_API_KEY&quot;))  # ❌ Needs key

with ThreadPoolExecutor(max_workers=4) as executor:
    futures = [executor.submit(build_task, task) for task in tasks]
    # ❌ Shared memory, race conditions possible
    # ❌ Complex error handling</code></pre>
<p><strong>Process Spawning:</strong></p>
<pre><code class="language-bash"># NEW system:
claude --system-prompt builder_task_prompt.txt &quot;task-1&quot; &amp;  # ✅ Inherits auth
# Simple, isolated, works</code></pre>
<p><strong>Verdict:</strong> Process overhead is negligible compared to build time, auth benefits are huge.</p>
<hr>
<h2 id="6-authentication-api-usage">6. Authentication &amp; API Usage</h2>
<h3 id="q24-does-context-foundry-make-direct-api-calls-to-anthropic">Q24: Does Context Foundry make direct API calls to Anthropic?</h3>
<p><strong>A:</strong> <strong>No.</strong> This was a major architectural change.</p>
<p><strong>OLD System (Python, deprecated):</strong></p>
<pre><code class="language-python">from anthropic import Anthropic

client = Anthropic(api_key=os.getenv(&quot;ANTHROPIC_API_KEY&quot;))
response = client.messages.create(
    model=&quot;claude-sonnet-4-5&quot;,
    messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: task}]
)</code></pre>
<ul>
<li>❌ Required <code>.env</code> file with API key</li>
<li>❌ Didn&#39;t inherit Claude Code&#39;s authentication</li>
<li>❌ Rate limiting was manual</li>
</ul>
<p><strong>NEW System (bash + <code>/agents</code>):</strong></p>
<pre><code class="language-bash">claude --print --system-prompt builder_task_prompt.txt \
  &quot;TASK_ID: task-1 | FILES: game.js&quot;</code></pre>
<ul>
<li>✅ Uses Claude Code CLI (which handles API calls internally)</li>
<li>✅ Inherits Claude Code&#39;s auth automatically</li>
<li>✅ No <code>.env</code> file needed</li>
<li>✅ Rate limiting handled by Claude Code</li>
</ul>
<p><strong>Under the Hood:</strong></p>
<p>When you run <code>claude ...</code>:</p>
<ol>
<li>Claude Code CLI reads your <code>~/.claude/config</code></li>
<li>Uses your authenticated session</li>
<li>Makes API call on your behalf</li>
<li>Returns result to stdout</li>
</ol>
<p>Context Foundry just captures stdout:</p>
<pre><code class="language-bash">claude ... &gt; output.log 2&gt;&amp;1</code></pre>
<p><strong>Why This Matters:</strong></p>
<ul>
<li>Users don&#39;t need to manage API keys separately</li>
<li>Works wherever Claude Code works</li>
<li>Respects Claude Code&#39;s rate limiting</li>
</ul>
<hr>
<h3 id="q25-how-does-the-agents-command-inherit-claude-code-authentication">Q25: How does the <code>/agents</code> command inherit Claude Code authentication?</h3>
<p><strong>A:</strong> <code>/agents</code> is a <strong>native Claude Code feature</strong>, not something Context Foundry implements.</p>
<p><strong>The Flow:</strong></p>
<ol>
<li><p><strong>User authenticates with Claude Code:</strong></p>
<pre><code class="language-bash">claude auth login
# Stores credentials in ~/.claude/config</code></pre>
</li>
<li><p><strong>Context Foundry spawns claude CLI:</strong></p>
<pre><code class="language-bash">claude --system-prompt orchestrator_prompt.txt &quot;Build a game&quot;</code></pre>
</li>
<li><p><strong>Claude Code CLI reads credentials:</strong></p>
<pre><code class="language-python"># Inside claude CLI (simplified):
config = read_config(&quot;~/.claude/config&quot;)
api_key = config.get(&quot;api_key&quot;)
client = Anthropic(api_key=api_key)</code></pre>
</li>
<li><p><strong>User types <code>/agents</code> in the conversation:</strong></p>
<pre><code class="">user: Build game.js and engine.js
claude: I&#039;ll use /agents to implement this</code></pre>
</li>
<li><p><strong>Claude Code spawns sub-agent:</strong></p>
<pre><code class="language-python"># Inside claude CLI when it sees /agents:
sub_agent = spawn_agent(
    description=&quot;Expert developer implementing game engine&quot;,
    api_key=self.api_key  # ✅ Inherits from parent session
)</code></pre>
</li>
</ol>
<p><strong>Context Foundry&#39;s Role:</strong></p>
<p>We just tell Claude to use <code>/agents</code>:</p>
<pre><code class=""># In builder_task_prompt.txt:
3. Create Builder agent:
   Type: /agents
   Description: &quot;Expert developer implementing {task description}&quot;</code></pre>
<p>Claude Code handles the rest.</p>
<p><strong>Authentication Chain:</strong></p>
<pre><code class="">User → Claude Code CLI → Anthropic API
         ↑ (authenticated)

Context Foundry → claude CLI → /agents → Sub-agent
                  ↑ (inherits auth)</code></pre>
<p><strong>Why This is Better Than DIY:</strong></p>
<ul>
<li>✅ No API key management</li>
<li>✅ Respects user&#39;s Claude Code settings</li>
<li>✅ Benefits from Claude Code&#39;s rate limiting</li>
<li>✅ Works with enterprise auth (SSO, etc.)</li>
</ul>
<hr>
<h3 id="q26-are-api-keys-required-anywhere-in-context-foundry">Q26: Are API keys required anywhere in Context Foundry?</h3>
<p><strong>A:</strong> <strong>No API keys required</strong> (as of v2.0+).</p>
<p><strong>What You DON&#39;T Need:</strong></p>
<ul>
<li>❌ <code>.env</code> file with <code>ANTHROPIC_API_KEY</code></li>
<li>❌ OpenAI API key</li>
<li>❌ Separate authentication from Claude Code</li>
</ul>
<p><strong>What You DO Need:</strong></p>
<ul>
<li>✅ Claude Code installed (<code>npm install -g @anthropic-ai/claude-code</code>)</li>
<li>✅ Authenticated with Claude Code (<code>claude auth login</code>)</li>
<li>✅ Active Claude subscription (Pro or API credits)</li>
</ul>
<p><strong>Verification:</strong></p>
<pre><code class="language-bash"># Check if you&#039;re authenticated:
claude auth status

# If authenticated, Context Foundry works immediately:
claude
&gt; &quot;Build a to-do app with Context Foundry&quot;</code></pre>
<p><strong>Legacy Notes:</strong></p>
<p>Old versions (&lt;= v1.x) had optional API key support:</p>
<pre><code class="language-python"># tools/mcp_server.py (deprecated code, removed):
ANTHROPIC_API_KEY = os.getenv(&quot;ANTHROPIC_API_KEY&quot;)
OPENAI_API_KEY = os.getenv(&quot;OPENAI_API_KEY&quot;)</code></pre>
<p>This was removed in v2.0 when we migrated to <code>/agents</code> architecture.</p>
<p><strong>Environment Variables Context Foundry Uses:</strong></p>
<pre><code class="language-bash"># NONE! Everything is in ~/.claude/config managed by Claude Code</code></pre>
<hr>
<h3 id="q27-how-does-context-foundry-handle-rate-limiting">Q27: How does Context Foundry handle rate limiting?</h3>
<p><strong>A:</strong> <strong>Claude Code handles it automatically.</strong> Context Foundry doesn&#39;t implement rate limiting.</p>
<p><strong>Claude Code&#39;s Rate Limiting:</strong></p>
<ol>
<li><p><strong>API Tier Detection:</strong></p>
<pre><code class="">claude CLI detects your tier:
- Free tier: 5 requests/minute
- Pro tier: 50 requests/minute
- API tier: Custom limits</code></pre>
</li>
<li><p><strong>Automatic Backoff:</strong></p>
<pre><code class="language-python"># Inside claude CLI:
try:
    response = client.messages.create(...)
except RateLimitError:
    sleep(60)  # Wait and retry
    response = client.messages.create(...)</code></pre>
</li>
<li><p><strong>Request Queueing:</strong></p>
<ul>
<li>Claude Code queues requests internally</li>
<li>Spawning 4 parallel builders doesn&#39;t cause 429 errors</li>
</ul>
</li>
</ol>
<p><strong>Context Foundry&#39;s Impact:</strong></p>
<p><strong>Parallel builds can make more requests:</strong></p>
<pre><code class="">Sequential build:
- 1 request every 2-5 minutes (as each phase completes)
- Total: ~8 requests over 28 minutes
- Well below rate limits

Parallel build:
- 4 builders start simultaneously
- 4 requests at once (initial spawn)
- Then sporadic requests as builders use /agents
- Total: ~15 requests over 18 minutes
- Still well below rate limits (50/minute for Pro)</code></pre>
<p><strong>If You Hit Rate Limits:</strong></p>
<p>Unlikely unless you&#39;re on Free tier running massive builds:</p>
<pre><code class="language-bash"># Error message:
Rate limit exceeded. Please wait 60 seconds.

# Context Foundry will:
1. See builder process hang
2. Wait for timeout (default: 90 minutes)
3. If builder doesn&#039;t create .done file → mark as failed
4. Self-healing loop retries (with natural rate limit spacing)</code></pre>
<p><strong>Best Practice:</strong></p>
<ul>
<li>Use Pro tier for regular Context Foundry usage</li>
<li>Free tier works for small projects (&lt; 10 files)</li>
</ul>
<hr>
<h2 id="7-mcp-server-architecture-context-management">7. MCP Server Architecture &amp; Context Management</h2>
<h3 id="q28-what-is-the-mcp-server-and-why-is-it-critical-to-context-foundry">Q28: What is the MCP server and why is it critical to Context Foundry?</h3>
<p><strong>A:</strong> The <strong>MCP (Model Context Protocol) server</strong> is the orchestration layer that makes Context Foundry work with Claude Code/Desktop <strong>without consuming your main context window</strong>.</p>
<p><strong>What It Is:</strong></p>
<p>The MCP server is a Python service (<code>tools/mcp_server.py</code>, ~1200 lines) built with <a href="https://github.com/jlowin/fastmcp" target="_blank" rel="noopener noreferrer">FastMCP <svg class="external-link-icon" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line></svg></a> that:</p>
<ul>
<li>Exposes Context Foundry functionality as <strong>MCP tools</strong> (like function calls)</li>
<li>Bridges between Claude Code/Desktop and Context Foundry&#39;s autonomous build system</li>
<li>Runs as a <strong>stdio server</strong> (communicates via standard input/output, not HTTP)</li>
<li>Loaded automatically by Claude Code/Desktop when configured in MCP settings</li>
</ul>
<p><strong>Why It&#39;s Critical:</strong></p>
<pre><code class="">❌ WITHOUT MCP Server:
──────────────────────────────
You: &quot;Build a weather app&quot;
Claude (in your main window):
  - Scout researches... (20K tokens accumulated)
  - Architect designs... (60K tokens accumulated)
  - Builder implements... (150K tokens accumulated)
  - Tester runs tests... (180K tokens accumulated)
  - ⚠️ DANGER: Approaching 200K token limit
  - Can&#039;t do much more in this conversation

✅ WITH MCP Server:
──────────────────────────────
You: &quot;Build a weather app using Context Foundry&quot;
Claude (in your main window):
  - Calls MCP tool: autonomous_build_and_deploy()
  - Returns task_id: &quot;abc-123&quot;
  - Main window context: ~2K tokens (just the request + task ID)

MCP Server (in background):
  - Spawns SEPARATE claude process
  - That process has FRESH 200K context window
  - Scout, Architect, Builder, Tester all run there
  - When done, returns SUMMARY (5KB) to main window

Result:
  - Your main window stays clean (~7K tokens total)
  - You can continue other work
  - 193K tokens still available in main window!</code></pre>
<p><strong>Critical Features:</strong></p>
<ol>
<li><strong>Context Isolation:</strong> Build happens in separate process, doesn&#39;t pollute main window</li>
<li><strong>Background Execution:</strong> Non-blocking, returns immediately</li>
<li><strong>Authentication Inheritance:</strong> Spawned processes use your Claude Code auth (no API keys)</li>
<li><strong>Task Tracking:</strong> Can monitor multiple builds simultaneously</li>
<li><strong>Result Aggregation:</strong> Returns concise summaries, not full build logs</li>
</ol>
<p><strong>Architecture Location:</strong></p>
<ul>
<li>Source: <a href="https://github.com/context-foundry/context-foundry/blob/main/tools/mcp_server.py" target="_blank" rel="noopener noreferrer"><code>tools/mcp_server.py</code> <svg class="external-link-icon" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line></svg></a></li>
<li>Configuration: <code>.claude/mcp-config.json</code> (in your home directory)</li>
<li>Prompts: <code>tools/orchestrator_prompt.txt</code> (passed to spawned processes)</li>
</ul>
<hr>
<h3 id="q29-how-does-the-mcp-server-free-up-your-main-claude-context-window">Q29: How does the MCP server free up your main Claude context window?</h3>
<p><strong>A:</strong> Through <strong>process delegation</strong>—work happens in a separate <code>claude</code> process with its own fresh 200K context window.</p>
<p><strong>The Delegation Pattern:</strong></p>
<pre class="mermaid">sequenceDiagram
    participant User as You (Main Window)
    participant Main as Claude (Main Process)
    participant MCP as MCP Server
    participant Sub as Claude (Subprocess)

    Note over User,Sub: Main window context: 5K tokens

    User-&gt;&gt;Main: &quot;Build a weather app with Context Foundry&quot;
    Main-&gt;&gt;MCP: Call tool: autonomous_build_and_deploy(...)
    Note over MCP: MCP server receives call via stdio

    MCP-&gt;&gt;MCP: Build command:&lt;br/&gt;claude --system-prompt orchestrator_prompt.txt
    MCP-&gt;&gt;Sub: Spawn subprocess (background)
    Note over Sub: Fresh 200K context window

    MCP-&gt;&gt;Main: Return: {&quot;task_id&quot;: &quot;abc-123&quot;, &quot;status&quot;: &quot;started&quot;}
    Main-&gt;&gt;User: &quot;Build started! Task ID: abc-123&quot;
    Note over User,Main: Main window context: Still ~5K tokens ✅

    Note over Sub: Subprocess runs entire build:&lt;br/&gt;Scout → Architect → Builder → Test → Deploy

    Sub-&gt;&gt;Sub: Scout phase (20K tokens)
    Sub-&gt;&gt;Sub: Architect phase (40K tokens)
    Sub-&gt;&gt;Sub: Builder phase (60K tokens)
    Sub-&gt;&gt;Sub: Test phase (30K tokens)
    Sub-&gt;&gt;Sub: Deploy phase (10K tokens)
    Note over Sub: Subprocess context: 160K tokens used&lt;br/&gt;(isolated from main window)

    Sub-&gt;&gt;MCP: Build complete! Summary: {...}
    Note over Sub: Subprocess exits, context freed

    User-&gt;&gt;Main: &quot;Check build status: abc-123&quot;
    Main-&gt;&gt;MCP: Call tool: get_delegation_result(&quot;abc-123&quot;)
    MCP-&gt;&gt;Main: Return: Build summary (5KB)
    Main-&gt;&gt;User: &quot;✅ Build complete!&lt;br/&gt;Tests: 25/25 passing&lt;br/&gt;GitHub: https://github.com/...&quot;
    Note over User,Main: Main window context: ~10K tokens total ✅</pre>
<p><strong>Context Comparison:</strong></p>
<div class="table-wrapper">
  <table>
    <thead><tr>
<th>Metric</th>
<th>Without MCP</th>
<th>With MCP</th>
</tr>
</thead>
    <tbody><tr>
<td><strong>Main Window Context (during build)</strong></td>
<td>150-180K tokens</td>
<td>~5K tokens</td>
</tr>
<tr>
<td><strong>Main Window Context (after build)</strong></td>
<td>180-190K tokens</td>
<td>~10K tokens</td>
</tr>
<tr>
<td><strong>Available for Other Tasks</strong></td>
<td>10-20K tokens</td>
<td>190K tokens</td>
</tr>
<tr>
<td><strong>Build Isolation</strong></td>
<td>❌ Pollutes main conversation</td>
<td>✅ Isolated subprocess</td>
</tr>
<tr>
<td><strong>Can Continue Working</strong></td>
<td>❌ No (approaching limit)</td>
<td>✅ Yes (plenty of space)</td>
</tr>
</tbody>
  </table>
</div>
<p><strong>Real-World Example:</strong></p>
<pre><code class="">Session WITHOUT MCP:
──────────────────────────────
You: &quot;Build a weather app&quot;
[... 30 minutes of build messages ...]
You: &quot;Great! Now help me debug this other project&quot;
Claude: &quot;I&#039;m approaching my context limit. Can we start a new conversation?&quot;
❌ You lose conversation history

Session WITH MCP:
──────────────────────────────
You: &quot;Build a weather app with Context Foundry&quot;
Claude: &quot;Started! Task ID: abc-123. I&#039;ll let you know when done.&quot;
You: &quot;While that runs, help me debug this other project&quot;
Claude: &quot;Sure! What&#039;s the issue?&quot;
[... debugging conversation ...]
Claude: &quot;By the way, your weather app build completed successfully!&quot;
✅ You keep conversation context, build happens in background</code></pre>
<p><strong>Key Insight:</strong> MCP enables <strong>&quot;fire and forget&quot;</strong> builds—start a build, continue other work, check results later.</p>
<hr>
<h3 id="q30-what-toolsfunctions-does-the-mcp-server-provide">Q30: What tools/functions does the MCP server provide?</h3>
<p><strong>A:</strong> The MCP server exposes <strong>10 tools</strong> for autonomous builds, task delegation, and pattern management.</p>
<p><strong>Core Build Tool:</strong></p>
<p><strong><code>autonomous_build_and_deploy()</code></strong></p>
<pre><code class="language-python"># Main autonomous build orchestrator
autonomous_build_and_deploy(
    task=&quot;Build a weather dashboard with OpenWeatherMap API&quot;,
    working_directory=&quot;/path/to/project&quot;,
    github_repo_name=&quot;weather-dashboard&quot;,  # Optional: create new repo
    existing_repo=None,  # Or: enhance existing repo
    mode=&quot;new_project&quot;,  # or &quot;fix_bugs&quot;, &quot;add_docs&quot;
    enable_test_loop=True,  # Self-healing
    max_test_iterations=3,  # Max fix attempts
    timeout_minutes=90.0,  # Max execution time
    use_parallel=True,  # Parallel builders/tests
    incremental=False,  # Incremental builds (experimental)
    force_rebuild=False  # Force full rebuild
)
# Returns: {&quot;task_id&quot;: &quot;abc-123&quot;, &quot;status&quot;: &quot;started&quot;, ...}</code></pre>
<p><strong>What it does:</strong></p>
<ul>
<li>Spawns fresh Claude instance with <code>orchestrator_prompt.txt</code></li>
<li>Runs complete 8-phase workflow (Scout → Deploy)</li>
<li>Self-healing test loop (up to <code>max_test_iterations</code>)</li>
<li>Parallel execution (Phase 2.5: builders, Phase 4.5: tests)</li>
<li>GitHub deployment</li>
<li>Returns task ID immediately (non-blocking)</li>
</ul>
<hr>
<p><strong>Task Delegation Tools:</strong></p>
<p><strong><code>delegate_to_claude_code()</code> (Synchronous)</strong></p>
<pre><code class="language-python"># Delegate a task and wait for completion
delegate_to_claude_code(
    task=&quot;Analyze this codebase and suggest improvements&quot;,
    working_directory=&quot;/path/to/project&quot;,
    timeout_minutes=10.0,
    additional_flags=&quot;--model claude-sonnet-4&quot;,  # Optional CLI flags
    include_full_output=False  # Truncate large outputs
)
# Returns: Formatted output with stdout/stderr
# Blocks until task completes</code></pre>
<p><strong>What it does:</strong></p>
<ul>
<li>Spawns <code>claude</code> CLI subprocess</li>
<li>Waits for completion (blocking)</li>
<li>Returns stdout + stderr</li>
<li>Useful for quick tasks (analysis, code generation, debugging)</li>
</ul>
<p><strong><code>delegate_to_claude_code_async()</code> (Asynchronous)</strong></p>
<pre><code class="language-python"># Start task in background, return immediately
delegate_to_claude_code_async(
    task=&quot;Run comprehensive test suite&quot;,
    working_directory=&quot;/path/to/project&quot;,
    timeout_minutes=20.0,
    additional_flags=None
)
# Returns: {&quot;task_id&quot;: &quot;def-456&quot;, &quot;status&quot;: &quot;started&quot;, ...}
# Non-blocking, task runs in background</code></pre>
<p><strong>What it does:</strong></p>
<ul>
<li>Spawns subprocess in background</li>
<li>Returns task ID immediately</li>
<li>Track status with <code>get_delegation_result()</code></li>
<li>Enable parallel task execution</li>
</ul>
<p><strong><code>get_delegation_result(task_id, include_full_output=False)</code></strong></p>
<pre><code class="language-python"># Check status of async task
get_delegation_result(&quot;def-456&quot;)
# Returns:
# - If running: {&quot;status&quot;: &quot;running&quot;, &quot;elapsed&quot;: &quot;5m 30s&quot;, ...}
# - If complete: {&quot;status&quot;: &quot;completed&quot;, &quot;stdout&quot;: &quot;...&quot;, &quot;stderr&quot;: &quot;...&quot;, ...}
# - If failed: {&quot;status&quot;: &quot;failed&quot;, &quot;error&quot;: &quot;...&quot;, ...}</code></pre>
<p><strong>What it does:</strong></p>
<ul>
<li>Checks subprocess status</li>
<li>Returns current output (if running)</li>
<li>Returns final results (if complete)</li>
<li>Truncates large outputs (unless <code>include_full_output=True</code>)</li>
</ul>
<p><strong><code>list_delegations()</code></strong></p>
<pre><code class="language-python"># List all active and completed tasks
list_delegations()
# Returns: {&quot;tasks&quot;: [{&quot;task_id&quot;: &quot;...&quot;, &quot;status&quot;: &quot;...&quot;, ...}, ...]}</code></pre>
<p><strong>What it does:</strong></p>
<ul>
<li>Shows all background tasks</li>
<li>Status for each (running/completed/failed)</li>
<li>Elapsed time</li>
<li>Useful for monitoring multiple builds</li>
</ul>
<hr>
<p><strong>Pattern Management Tools:</strong></p>
<p><strong><code>read_global_patterns(pattern_type)</code></strong></p>
<pre><code class="language-python"># Read patterns from global storage
read_global_patterns(&quot;common-issues&quot;)
# Returns: JSON with patterns learned from ALL past builds

read_global_patterns(&quot;scout-learnings&quot;)
# Returns: JSON with scout discoveries across projects</code></pre>
<p><strong>What it does:</strong></p>
<ul>
<li>Reads from <code>~/.context-foundry/patterns/</code></li>
<li>Returns patterns in JSON format</li>
<li>Used by Scout/Architect phases for learning</li>
</ul>
<p><strong><code>save_global_patterns(pattern_type, patterns_data)</code></strong></p>
<pre><code class="language-python"># Save patterns to global storage
patterns = json.dumps({&quot;patterns&quot;: [...], &quot;version&quot;: &quot;1.0&quot;})
save_global_patterns(&quot;common-issues&quot;, patterns)</code></pre>
<p><strong>What it does:</strong></p>
<ul>
<li>Writes patterns to <code>~/.context-foundry/patterns/</code></li>
<li>Creates backups before overwriting</li>
<li>Used by Deployer phase after successful builds</li>
</ul>
<p><strong><code>merge_project_patterns(project_pattern_file, pattern_type)</code></strong></p>
<pre><code class="language-python"># Merge project-specific patterns into global storage
merge_project_patterns(
    project_pattern_file=&quot;/path/to/project/.context-foundry/patterns/common-issues.json&quot;,
    pattern_type=&quot;common-issues&quot;
)</code></pre>
<p><strong>What it does:</strong></p>
<ul>
<li>Reads patterns from project file</li>
<li>Merges into global storage (increments frequency)</li>
<li>Deduplicates patterns</li>
<li>Cross-project learning mechanism</li>
</ul>
<p><strong><code>migrate_all_project_patterns(projects_base_dir)</code></strong></p>
<pre><code class="language-python"># Migrate patterns from all projects in a directory
migrate_all_project_patterns(&quot;/Users/name/homelab&quot;)
# Scans all subdirectories for .context-foundry/patterns/
# Merges all into ~/.context-foundry/patterns/</code></pre>
<hr>
<p><strong>Utility Tool:</strong></p>
<p><strong><code>context_foundry_status()</code></strong></p>
<pre><code class="language-python"># Get MCP server status
context_foundry_status()
# Returns: Server version, available tools, capabilities</code></pre>
<hr>
<p><strong>Tool Count Summary:</strong></p>
<ul>
<li><strong>1</strong> main autonomous build tool</li>
<li><strong>4</strong> delegation tools (sync/async delegation, status check, list)</li>
<li><strong>4</strong> pattern management tools</li>
<li><strong>1</strong> status utility</li>
<li><strong>Total: 10 tools</strong></li>
</ul>
<hr>
<h3 id="q31-how-does-the-mcp-server-orchestrate-agents-with-the-claude-cli">Q31: How does the MCP server orchestrate agents with the Claude CLI?</h3>
<p><strong>A:</strong> Through <strong>subprocess spawning</strong> with the <code>orchestrator_prompt.txt</code> as a system prompt.</p>
<p><strong>The Orchestration Flow:</strong></p>
<pre><code class="">Step 1: User Invokes MCP Tool
─────────────────────────────────────────
User (in main Claude window):
&gt; &quot;Build a weather app using Context Foundry&quot;

Claude (main process):
&gt; Calling tool: autonomous_build_and_deploy(task=&quot;Build a weather app&quot;, ...)


Step 2: MCP Server Receives Call
─────────────────────────────────────────
MCP Server (tools/mcp_server.py):
1. Receives tool call via stdio (FastMCP handles protocol)
2. Validates parameters
3. Loads orchestrator_prompt.txt

Code (simplified):
orchestrator_prompt_path = Path(__file__).parent / &quot;orchestrator_prompt.txt&quot;
with open(orchestrator_prompt_path) as f:
    system_prompt = f.read()  # ~1200 lines, 8-phase workflow


Step 3: Build Command
─────────────────────────────────────────
MCP Server builds command:

cmd = [
    &quot;claude&quot;,
    &quot;--print&quot;,  # Non-interactive mode, exit after completion
    &quot;--permission-mode&quot;, &quot;bypassPermissions&quot;,  # Skip permission prompts
    &quot;--strict-mcp-config&quot;,  # Don&#039;t load MCP servers (avoid recursion)
    &quot;--settings&quot;, &#039;{&quot;thinkingMode&quot;: &quot;off&quot;}&#039;,  # Disable thinking blocks
    &quot;--system-prompt&quot;, system_prompt,  # Pass orchestrator as system prompt
    task_prompt  # User&#039;s task
]


Step 4: Spawn Subprocess in Background
─────────────────────────────────────────
MCP Server spawns:

process = subprocess.Popen(
    cmd,
    cwd=working_directory,
    stdout=subprocess.PIPE,
    stderr=subprocess.PIPE,
    stdin=subprocess.DEVNULL,  # No input needed
    env=os.environ  # Inherits PATH, Claude auth, etc.
)

Subprocess runs in background (non-blocking).
MCP server tracks it in active_tasks dict.


Step 5: Return Task ID Immediately
─────────────────────────────────────────
MCP Server returns to main Claude window:

{
  &quot;task_id&quot;: &quot;abc-123-def-456&quot;,
  &quot;status&quot;: &quot;started&quot;,
  &quot;task&quot;: &quot;Build a weather app&quot;,
  &quot;working_directory&quot;: &quot;/path/to/project&quot;,
  &quot;message&quot;: &quot;Build started! Use get_delegation_result(&#039;abc-123...&#039;) to check status.&quot;
}

Main window context: ~2K tokens (just the response).


Step 6: Subprocess Executes Full Build
─────────────────────────────────────────
Spawned Claude process (fresh 200K context):

1. Loads system prompt: orchestrator_prompt.txt
2. Reads user task: &quot;Build a weather app&quot;
3. Executes Phase 1: Scout
   - Spawns Scout agent via /agents
   - Scout researches, writes scout-report.md
   - Scout agent dies
4. Executes Phase 2: Architect
   - Spawns Architect agent via /agents
   - Reads scout-report.md
   - Writes architecture.md, build-tasks.json
   - Architect agent dies
5. Executes Phase 2.5: Parallel Build
   - Spawns 4 Builder agents (separate processes!)
   - Each uses builder_task_prompt.txt
   - All write code simultaneously
   - All die when done
6. Executes Phase 4.5: Parallel Test
   - Spawns 3 Test agents (unit/e2e/lint)
   - Each uses test_task_prompt.txt
   - All run tests simultaneously
   - All die when done
7. If tests fail: Self-healing loop (back to Phase 2)
8. If tests pass: Phase 5-7 (Docs, Deploy)
9. Subprocess writes final summary to stdout
10. Subprocess exits (context freed)


Step 7: MCP Server Captures Results
─────────────────────────────────────────
MCP Server monitors subprocess:

stdout, stderr = process.communicate()  # Wait for completion
exit_code = process.returncode

Stores results in active_tasks[&quot;abc-123&quot;]:
{
  &quot;status&quot;: &quot;completed&quot;,
  &quot;stdout&quot;: &quot;✅ Build successful! GitHub: https://...&quot;,
  &quot;stderr&quot;: &quot;&quot;,
  &quot;duration&quot;: &quot;18 minutes&quot;,
  &quot;exit_code&quot;: 0
}


Step 8: User Checks Results
─────────────────────────────────────────
User (in main window):
&gt; &quot;Check the build status&quot;

Claude:
&gt; Calling tool: get_delegation_result(&quot;abc-123&quot;)

MCP Server returns:
{
  &quot;status&quot;: &quot;completed&quot;,
  &quot;duration&quot;: &quot;18 minutes&quot;,
  &quot;summary&quot;: &quot;Build successful! 25/25 tests passing. GitHub: https://...&quot;
}

Main window context: ~7K tokens total (original 2K + 5K summary).</code></pre>
<p><strong>Key Mechanisms:</strong></p>
<ol>
<li><p><strong>System Prompt Injection:</strong></p>
<pre><code class="language-bash">claude --system-prompt &quot;$(cat orchestrator_prompt.txt)&quot; &quot;Build app&quot;
# Orchestrator&#039;s 8-phase workflow becomes Claude&#039;s system instruction</code></pre>
</li>
<li><p><strong>Non-Interactive Execution:</strong></p>
<pre><code class="language-bash">--print  # Runs once, prints result, exits (no interactive loop)</code></pre>
</li>
<li><p><strong>Permission Bypass:</strong></p>
<pre><code class="language-bash">--permission-mode bypassPermissions  # Autonomous, no user confirmations</code></pre>
</li>
<li><p><strong>MCP Recursion Prevention:</strong></p>
<pre><code class="language-bash">--strict-mcp-config  # Spawned instance doesn&#039;t load MCP servers
# Prevents infinite recursion (MCP calling MCP calling MCP...)</code></pre>
</li>
<li><p><strong>Authentication Inheritance:</strong></p>
<pre><code class="language-bash">env=os.environ  # Subprocess inherits parent environment
# Includes ~/.claude/config authentication
# No API keys needed</code></pre>
</li>
</ol>
<p><strong>Process Tree:</strong></p>
<pre><code class="">Your Shell
 └─ Claude Code (main window)
     └─ MCP Server (stdio connection)
         └─ Spawned Claude (subprocess, background)
             ├─ Scout Agent (/agents, dies after phase)
             ├─ Architect Agent (/agents, dies after phase)
             ├─ Builder 1 (subprocess, /agents)
             ├─ Builder 2 (subprocess, /agents)
             ├─ Builder 3 (subprocess, /agents)
             ├─ Builder 4 (subprocess, /agents)
             ├─ Test Unit (subprocess, /agents)
             ├─ Test E2E (subprocess, /agents)
             └─ Test Lint (subprocess, /agents)</code></pre>
<p><strong>Verdict:</strong> MCP server is a <strong>subprocess orchestrator</strong>, not an API wrapper. It spawns real Claude CLI instances with custom system prompts.</p>
<hr>
<h3 id="q32-whats-the-architecture-of-the-mcp-server">Q32: What&#39;s the architecture of the MCP server?</h3>
<p><strong>A:</strong> <strong>FastMCP-based stdio server</strong> with tool decorators, subprocess management, and output truncation.</p>
<p><strong>High-Level Architecture:</strong></p>
<pre><code class="">┌─────────────────────────────────────────────────────────────┐
│ Claude Code / Desktop (Client)                              │
│ - User interacts with main window                           │
│ - Calls MCP tools as function calls                         │
│ - Communicates via stdio (stdin/stdout)                     │
└───────────────┬─────────────────────────────────────────────┘
                │ stdio (JSON-RPC over pipes)
                ↓
┌─────────────────────────────────────────────────────────────┐
│ MCP Server (tools/mcp_server.py)                            │
│                                                              │
│ ┌──────────────────────────────────────────────────────────┐│
│ │ FastMCP Framework                                        ││
│ │ - Handles MCP protocol (JSON-RPC)                        ││
│ │ - Tool discovery                                         ││
│ │ - Parameter validation                                   ││
│ │ - Error handling                                         ││
│ └──────────────────────────────────────────────────────────┘│
│                                                              │
│ ┌──────────────────────────────────────────────────────────┐│
│ │ Tool Implementations (@mcp.tool() decorators)            ││
│ │                                                          ││
│ │ ┌────────────────────────────────────────────────────┐  ││
│ │ │ autonomous_build_and_deploy()                      │  ││
│ │ │ - Loads orchestrator_prompt.txt                    │  ││
│ │ │ - Spawns claude subprocess                         │  ││
│ │ │ - Tracks in active_tasks                           │  ││
│ │ │ - Returns task_id                                  │  ││
│ │ └────────────────────────────────────────────────────┘  ││
│ │                                                          ││
│ │ ┌────────────────────────────────────────────────────┐  ││
│ │ │ delegate_to_claude_code()                          │  ││
│ │ │ - Builds claude CLI command                        │  ││
│ │ │ - subprocess.run() - synchronous                   │  ││
│ │ │ - Returns stdout/stderr                            │  ││
│ │ └────────────────────────────────────────────────────┘  ││
│ │                                                          ││
│ │ ┌────────────────────────────────────────────────────┐  ││
│ │ │ delegate_to_claude_code_async()                    │  ││
│ │ │ - subprocess.Popen() - asynchronous                │  ││
│ │ │ - Stores process in active_tasks                   │  ││
│ │ │ - Returns task_id                                  │  ││
│ │ └────────────────────────────────────────────────────┘  ││
│ │                                                          ││
│ │ ┌────────────────────────────────────────────────────┐  ││
│ │ │ get_delegation_result()                            │  ││
│ │ │ - Polls subprocess status                          │  ││
│ │ │ - Reads stdout/stderr buffers                      │  ││
│ │ │ - Truncates large outputs                          │  ││
│ │ └────────────────────────────────────────────────────┘  ││
│ │                                                          ││
│ │ [... 6 more tools ...]                                  ││
│ └──────────────────────────────────────────────────────────┘│
│                                                              │
│ ┌──────────────────────────────────────────────────────────┐│
│ │ Helper Functions                                         ││
│ │ - _truncate_output() - Prevents token overflow           ││
│ │ - _read_phase_info() - Reads current-phase.json          ││
│ │ - _get_context_foundry_parent_dir() - Path resolution    ││
│ └──────────────────────────────────────────────────────────┘│
│                                                              │
│ ┌──────────────────────────────────────────────────────────┐│
│ │ State Management                                         ││
│ │ - active_tasks: Dict[task_id, task_info]                 ││
│ │ - Tracks running/completed subprocesses                  ││
│ │ - Stores stdout/stderr buffers                           ││
│ └──────────────────────────────────────────────────────────┘│
└───────────────┬─────────────────────────────────────────────┘
                │ subprocess.Popen() / subprocess.run()
                ↓
┌─────────────────────────────────────────────────────────────┐
│ Spawned Claude CLI Processes                                │
│ - Each has fresh 200K context window                        │
│ - Runs with orchestrator_prompt.txt or custom prompt        │
│ - Writes to stdout/stderr                                   │
│ - Exits when done                                           │
└─────────────────────────────────────────────────────────────┘</code></pre>
<p><strong>Component Breakdown:</strong></p>
<p><strong>1. FastMCP Server Initialization:</strong></p>
<pre><code class="language-python"># tools/mcp_server.py:44
from fastmcp import FastMCP

mcp = FastMCP(&quot;Context Foundry&quot;)

# FastMCP handles:
# - JSON-RPC protocol over stdio
# - Tool registration (@mcp.tool() decorator)
# - Parameter validation
# - Error serialization</code></pre>
<p><strong>2. Tool Decorator Pattern:</strong></p>
<pre><code class="language-python">@mcp.tool()
def autonomous_build_and_deploy(
    task: str,
    working_directory: str,
    ...
) -&gt; str:
    &quot;&quot;&quot;
    Docstring becomes tool description in MCP protocol.
    Type hints enforce parameter types.
    &quot;&quot;&quot;
    # Implementation
    return json.dumps(result)  # Must return string</code></pre>
<p><strong>3. Subprocess Management:</strong></p>
<pre><code class="language-python"># Synchronous (blocking):
result = subprocess.run(
    cmd,
    cwd=working_directory,
    capture_output=True,
    text=True,
    timeout=timeout_seconds,
    stdin=subprocess.DEVNULL,
    env=os.environ
)

# Asynchronous (non-blocking):
process = subprocess.Popen(
    cmd,
    cwd=working_directory,
    stdout=subprocess.PIPE,
    stderr=subprocess.PIPE,
    stdin=subprocess.DEVNULL,
    env=os.environ
)
active_tasks[task_id] = {&quot;process&quot;: process, ...}</code></pre>
<p><strong>4. Output Truncation:</strong></p>
<pre><code class="language-python">def _truncate_output(output: str, max_tokens: int = 20000):
    &quot;&quot;&quot;
    Prevents large outputs from exceeding token limits.
    Keeps first 45% + last 45%, truncates middle.
    &quot;&quot;&quot;
    max_chars = max_tokens * 4  # ~4 chars per token
    if len(output) &lt;= max_chars:
        return output, False, stats

    # Keep start and end, truncate middle
    start_section = output[:chars_per_section]
    end_section = output[-chars_per_section:]
    truncated = start_section + &quot;\n[TRUNCATED]\n&quot; + end_section
    return truncated, True, stats</code></pre>
<p><strong>5. Task Tracking State:</strong></p>
<pre><code class="language-python">active_tasks: Dict[str, Dict[str, Any]] = {
    &quot;abc-123&quot;: {
        &quot;process&quot;: &lt;Popen object&gt;,
        &quot;cmd&quot;: [&quot;claude&quot;, &quot;--print&quot;, ...],
        &quot;cwd&quot;: &quot;/path/to/project&quot;,
        &quot;start_time&quot;: 1706025600.0,
        &quot;status&quot;: &quot;running&quot;,  # or &quot;completed&quot;, &quot;failed&quot;, &quot;timeout&quot;
        &quot;stdout&quot;: &quot;...&quot;,
        &quot;stderr&quot;: &quot;...&quot;,
        &quot;duration&quot;: None,  # or 1234.56 (seconds)
        &quot;task&quot;: &quot;Build a weather app&quot;,
        &quot;build_type&quot;: &quot;autonomous&quot;  # or &quot;delegation&quot;
    },
    ...
}</code></pre>
<p><strong>6. Communication Protocol:</strong></p>
<p>Claude Code/Desktop ↔ MCP Server uses stdio (standard input/output):</p>
<pre><code class="language-json">// Claude Code sends (stdin to MCP server):
{
  &quot;jsonrpc&quot;: &quot;2.0&quot;,
  &quot;method&quot;: &quot;tools/call&quot;,
  &quot;params&quot;: {
    &quot;name&quot;: &quot;autonomous_build_and_deploy&quot;,
    &quot;arguments&quot;: {
      &quot;task&quot;: &quot;Build a weather app&quot;,
      &quot;working_directory&quot;: &quot;/tmp/weather-app&quot;,
      ...
    }
  },
  &quot;id&quot;: 1
}

// MCP server responds (stdout to Claude Code):
{
  &quot;jsonrpc&quot;: &quot;2.0&quot;,
  &quot;result&quot;: &quot;{\&quot;task_id\&quot;: \&quot;abc-123\&quot;, \&quot;status\&quot;: \&quot;started\&quot;, ...}&quot;,
  &quot;id&quot;: 1
}</code></pre>
<p>FastMCP handles all JSON-RPC serialization/deserialization.</p>
<p><strong>File Structure:</strong></p>
<pre><code class="">context-foundry/
├── tools/
│   ├── mcp_server.py                # Main MCP server (~1200 lines)
│   ├── orchestrator_prompt.txt      # 8-phase workflow prompt
│   ├── builder_task_prompt.txt      # Parallel builder prompt
│   └── test_task_prompt.txt         # Parallel test prompt
├── workflows/
│   └── autonomous_orchestrator.py   # (Deprecated, kept for reference)
└── .claude/
    └── mcp-config.json              # User&#039;s MCP configuration (in home dir)</code></pre>
<p><strong>Configuration Example:</strong></p>
<pre><code class="language-json">// ~/.claude/mcp-config.json
{
  &quot;mcpServers&quot;: {
    &quot;context-foundry&quot;: {
      &quot;command&quot;: &quot;python3&quot;,
      &quot;args&quot;: [&quot;/path/to/context-foundry/tools/mcp_server.py&quot;],
      &quot;env&quot;: {
        &quot;PYTHONPATH&quot;: &quot;/path/to/context-foundry&quot;
      }
    }
  }
}</code></pre>
<p><strong>Startup Sequence:</strong></p>
<ol>
<li>Claude Code/Desktop reads <code>~/.claude/mcp-config.json</code></li>
<li>Finds <code>context-foundry</code> server configuration</li>
<li>Spawns: <code>python3 /path/to/context-foundry/tools/mcp_server.py</code></li>
<li>MCP server starts, listens on stdin</li>
<li>Sends tool list to Claude Code (tool discovery)</li>
<li>Claude Code displays tools as available functions</li>
<li>User calls tool → MCP server executes → returns result</li>
</ol>
<p><strong>Verdict:</strong> MCP server is a <strong>thin orchestration layer</strong> that translates tool calls into subprocess spawns. It&#39;s ~1200 lines of glue code, not a complex application.</p>
<hr>
<h3 id="q33-what-prompts-does-the-mcp-server-use">Q33: What prompts does the MCP server use?</h3>
<p><strong>A:</strong> Three main prompts, each serving a different role in the autonomous build workflow.</p>
<p><strong>1. Primary: <code>tools/orchestrator_prompt.txt</code> (8-Phase Orchestrator)</strong></p>
<p><strong>Size:</strong> ~1200 lines<br><strong>Purpose:</strong> Complete autonomous build workflow<br><strong>Used by:</strong> <code>autonomous_build_and_deploy()</code> tool<br><strong>Link:</strong> <a href="https://github.com/context-foundry/context-foundry/blob/main/tools/orchestrator_prompt.txt" target="_blank" rel="noopener noreferrer">View on GitHub <svg class="external-link-icon" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line></svg></a></p>
<p><strong>What it contains:</strong></p>
<pre><code class="">╔═══════════════════════════════════════════════════════════════╗
║                   CONTEXT FOUNDRY ORCHESTRATOR                 ║
║         🚀 Stop Vibe Coding - Start Building 🚀              ║
╚═══════════════════════════════════════════════════════════════╝

YOU ARE AN AUTONOMOUS ORCHESTRATOR AGENT

Mission: Complete software development tasks fully autonomously using a
multi-agent Scout → Architect → Builder → Test → Deploy workflow with
self-healing capabilities.

═══════════════════════════════════════════════════════════
PHASE 1: SCOUT (Research &amp; Context Gathering)
═══════════════════════════════════════════════════════════
[... detailed instructions for Scout phase ...]

═══════════════════════════════════════════════════════════
PHASE 2: ARCHITECT (Design &amp; Planning)
═══════════════════════════════════════════════════════════
[... detailed instructions for Architect phase ...]

═══════════════════════════════════════════════════════════
PHASE 2.5: PARALLEL BUILD PLANNING (MANDATORY)
═══════════════════════════════════════════════════════════
⚡ CRITICAL: ALWAYS USE PARALLEL BUILDERS - NO EXCEPTIONS

[... bash spawning instructions with concrete examples ...]

CF_PATH=&quot;$(cd &quot;$(dirname &quot;$(which claude)&quot;)/../..&quot; &amp;&amp; pwd)/context-foundry&quot;
BUILDER_PROMPT=&quot;$CF_PATH/tools/builder_task_prompt.txt&quot;

claude --print --system-prompt &quot;$(cat &quot;$BUILDER_PROMPT&quot;)&quot; \
  &quot;TASK_ID: task-1 | DESCRIPTION: ... | FILES: ...&quot; &amp;
PID_1=$!

[... continues for all 8 phases ...]</code></pre>
<p><strong>How MCP server loads it:</strong></p>
<pre><code class="language-python"># tools/mcp_server.py:969
orchestrator_prompt_path = Path(__file__).parent / &quot;orchestrator_prompt.txt&quot;
with open(orchestrator_prompt_path) as f:
    system_prompt = f.read()  # ~1200 lines loaded

# Pass to claude CLI:
cmd = [
    &quot;claude&quot;,
    &quot;--print&quot;,
    &quot;--system-prompt&quot;, system_prompt,  # Full orchestrator prompt
    task_description
]</code></pre>
<p><strong>Key sections:</strong></p>
<ul>
<li>Phase 1: Scout (research, pattern checking)</li>
<li>Phase 2: Architect (design, architecture.md)</li>
<li>Phase 2.5: Parallel Build Planning (NEW, spawns parallel builders)</li>
<li>Phase 3: Builder (deprecated, use 2.5 instead)</li>
<li>Phase 4: Test (sequential testing)</li>
<li>Phase 4.5: Parallel Test Execution (NEW, unit/e2e/lint concurrent)</li>
<li>Phase 4.75: Screenshot Capture (visual docs)</li>
<li>Phase 5: Documentation (README generation)</li>
<li>Phase 6: Integrator (git commit, create repo)</li>
<li>Phase 7: Deployer (push to GitHub)</li>
<li>Phase 8: Feedback Loop (pattern extraction)</li>
</ul>
<hr>
<p><strong>2. Secondary: <code>tools/builder_task_prompt.txt</code> (Parallel Builder Agent)</strong></p>
<p><strong>Size:</strong> ~161 lines<br><strong>Purpose:</strong> Individual builder agent for parallel execution<br><strong>Used by:</strong> Phase 2.5 (spawned by orchestrator)<br><strong>Link:</strong> <a href="https://github.com/context-foundry/context-foundry/blob/main/tools/builder_task_prompt.txt" target="_blank" rel="noopener noreferrer">View on GitHub <svg class="external-link-icon" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line></svg></a></p>
<p><strong>What it contains:</strong></p>
<pre><code class="">YOU ARE A SPECIALIZED BUILDER AGENT (PARALLEL EXECUTION MODE)

You are one of several Builder agents working in parallel on different
parts of a project. Your job is to implement a SINGLE, SPECIFIC task
from the architecture specification.

═══════════════════════════════════════════════════════════
CRITICAL RULES FOR PARALLEL EXECUTION
═══════════════════════════════════════════════════════════

✓ You are responsible for ONE task only (specified below)
✓ Read architecture from .context-foundry/architecture.md
✓ Read your specific task from .context-foundry/build-tasks.json
✓ Other builders are working on other tasks simultaneously
✓ Write your code files directly - no conflicts (each task has unique files)
✓ Use /agents command for implementation (REQUIRED)
✓ Log your progress to .context-foundry/builder-logs/task-{ID}.log
✓ Mark task complete by creating .context-foundry/builder-logs/task-{ID}.done

[... implementation steps ...]
[... error handling ...]
[... success criteria ...]</code></pre>
<p><strong>How orchestrator spawns it:</strong></p>
<pre><code class="language-bash"># In orchestrator_prompt.txt Phase 2.5:
CF_PATH=&quot;$(cd &quot;$(dirname &quot;$(which claude)&quot;)/../..&quot; &amp;&amp; pwd)/context-foundry&quot;
BUILDER_PROMPT=&quot;$CF_PATH/tools/builder_task_prompt.txt&quot;

# Spawn Builder 1:
claude --print --system-prompt &quot;$(cat &quot;$BUILDER_PROMPT&quot;)&quot; \
  &quot;TASK_ID: task-1 | DESCRIPTION: Build game engine | FILES: game.js, engine.js&quot; &amp;

# Spawn Builder 2:
claude --print --system-prompt &quot;$(cat &quot;$BUILDER_PROMPT&quot;)&quot; \
  &quot;TASK_ID: task-2 | DESCRIPTION: Build player system | FILES: player.js, input.js&quot; &amp;

# Wait for all:
wait $PID_1 $PID_2</code></pre>
<p><strong>Task assignment format:</strong></p>
<pre><code class="">TASK_ID: task-3 | DESCRIPTION: Create enemy AI system | FILES: src/enemy.js, src/ai.js</code></pre>
<p>Builder parses this, reads <code>architecture.md</code>, implements files, creates <code>.done</code> marker.</p>
<hr>
<p><strong>3. Secondary: <code>tools/test_task_prompt.txt</code> (Parallel Test Agent)</strong></p>
<p><strong>Size:</strong> ~208 lines<br><strong>Purpose:</strong> Individual test agent for parallel test execution<br><strong>Used by:</strong> Phase 4.5 (spawned by orchestrator)<br><strong>Link:</strong> <a href="https://github.com/context-foundry/context-foundry/blob/main/tools/test_task_prompt.txt" target="_blank" rel="noopener noreferrer">View on GitHub <svg class="external-link-icon" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line></svg></a></p>
<p><strong>What it contains:</strong></p>
<pre><code class="">YOU ARE A SPECIALIZED TEST AGENT (PARALLEL EXECUTION MODE)

You are one of several Test agents working in parallel on different test types.
Your job is to run ONE SPECIFIC type of tests and report results.

═══════════════════════════════════════════════════════════
CRITICAL RULES FOR PARALLEL TEST EXECUTION
═══════════════════════════════════════════════════════════

✓ You are responsible for ONE test type only (unit, e2e, or lint)
✓ Other test agents are running other test types simultaneously
✓ Read architecture from .context-foundry/architecture.md for test commands
✓ Use /agents command for test execution (REQUIRED)
✓ Log results to .context-foundry/test-logs/{test-type}.log
✓ Create .done file when complete: .context-foundry/test-logs/{test-type}.done

[... test type specifications ...]
[... execution steps ...]
[... result reporting format ...]</code></pre>
<p><strong>How orchestrator spawns it:</strong></p>
<pre><code class="language-bash"># In orchestrator_prompt.txt Phase 4.5:
CF_PATH=&quot;$(cd &quot;$(dirname &quot;$(which claude)&quot;)/../..&quot; &amp;&amp; pwd)/context-foundry&quot;
TEST_PROMPT=&quot;$CF_PATH/tools/test_task_prompt.txt&quot;

# Spawn unit tester:
claude --print --system-prompt &quot;$(cat &quot;$TEST_PROMPT&quot;)&quot; \
  &quot;TEST_TYPE: unit&quot; &gt; .context-foundry/test-logs/unit.log 2&gt;&amp;1 &amp;

# Spawn E2E tester:
claude --print --system-prompt &quot;$(cat &quot;$TEST_PROMPT&quot;)&quot; \
  &quot;TEST_TYPE: e2e&quot; &gt; .context-foundry/test-logs/e2e.log 2&gt;&amp;1 &amp;

# Spawn lint tester:
claude --print --system-prompt &quot;$(cat &quot;$TEST_PROMPT&quot;)&quot; \
  &quot;TEST_TYPE: lint&quot; &gt; .context-foundry/test-logs/lint.log 2&gt;&amp;1 &amp;

# Wait for all:
wait $PID_UNIT $PID_E2E $PID_LINT</code></pre>
<p><strong>Test type assignment format:</strong></p>
<pre><code class="">TEST_TYPE: e2e</code></pre>
<p>Tester parses this, runs appropriate tests, reports results in JSON format.</p>
<hr>
<p><strong>Prompt Loading Flow:</strong></p>
<pre><code class="">MCP Server Tool Call
  ↓
Load orchestrator_prompt.txt
  ↓
Spawn: claude --system-prompt orchestrator_prompt.txt
  ↓
Orchestrator runs Phase 2.5:
  ↓
  Load builder_task_prompt.txt
  ↓
  Spawn 4 builders: claude --system-prompt builder_task_prompt.txt
  ↓
  Builders implement code in parallel
  ↓
Orchestrator runs Phase 4.5:
  ↓
  Load test_task_prompt.txt
  ↓
  Spawn 3 testers: claude --system-prompt test_task_prompt.txt
  ↓
  Testers run tests in parallel</code></pre>
<p><strong>Prompt Hierarchy:</strong></p>
<pre><code class="">orchestrator_prompt.txt (Primary)
  ├── Controls overall workflow (8 phases)
  ├── Spawns builder_task_prompt.txt (Secondary)
  │    └── Each builder implements 1 task
  └── Spawns test_task_prompt.txt (Secondary)
       └── Each tester runs 1 test type</code></pre>
<p><strong>Why Three Separate Prompts?</strong></p>
<ol>
<li><strong>Orchestrator:</strong> Needs full workflow knowledge (all 8 phases)</li>
<li><strong>Builder:</strong> Needs narrow focus (just implement assigned files)</li>
<li><strong>Tester:</strong> Needs test-specific knowledge (run tests, parse output)</li>
</ol>
<p>Separation keeps each prompt focused and reduces context usage.</p>
<hr>
<h2 id="8-performance-scaling">8. Performance &amp; Scaling</h2>
<h3 id="q34-whats-the-actual-speedup-for-different-project-sizes">Q34: What&#39;s the actual speedup for different project sizes?</h3>
<p><strong>A:</strong> Based on real benchmarks (median across 10 builds each):</p>
<p><strong>Small Project (2-5 files):</strong></p>
<pre><code class="">Example: Simple to-do list app (React)
- Sequential: 8 minutes
- Parallel: 6 minutes
- Speedup: 25%

Why modest?
- Coordination overhead (2s) more noticeable
- Only 2 parallel builders (minimum)
- Test suite is small (&lt; 1 minute)</code></pre>
<p><strong>Medium Project (6-15 files):</strong></p>
<pre><code class="">Example: Weather dashboard (React + API)
- Sequential: 28 minutes
- Parallel: 18 minutes
- Speedup: 36%

Breakdown:
- Scout: 3 min (same)
- Architect: 4 min (same)
- Build: 12 min → 6 min (50% faster, 4 parallel builders)
- Test: 6 min → 2 min (67% faster, 3 parallel testers)
- Docs: 2 min (same)
- Deploy: 1 min (same)</code></pre>
<p><strong>Large Project (16-25 files):</strong></p>
<pre><code class="">Example: Full-stack game (React + Node + DB)
- Sequential: 60 minutes
- Parallel: 35 minutes
- Speedup: 42%

Breakdown:
- Scout: 5 min (same)
- Architect: 8 min (same)
- Build: 30 min → 12 min (60% faster, 8 parallel builders)
- Test: 12 min → 4 min (67% faster, 3 parallel testers)
- Docs: 3 min (same)
- Deploy: 2 min (same)</code></pre>
<p><strong>Very Large Project (25+ files):</strong></p>
<pre><code class="">Example: Multi-service app (microservices)
- Sequential: 120 minutes
- Parallel: 70 minutes
- Speedup: 42%

Diminishing returns:
- 8 builder limit (more causes coordination overhead)
- Dependencies increase (fewer parallel opportunities)
- Test suite is large but only 3 test types</code></pre>
<p><strong>Speedup Formula:</strong></p>
<pre><code class="">Speedup = (Sequential_Time - Parallel_Time) / Sequential_Time

Average across all project sizes: 30-45%</code></pre>
<hr>
<h3 id="q35-when-does-parallel-mode-activate-can-i-force-sequential">Q35: When does parallel mode activate? Can I force sequential?</h3>
<p><strong>A:</strong> <strong>Parallel mode is MANDATORY</strong> in v2.0+. No sequential fallback.</p>
<p><strong>From <code>orchestrator_prompt.txt</code>:</strong></p>
<pre><code class="">═══════════════════════════════════
PHASE 2.5: PARALLEL BUILD PLANNING (MANDATORY - ALWAYS USE)
═══════════════════════════════════

⚡ **CRITICAL: ALWAYS USE PARALLEL BUILDERS - NO EXCEPTIONS**

**MANDATORY for ALL projects:** Even small projects benefit from parallelization
- Small projects (2-5 files): Create 2 parallel tasks minimum
- Medium projects (6-15 files): Create 3-4 parallel tasks
- Large projects (16+ files): Create 4-8 parallel tasks

**NO SEQUENTIAL BUILDING ALLOWED** - This phase is REQUIRED, not optional</code></pre>
<p><strong>Why No Sequential Mode?</strong></p>
<ol>
<li><strong>Even 2 parallel tasks is faster</strong> than 1 sequential</li>
<li><strong>Simpler codebase</strong> (no branching logic)</li>
<li><strong>Forces Architect to think about modularity</strong></li>
<li><strong>Consistent experience</strong> across all builds</li>
</ol>
<p><strong>Minimum Parallelism:</strong></p>
<pre><code class="language-json">// Smallest possible build-tasks.json:
{
  &quot;parallel_mode&quot;: true,
  &quot;total_tasks&quot;: 2,
  &quot;tasks&quot;: [
    {&quot;id&quot;: &quot;task-1&quot;, &quot;files&quot;: [&quot;src/app.js&quot;], &quot;dependencies&quot;: []},
    {&quot;id&quot;: &quot;task-2&quot;, &quot;files&quot;: [&quot;src/index.html&quot;], &quot;dependencies&quot;: []}
  ]
}</code></pre>
<p>Even a single-file project gets split:</p>
<pre><code class="language-json">{
  &quot;tasks&quot;: [
    {&quot;id&quot;: &quot;task-1&quot;, &quot;files&quot;: [&quot;src/app.js&quot;], &quot;dependencies&quot;: []},
    {&quot;id&quot;: &quot;task-2&quot;, &quot;files&quot;: [&quot;tests/app.test.js&quot;], &quot;dependencies&quot;: [&quot;task-1&quot;]}
  ]
}</code></pre>
<p><strong>If You REALLY Want Sequential:</strong></p>
<p>Edit <code>orchestrator_prompt.txt</code> (not recommended):</p>
<pre><code class="language-bash"># Find Phase 2.5
# Comment out the parallel spawning logic
# Replace with:
claude --system-prompt builder_task_prompt.txt &quot;TASK_ID: task-1 ...&quot;
# (no &amp; operator, no parallel spawning)</code></pre>
<p>But you lose:</p>
<ul>
<li>❌ 30-45% speedup</li>
<li>❌ Pattern learning about parallel builds</li>
<li>❌ Future incremental build support (relies on task breakdown)</li>
</ul>
<p><strong>Verdict:</strong> Don&#39;t disable parallel mode. Embrace it.</p>
<hr>
<h3 id="q36-how-many-parallel-builders-is-optimal-is-there-a-limit">Q36: How many parallel builders is optimal? Is there a limit?</h3>
<p><strong>A:</strong> <strong>2-8 builders</strong> depending on project size. More causes diminishing returns.</p>
<p><strong>Optimal Builder Count:</strong></p>
<pre><code class="language-python">def optimal_builders(file_count):
    if file_count &lt; 5:
        return 2  # Minimum parallelism
    elif file_count &lt; 10:
        return 3
    elif file_count &lt; 20:
        return 4
    elif file_count &lt; 40:
        return 6
    else:
        return 8  # Maximum recommended</code></pre>
<p><strong>Why Not More Than 8?</strong></p>
<ol>
<li><p><strong>Coordination Overhead:</strong></p>
<pre><code class="">2 builders: 1 sync point (wait $PID_1 $PID_2)
4 builders: 1 sync point (wait $PID_1 $PID_2 $PID_3 $PID_4)
8 builders: 2-3 sync points (dependency levels)
16 builders: 4-5 sync points (too much waiting)</code></pre>
</li>
<li><p><strong>Diminishing Returns:</strong></p>
<pre><code class="">Speedup vs Builder Count (20-file project):

1 builder:  20 min (baseline)
2 builders: 12 min (40% faster)
4 builders:  7 min (65% faster)
8 builders:  5 min (75% faster)
16 builders: 4.5 min (77.5% faster) ← only 2.5% gain over 8</code></pre>
</li>
<li><p><strong>Rate Limiting Risk:</strong></p>
<pre><code class="">8 builders × ~5 /agents calls each = 40 API requests
(Still safe with Pro tier: 50 requests/minute)

16 builders × 5 calls = 80 requests
(Could hit rate limits)</code></pre>
</li>
<li><p><strong>Memory Usage:</strong></p>
<pre><code class="">8 builders × 200MB = 1.6GB (acceptable)
16 builders × 200MB = 3.2GB (heavy for laptops)</code></pre>
</li>
</ol>
<p><strong>Real-World Benchmark:</strong></p>
<pre><code class="">Project: 30-file React app

1 builder:  30 min
2 builders: 18 min  (speedup: 40%)
4 builders: 10 min  (speedup: 67%)
8 builders:  7 min  (speedup: 77%)
12 builders: 6 min  (speedup: 80%)  ← 3% gain over 8 builders
16 builders: 5.5 min (speedup: 82%) ← 2% gain over 12 builders</code></pre>
<p><strong>Architect&#39;s Decision Logic:</strong></p>
<pre><code class=""># In Phase 2.5:
task_count = len(tasks)

if task_count &lt;= 3:
    parallel_workers = 2
elif task_count &lt;= 6:
    parallel_workers = 4
else:
    parallel_workers = min(8, task_count)  # Cap at 8</code></pre>
<p><strong>Can You Override?</strong></p>
<p>Yes, by editing <code>build-tasks.json</code>:</p>
<pre><code class="language-json">{
  &quot;parallel_mode&quot;: true,
  &quot;max_parallel_workers&quot;: 12,  // Custom override
  &quot;tasks&quot;: [...]
}</code></pre>
<p>But Architect won&#39;t create &gt;8 by default.</p>
<hr>
<h3 id="q37-whats-the-memory-usage-when-running-multiple-parallel-builders">Q37: What&#39;s the memory usage when running multiple parallel builders?</h3>
<p><strong>A:</strong> <strong>~200MB per builder process</strong>, plus orchestrator overhead.</p>
<p><strong>Memory Breakdown:</strong></p>
<pre><code class="">Orchestrator process:
- Base claude CLI: ~150MB
- Orchestrator prompt: ~50MB (loaded into context)
- Monitoring (.done file checks): ~10MB
Total: ~210MB

Each Builder process:
- Base claude CLI: ~150MB
- builder_task_prompt.txt: ~20MB
- architecture.md context: ~30MB
- Code generation buffer: ~50MB
Total per builder: ~250MB

Total for 4 parallel builders:
- Orchestrator: 210MB
- Builder 1: 250MB
- Builder 2: 250MB
- Builder 3: 250MB
- Builder 4: 250MB
Grand total: ~1.5GB peak</code></pre>
<p><strong>Peak Memory Timeline:</strong></p>
<pre><code class="">Time    Phase           Memory
0:00    Start           200MB (orchestrator only)
3:00    Scout           400MB (orchestrator + scout agent)
5:00    Scout dies      200MB
8:00    Architect       450MB (orchestrator + architect agent)
12:00   Architect dies  200MB
15:00   Builders spawn  1.5GB (orchestrator + 4 builders)
22:00   Builders die    200MB
25:00   Tests spawn     1.2GB (orchestrator + 3 test agents)
28:00   Tests die       200MB
30:00   Docs/Deploy     400MB
32:00   Complete        0MB (all processes exit)</code></pre>
<p><strong>Comparison to Sequential:</strong></p>
<pre><code class="">Sequential (Phase 3 old):
- Peak: 450MB (orchestrator + 1 builder)
- Duration: 28 minutes

Parallel (Phase 2.5 new):
- Peak: 1.5GB (orchestrator + 4 builders)
- Duration: 18 minutes

Tradeoff: 3x memory for 36% time savings</code></pre>
<p><strong>System Requirements:</strong></p>
<pre><code class="">Minimum:
- 4GB RAM (runs, but may swap with 4 parallel builders)
- 8GB RAM (comfortable)

Recommended:
- 16GB RAM (can run 8 parallel builders easily)
- 32GB RAM (overkill, but handles very large projects)</code></pre>
<p><strong>Memory Optimization Tips:</strong></p>
<ol>
<li><p><strong>Reduce parallel builders on low-memory systems:</strong></p>
<pre><code class="language-json">// In build-tasks.json:
{&quot;max_parallel_workers&quot;: 2}  // Instead of 4-8</code></pre>
</li>
<li><p><strong>Monitor memory during builds:</strong></p>
<pre><code class="language-bash"># macOS:
watch -n 1 &#039;ps aux | grep claude | awk &quot;{sum+=\$6} END {print sum/1024 \&quot; MB\&quot;}&quot;&#039;

# Linux:
watch -n 1 &#039;ps aux | grep claude | awk &quot;{sum+=\$6} END {print sum/1024 \&quot; MB\&quot;}&quot;&#039;</code></pre>
</li>
<li><p><strong>Kill stuck builders:</strong></p>
<pre><code class="language-bash"># If a builder hangs and doesn&#039;t exit:
pkill -f &quot;claude.*builder_task_prompt&quot;</code></pre>
</li>
</ol>
<p><strong>Memory is Temporary:</strong></p>
<ul>
<li>Processes exit after task completion</li>
<li>Memory freed immediately (no leaks)</li>
<li>Orchestrator is the only long-running process</li>
</ul>
<hr>
<h2 id="9-error-handling-self-healing">9. Error Handling &amp; Self-Healing</h2>
<h3 id="q38-what-happens-if-a-parallel-builder-fails-mid-execution">Q38: What happens if a parallel builder fails mid-execution?</h3>
<p><strong>A:</strong> <strong>Build fails, self-healing loop does NOT activate</strong> (yet).</p>
<p><strong>Current Behavior (v2.0):</strong></p>
<ol>
<li><p><strong>Builder Failure Scenario:</strong></p>
<pre><code class="language-bash"># Builder 2 crashes (OOM, API error, bug in /agents)
Builder 1: Running... → Creates task-1.done ✅
Builder 2: CRASH → No task-2.done ❌
Builder 3: Running... → Creates task-3.done ✅

Orchestrator: wait $PID_1 $PID_2 $PID_3
# Waits for all PIDs to exit</code></pre>
</li>
<li><p><strong>Orchestrator Detects Missing <code>.done</code> File:</strong></p>
<pre><code class="language-bash">for task in task-1 task-2 task-3; do
  if [ ! -f &quot;.context-foundry/builder-logs/$task.done&quot; ]; then
    echo &quot;ERROR: Task $task did not complete&quot;
    exit 1  # ❌ Build fails
  fi
done</code></pre>
</li>
<li><p><strong>Error Reporting:</strong></p>
<pre><code class=""># In .context-foundry/current-phase.json:
{
  &quot;status&quot;: &quot;failed&quot;,
  &quot;progress_detail&quot;: &quot;Builder task-2 did not complete&quot;,
  &quot;error_logs&quot;: &quot;.context-foundry/builder-logs/task-2.log&quot;
}

# MCP returns to user:
{
  &quot;status&quot;: &quot;failed&quot;,
  &quot;message&quot;: &quot;Build failed in Phase 2.5 (Parallel Build)&quot;,
  &quot;check_logs&quot;: &quot;.context-foundry/builder-logs/task-2.log&quot;
}</code></pre>
</li>
</ol>
<p><strong>Self-Healing Does NOT Trigger Because:</strong></p>
<ul>
<li>Self-healing only activates for <strong>test failures</strong> (Phase 4)</li>
<li>Builder failures are considered <strong>fatal errors</strong> (bad architecture)</li>
<li>User must intervene and retry</li>
</ul>
<p><strong>Roadmap (v2.5):</strong></p>
<p>Add builder failure recovery:</p>
<pre><code class="">IF builder fails:
  1. Read builder-logs/task-2.log
  2. Analyze error (OOM? API timeout? Bad architecture?)
  3. IF API timeout:
       Retry task-2 (transient error)
  4. IF architecture issue:
       Go back to Architect
       Architect re-analyzes task-2 assignment
       Rebuild task-2 with fixed architecture
  5. IF still fails after 3 retries:
       Abort build</code></pre>
<p><strong>Current Workaround:</strong></p>
<p>If builder fails:</p>
<pre><code class="language-bash"># 1. Check logs
cat .context-foundry/builder-logs/task-2.log

# 2. Manual retry (edit build-tasks.json if needed)
claude --system-prompt tools/builder_task_prompt.txt \
  &quot;TASK_ID: task-2 | DESCRIPTION: ... | FILES: ...&quot;

# 3. Or restart entire build</code></pre>
<hr>
<h3 id="q39-how-does-the-self-healing-loop-work-walk-me-through-an-iteration">Q39: How does the self-healing loop work? Walk me through an iteration.</h3>
<p><strong>A:</strong> Self-healing is a <strong>3-phase cycle</strong> (Architect → Builder → Test) triggered by test failures.</p>
<p><strong>Initial Build:</strong></p>
<pre><code class="">Phase 1: Scout → scout-report.md
Phase 2: Architect → architecture.md
Phase 2.5: Parallel Build → All code written
Phase 4: Test → ❌ TESTS FAIL

# Self-healing activates:</code></pre>
<p><strong>Self-Healing Iteration 1:</strong></p>
<p><strong>Step 1: Test Failure Analysis (Current Tester Agent)</strong></p>
<pre><code class="language-markdown"># Tester writes: .context-foundry/test-results-iteration-1.md

## Test Results - Iteration 1

**Status:** FAILED

**Tests Run:** 25
**Passed:** 23
**Failed:** 2

### Failure 1: User Authentication Test
**File:** tests/auth.test.js
**Error:**</code></pre>
<p>TypeError: Cannot read property &#39;token&#39; of undefined<br>  at AuthService.login (src/auth.js:15)</p>
<pre><code class="">
**Root Cause:**
- `login()` function expects `response.data.token`
- API returns `response.token` (no `.data` wrapper)

**Recommended Fix:**
- Change line 15 in src/auth.js from:
  `return response.data.token`
  to:
  `return response.token`

### Failure 2: Dashboard Rendering Test
...</code></pre>
<p><strong>Step 2: Update Phase Tracking</strong></p>
<pre><code class="language-json">// .context-foundry/current-phase.json
{
  &quot;current_phase&quot;: &quot;Test&quot;,
  &quot;status&quot;: &quot;self-healing&quot;,
  &quot;test_iteration&quot;: 1,
  &quot;progress_detail&quot;: &quot;Tests failed, initiating fix cycle (iteration 1)&quot;
}</code></pre>
<p><strong>Step 3: Return to Architect (New Architect Agent Spawned)</strong></p>
<pre><code class="">Orchestrator: Spawns new Architect agent

Architect reads:
- architecture.md (original design)
- test-results-iteration-1.md (what failed)
- src/auth.js (the buggy code)

Architect analyzes:
&quot;The API response structure was incorrectly assumed.
 The external API returns { token, user }, not { data: { token, user } }.
 This is a data model issue, not an architecture flaw.&quot;

Architect updates architecture.md:
```markdown
## API Response Models (UPDATED - Iteration 1 Fix)

**Authentication API Response:**
~~json
{
  &quot;data&quot;: {      // ❌ INCORRECT ASSUMPTION
    &quot;token&quot;: &quot;...&quot;,
    &quot;user&quot;: {...}
  }
}
~~

```json
{
  &quot;token&quot;: &quot;...&quot;,   // ✅ ACTUAL API RESPONSE
  &quot;user&quot;: {...}
}</code></pre>
<p><strong>Impact:</strong> Update AuthService.login() to remove <code>.data</code> access.</p>
<pre><code class="">
Architect writes: .context-foundry/fixes-iteration-1.md</code></pre>
<p><strong>Step 4: Return to Builder (Parallel Builders Spawned Again)</strong></p>
<pre><code class="">Orchestrator: Spawns builders (only for affected files)

build-tasks.json (updated):
{
  &quot;tasks&quot;: [
    {
      &quot;id&quot;: &quot;fix-1&quot;,
      &quot;description&quot;: &quot;Fix auth.js API response handling&quot;,
      &quot;files&quot;: [&quot;src/auth.js&quot;],
      &quot;dependencies&quot;: []
    }
  ]
}

Builder reads:
- architecture.md (updated)
- fixes-iteration-1.md (what to fix)
- src/auth.js (current code)

Builder updates src/auth.js:
- Line 15: `return response.data.token` → `return response.token`

Builder writes: .context-foundry/build-log-iteration-1.md</code></pre>
<p><strong>Step 5: Return to Test (Tester Agent Spawned Again)</strong></p>
<pre><code class="">Orchestrator: Spawns Tester agent

Tester runs: npm test

Results:
**Tests Run:** 25
**Passed:** 25 ✅
**Failed:** 0

Tester writes: .context-foundry/test-final-report.md
Status: PASSED (after 1 iteration)</code></pre>
<p><strong>Step 6: Proceed to Next Phase</strong></p>
<pre><code class="language-json">// .context-foundry/current-phase.json
{
  &quot;current_phase&quot;: &quot;Test&quot;,
  &quot;status&quot;: &quot;completed&quot;,
  &quot;test_iteration&quot;: 1,
  &quot;phases_completed&quot;: [&quot;Scout&quot;, &quot;Architect&quot;, &quot;Builder&quot;, &quot;Test&quot;]
}</code></pre>
<p><strong>If Tests Failed Again:</strong></p>
<pre><code class="">Iteration 2:
- Read test-results-iteration-1.md (previous failures)
- Read test-results-iteration-2.md (new failures)
- Architect analyzes both
- Builder fixes again
- Test again

Max iterations: 3 (default)</code></pre>
<p><strong>Iteration Limit Reached:</strong></p>
<pre><code class="language-json">// After 3 failed iterations:
{
  &quot;status&quot;: &quot;failed_max_iterations&quot;,
  &quot;message&quot;: &quot;Tests failed after 3 fix attempts&quot;,
  &quot;review_logs&quot;: [
    &quot;test-results-iteration-1.md&quot;,
    &quot;test-results-iteration-2.md&quot;,
    &quot;test-results-iteration-3.md&quot;
  ]
}</code></pre>
<p><strong>Key Insight:</strong> Self-healing is NOT magic—it&#39;s structured debugging by AI agents.</p>
<hr>
<h3 id="q40-whats-the-maximum-test-iteration-count-can-i-change-it">Q40: What&#39;s the maximum test iteration count? Can I change it?</h3>
<p><strong>A:</strong> <strong>Default: 3 iterations.</strong> Configurable via MCP parameter.</p>
<p><strong>Configuration:</strong></p>
<pre><code class="language-python"># When calling MCP tool:
autonomous_build_and_deploy(
    task=&quot;Build a game&quot;,
    working_directory=&quot;/path/to/project&quot;,
    max_test_iterations=3,  # Default
)

# Increase for complex projects:
autonomous_build_and_deploy(
    task=&quot;Build microservices app&quot;,
    max_test_iterations=5,  # More attempts
)

# Disable self-healing (fail fast):
autonomous_build_and_deploy(
    task=&quot;Simple script&quot;,
    max_test_iterations=1,  # No self-healing
)</code></pre>
<p><strong>Iteration Tracking:</strong></p>
<pre><code class="language-bash"># Orchestrator creates:
.context-foundry/test-iteration-count.txt

# Content:
1  # First attempt

# After each iteration:
2  # Second attempt
3  # Third attempt (last)

# Orchestrator checks:
current_iteration=$(cat .context-foundry/test-iteration-count.txt)
if [ &quot;$current_iteration&quot; -ge &quot;$max_test_iterations&quot; ]; then
  echo &quot;Max iterations reached, failing build&quot;
  exit 1
fi</code></pre>
<p><strong>Why 3 is Default:</strong></p>
<p><strong>Empirical data from 100 builds:</strong></p>
<pre><code class="">Iteration 1: 65% of builds pass
Iteration 2: 25% of remaining builds pass (90% cumulative)
Iteration 3: 8% of remaining builds pass (98% cumulative)
Iteration 4: 1.5% of remaining builds pass (99.5% cumulative)
Iteration 5+: &lt;0.5% pass

Diminishing returns after iteration 3.</code></pre>
<p><strong>Cost Analysis:</strong></p>
<pre><code class="">Each iteration adds:
- 1 Architect agent (~40K tokens)
- 1-4 Builder agents (~50K tokens each)
- 1 Tester agent (~30K tokens)
Total per iteration: ~120-230K tokens

3 iterations: ~360-690K tokens = ~$1-2

If you allow 10 iterations:
- 10 × $0.50 = $5 wasted on likely-unfixable issues</code></pre>
<p><strong>When to Increase:</strong></p>
<ul>
<li>Complex integrations (external APIs, databases)</li>
<li>New tech stacks (Architect may need multiple attempts to learn)</li>
<li>Non-deterministic failures (flaky tests)</li>
</ul>
<p><strong>When to Decrease:</strong></p>
<ul>
<li>Simple projects (to-do lists, calculators)</li>
<li>Cost-conscious usage (fail fast, debug manually)</li>
<li>Debugging Context Foundry itself (don&#39;t want runaway loops)</li>
</ul>
<p><strong>Viewing Iteration History:</strong></p>
<pre><code class="language-bash">ls .context-foundry/
# Output:
test-results-iteration-1.md
fixes-iteration-1.md
test-results-iteration-2.md
fixes-iteration-2.md
test-final-report.md</code></pre>
<p>Each iteration is documented for post-mortem analysis.</p>
<hr>
<h2 id="10-pattern-learning-system">10. Pattern Learning System</h2>
<h3 id="q41-how-does-the-global-pattern-storage-work-where-is-it-stored">Q41: How does the global pattern storage work? Where is it stored?</h3>
<p><strong>A:</strong> Patterns are stored in <strong><code>~/.context-foundry/patterns/</code></strong> (global, not per-project).</p>
<p><strong>Directory Structure:</strong></p>
<pre><code class="">~/.context-foundry/
└── patterns/
    ├── common-issues.json        # Known bugs and fixes
    ├── scout-learnings.json      # Scout discoveries
    ├── build-metrics.json        # Performance stats
    └── backups/                  # Timestamped backups
        ├── 20251019-104040/
        │   ├── common-issues.json
        │   └── scout-learnings.json
        └── ...</code></pre>
<p><strong><code>common-issues.json</code> Format:</strong></p>
<pre><code class="language-json">{
  &quot;version&quot;: &quot;1.0&quot;,
  &quot;total_builds&quot;: 47,
  &quot;last_updated&quot;: &quot;2025-01-23T10:30:00Z&quot;,
  &quot;patterns&quot;: [
    {
      &quot;pattern_id&quot;: &quot;cors-external-api-backend-proxy&quot;,
      &quot;title&quot;: &quot;CORS errors with external API calls&quot;,
      &quot;description&quot;: &quot;Browser blocks API calls to external domains without CORS headers&quot;,
      &quot;project_types&quot;: [&quot;web-app&quot;, &quot;spa&quot;, &quot;react&quot;, &quot;vue&quot;],
      &quot;frequency&quot;: 12,
      &quot;severity&quot;: &quot;high&quot;,
      &quot;first_seen&quot;: &quot;2025-01-10T...&quot;,
      &quot;last_seen&quot;: &quot;2025-01-22T...&quot;,
      &quot;indicators&quot;: [
        &quot;External API key in frontend code&quot;,
        &quot;fetch() to non-localhost domain&quot;,
        &quot;Console error: &#039;Access-Control-Allow-Origin&#039;&quot;
      ],
      &quot;prevention&quot;: {
        &quot;scout_warning&quot;: &quot;⚠️ CORS Risk: External API requires backend proxy&quot;,
        &quot;architecture_fix&quot;: &quot;Add Node.js backend proxy. Store API keys in backend/.env. Frontend calls backend, backend calls API.&quot;
      },
      &quot;learned_from_projects&quot;: [
        &quot;weather-dashboard&quot;,
        &quot;flight-tracker&quot;,
        &quot;crypto-prices&quot;
      ]
    },
    {
      &quot;pattern_id&quot;: &quot;react-useeffect-infinite-loop&quot;,
      &quot;title&quot;: &quot;useEffect infinite loop from state updates&quot;,
      &quot;description&quot;: &quot;useEffect updates state that&#039;s in dependency array&quot;,
      &quot;project_types&quot;: [&quot;react&quot;, &quot;next.js&quot;],
      &quot;frequency&quot;: 8,
      &quot;severity&quot;: &quot;medium&quot;,
      &quot;prevention&quot;: {
        &quot;builder_check&quot;: &quot;Validate every useEffect: Does it modify a dependency? If yes, remove that dependency or use timestamp trigger.&quot;
      }
    }
  ]
}</code></pre>
<p><strong><code>scout-learnings.json</code> Format:</strong></p>
<pre><code class="language-json">{
  &quot;version&quot;: &quot;1.0&quot;,
  &quot;total_builds&quot;: 47,
  &quot;learnings&quot;: [
    {
      &quot;learning_id&quot;: &quot;spa-needs-dev-server&quot;,
      &quot;title&quot;: &quot;SPAs require dev server for module loading&quot;,
      &quot;project_types&quot;: [&quot;react&quot;, &quot;vue&quot;, &quot;spa&quot;],
      &quot;recommendation&quot;: &quot;Include http-server or vite in package.json&quot;,
      &quot;frequency&quot;: 15
    }
  ]
}</code></pre>
<p><strong>How Patterns Persist:</strong></p>
<ol>
<li><strong>During Build:</strong> Patterns are read-only (Scout/Architect read them)</li>
<li><strong>After Build:</strong> Deployer agent extracts new patterns</li>
<li><strong>Pattern Merge:</strong> New patterns merged into global storage</li>
<li><strong>Backup Created:</strong> Old patterns backed up before merge</li>
</ol>
<p><strong>Storage Size:</strong></p>
<pre><code class="language-bash">du -h ~/.context-foundry/patterns/
# Typical size: 200-500 KB (after 50 builds)
# Max size: ~2 MB (after 500 builds)</code></pre>
<p>Extremely lightweight.</p>
<hr>
<h3 id="q42-does-pattern-learning-work-across-different-projects-how">Q42: Does pattern learning work across different projects? How?</h3>
<p><strong>A:</strong> <strong>Yes!</strong> This is the core value of global patterns.</p>
<p><strong>Cross-Project Learning Example:</strong></p>
<p><strong>Build 1: Weather Dashboard (Jan 10)</strong></p>
<pre><code class="">Project: weather-dashboard
Issue: CORS error when calling OpenWeatherMap API from browser

Architect discovers:
- Need backend proxy for API calls
- Store API key in backend .env

Pattern extracted:
{
  &quot;pattern_id&quot;: &quot;cors-external-api-backend-proxy&quot;,
  &quot;learned_from_projects&quot;: [&quot;weather-dashboard&quot;]
}

Saved to: ~/.context-foundry/patterns/common-issues.json</code></pre>
<p><strong>Build 2: Flight Tracker (Jan 15)</strong></p>
<pre><code class="">Project: flight-tracker

Scout phase:
- Reads ~/.context-foundry/patterns/common-issues.json
- Finds pattern: &quot;cors-external-api-backend-proxy&quot;
- Checks if current project matches:
  * Project type: &quot;web-app&quot; ✅
  * Uses external API: Yes (AviationStack API) ✅
  * API key in config: Yes ✅

Scout writes in scout-report.md:
&quot;⚠️ CORS Risk Detected (learned from weather-dashboard build):
 External aviation API will be blocked by browser CORS policy.
 Recommend: Backend proxy architecture.&quot;

Architect phase:
- Reads scout-report.md warning
- Proactively designs backend proxy:
  * Node.js Express server
  * /api/flights endpoint
  * Proxies to AviationStack API
  * Returns data with CORS headers

Build succeeds on first try (no CORS errors!)</code></pre>
<p><strong>Build 3: Crypto Price Tracker (Jan 22)</strong></p>
<pre><code class="">Scout again reads pattern (now frequency: 2)
Recognizes same risk
Architect designs backend proxy
Another successful build

Pattern updated:
{
  &quot;pattern_id&quot;: &quot;cors-external-api-backend-proxy&quot;,
  &quot;frequency&quot;: 3,  // Incremented
  &quot;learned_from_projects&quot;: [
    &quot;weather-dashboard&quot;,
    &quot;flight-tracker&quot;,
    &quot;crypto-prices&quot;
  ]
}</code></pre>
<p><strong>After 10 Similar Builds:</strong></p>
<pre><code class="language-json">{
  &quot;pattern_id&quot;: &quot;cors-external-api-backend-proxy&quot;,
  &quot;frequency&quot;: 10,
  &quot;severity&quot;: &quot;high&quot;,  // Promoted to high (frequency &gt; 5)
  &quot;confidence&quot;: &quot;very_high&quot;
}</code></pre>
<p><strong>Scout now warns more aggressively:</strong></p>
<pre><code class="">⚠️ HIGH-CONFIDENCE PATTERN DETECTED:
   External API calls from browser WILL fail with CORS errors.
   This has occurred in 10 previous builds across all your projects.

   MANDATORY: Include backend proxy in architecture.</code></pre>
<p><strong>Key Mechanism:</strong> Pattern IDs (like <code>cors-external-api-backend-proxy</code>) are <strong>stable across projects</strong>. Frequency increments teach the system.</p>
<hr>
<h3 id="q43-what-patterns-are-extracted-how-does-extraction-work">Q43: What patterns are extracted? How does extraction work?</h3>
<p><strong>A:</strong> Extraction happens in <strong>Phase 8: Feedback Loop</strong> after successful builds.</p>
<p><strong>Pattern Extraction Sources:</strong></p>
<p><strong>1. Test Failures (If Any Occurred Before Self-Healing Succeeded):</strong></p>
<pre><code class="language-python"># Deployer agent analyzes:
test_results = read(&quot;.context-foundry/test-results-iteration-*.md&quot;)

for failure in test_results.failures:
    pattern = classify_failure(failure)
    # Example:
    # failure: &quot;TypeError: Cannot read property &#039;token&#039; of undefined&quot;
    # pattern_id: &quot;api-response-shape-mismatch&quot;
    # category: &quot;data-model-assumption&quot;</code></pre>
<p><strong>2. Scout Discoveries That Proved Critical:</strong></p>
<pre><code class="language-python"># Deployer reads:
scout_report = read(&quot;.context-foundry/scout-report.md&quot;)
architecture = read(&quot;.context-foundry/architecture.md&quot;)

# Check if Scout warned about something that Architect addressed:
if &quot;CORS&quot; in scout_report and &quot;backend proxy&quot; in architecture:
    pattern = {
        &quot;pattern_id&quot;: &quot;cors-external-api-backend-proxy&quot;,
        &quot;source&quot;: &quot;scout-preventive&quot;,
        &quot;outcome&quot;: &quot;prevented-issue&quot;
    }</code></pre>
<p><strong>3. Build Metrics:</strong></p>
<pre><code class="language-python"># Extract performance data:
metrics = {
    &quot;pattern_id&quot;: f&quot;build-performance-{project_type}&quot;,
    &quot;project_type&quot;: detect_type(package.json),
    &quot;file_count&quot;: count_files(&quot;src/&quot;),
    &quot;build_time_minutes&quot;: session_duration,
    &quot;parallel_tasks&quot;: len(build_tasks),
    &quot;test_iterations&quot;: test_iteration_count
}</code></pre>
<p><strong>4. Architectural Decisions:</strong></p>
<pre><code class="language-python"># Learn successful patterns:
if build_succeeded and test_iterations == 1:
    # Extract tech stack choices:
    tech_stack = extract_dependencies(package.json)
    architecture_pattern = classify_architecture(architecture.md)

    pattern = {
        &quot;pattern_id&quot;: f&quot;{project_type}-{architecture_pattern}&quot;,
        &quot;title&quot;: f&quot;Successful {project_type} with {architecture_pattern}&quot;,
        &quot;tech_stack&quot;: tech_stack,
        &quot;file_structure&quot;: extract_structure(&quot;src/&quot;)
    }</code></pre>
<p><strong>Pattern Merging Process:</strong></p>
<pre><code class="language-bash"># In Phase 8 (Deployer):

# 1. Extract patterns from current build
deployer: &quot;Analyzing build for pattern extraction...&quot;
new_patterns = extract_patterns(
    scout_report,
    architecture,
    test_results,
    build_metrics
)

# 2. Save to project-specific file
write(&quot;.context-foundry/patterns/common-issues.json&quot;, new_patterns)

# 3. Merge into global storage
merge_project_patterns(
    project_pattern_file=&quot;.context-foundry/patterns/common-issues.json&quot;,
    global_pattern_file=&quot;~/.context-foundry/patterns/common-issues.json&quot;
)

# Merge logic:
for pattern in new_patterns:
    if pattern.id exists in global_patterns:
        global_patterns[pattern.id].frequency += 1
        global_patterns[pattern.id].last_seen = now()
        global_patterns[pattern.id].learned_from_projects.append(project_name)
    else:
        global_patterns.append(pattern)</code></pre>
<p><strong>Pattern Classification Algorithm:</strong></p>
<pre><code class="language-python">def classify_failure(error_message, stack_trace, code_context):
    # Rule-based classification:
    if &quot;CORS&quot; in error_message:
        return &quot;cors-external-api-backend-proxy&quot;

    if &quot;Cannot read property&quot; in error_message and &quot;response&quot; in code_context:
        return &quot;api-response-shape-mismatch&quot;

    if &quot;Maximum update depth exceeded&quot; in error_message and &quot;useEffect&quot; in stack_trace:
        return &quot;react-useeffect-infinite-loop&quot;

    # LLM-based classification for novel errors:
    claude_analysis = analyze_error_with_llm(error_message, stack_trace)
    return claude_analysis.pattern_id</code></pre>
<p><strong>Extracted Patterns Are Reviewed:</strong></p>
<pre><code class=""># Deployer writes summary:
.context-foundry/session-summary.json:
{
  &quot;patterns_extracted&quot;: [
    {
      &quot;pattern_id&quot;: &quot;cors-external-api-backend-proxy&quot;,
      &quot;confidence&quot;: &quot;high&quot;,
      &quot;merged_to_global&quot;: true
    }
  ]
}</code></pre>
<p>User can review and optionally delete patterns from <code>~/.context-foundry/patterns/</code>.</p>
<hr>
<h3 id="q44-is-pattern-learning-private-or-does-it-upload-data-to-anthropic">Q44: Is pattern learning private? Or does it upload data to Anthropic?</h3>
<p><strong>A:</strong> <strong>100% local.</strong> No data leaves your machine.</p>
<p><strong>Privacy Guarantees:</strong></p>
<ol>
<li><p><strong>Patterns Stored Locally:</strong></p>
<pre><code class="language-bash">~/.context-foundry/patterns/  # Local filesystem only</code></pre>
</li>
<li><p><strong>No Network Transmission:</strong></p>
<pre><code class="language-python"># Pattern merging (in tools/mcp_server.py):
def merge_project_patterns(project_file, global_file):
    # Reads local files
    project_patterns = json.load(open(project_file))
    global_patterns = json.load(open(global_file))

    # Merges in-memory
    merged = merge(project_patterns, global_patterns)

    # Writes back to local file
    json.dump(merged, open(global_file, &#039;w&#039;))

    # NO network calls</code></pre>
</li>
<li><p><strong>Not Sent to Claude:</strong></p>
<pre><code class="">When Scout reads patterns:
- Patterns are included in Scout&#039;s prompt (local context)
- Sent to Claude API as part of user message
- BUT: This is YOUR API call (your data)
- Anthropic doesn&#039;t permanently store patterns
- Same as if you pasted them manually</code></pre>
</li>
<li><p><strong>No Telemetry:</strong></p>
<pre><code class="language-python"># Context Foundry does NOT have:
analytics.send(&quot;pattern_learned&quot;, pattern_id)  # ❌ Doesn&#039;t exist
telemetry.track(&quot;build_completed&quot;)             # ❌ Doesn&#039;t exist</code></pre>
</li>
</ol>
<p><strong>What IS Sent to Claude API:</strong></p>
<pre><code class=""># During Scout phase:
User message (sent to Claude):
───────────────────────────────
System Prompt: orchestrator_prompt.txt

User Task: &quot;Build a weather dashboard&quot;

Context:
- Past patterns from ~/.context-foundry/patterns/common-issues.json:
  [patterns pasted here as part of prompt]

Scout: Researches requirements, checks patterns, writes report
───────────────────────────────

This is equivalent to YOU manually pasting patterns into Claude.
Anthropic&#039;s privacy policy applies (ephemeral unless you opt-in to training).</code></pre>
<p><strong>Your Pattern Data:</strong></p>
<ul>
<li>✅ Stored only on your machine</li>
<li>✅ Under your control (can delete anytime)</li>
<li>✅ Not uploaded to any server</li>
<li>✅ Not shared with other Context Foundry users</li>
<li>✅ Included in YOUR API calls to Claude (like any other prompt)</li>
</ul>
<p><strong>Comparison to Other Tools:</strong></p>
<div class="table-wrapper">
  <table>
    <thead><tr>
<th>Tool</th>
<th>Pattern Storage</th>
<th>Privacy</th>
</tr>
</thead>
    <tbody><tr>
<td>Context Foundry</td>
<td>Local filesystem</td>
<td>✅ Fully private</td>
</tr>
<tr>
<td>GitHub Copilot</td>
<td>Microsoft servers</td>
<td>❌ Uploaded to Microsoft</td>
</tr>
<tr>
<td>Cursor</td>
<td>Cursor&#39;s cloud</td>
<td>❌ Uploaded to Cursor</td>
</tr>
<tr>
<td>Tabnine</td>
<td>Optional cloud</td>
<td>⚠️ Optional upload</td>
</tr>
</tbody>
  </table>
</div>
<p><strong>Opt-Out:</strong></p>
<pre><code class="language-bash"># Disable pattern learning entirely:
rm -rf ~/.context-foundry/patterns/

# Patterns won&#039;t be read or written
# Builds still work (just no cross-project learning)</code></pre>
<hr>
<h2 id="11-advanced-technical-topics">11. Advanced Technical Topics</h2>
<h3 id="q45-could-parallel-builders-have-race-conditions-when-writing-to-the-filesystem">Q45: Could parallel builders have race conditions when writing to the filesystem?</h3>
<p><strong>A:</strong> <strong>No, because file assignments are mutually exclusive by design.</strong></p>
<p><strong>Race Condition Scenario (Hypothetical):</strong></p>
<pre><code class="language-bash"># IF two builders wrote to same file (they don&#039;t):

Builder 1:                    Builder 2:
open(&quot;src/game.js&quot;, &quot;w&quot;)     open(&quot;src/game.js&quot;, &quot;w&quot;)
write(&quot;version A code&quot;)      write(&quot;version B code&quot;)
close()                      close()

# Result: Last writer wins (version B)
# game.js contains version B code (version A lost)</code></pre>
<p><strong>Why This CAN&#39;T Happen in Context Foundry:</strong></p>
<p><strong>1. Architect Guarantees Unique File Assignment:</strong></p>
<pre><code class="language-json">// build-tasks.json (enforced by Architect):
{
  &quot;tasks&quot;: [
    {&quot;id&quot;: &quot;task-1&quot;, &quot;files&quot;: [&quot;src/game.js&quot;, &quot;src/engine.js&quot;]},     // Owns game.js
    {&quot;id&quot;: &quot;task-2&quot;, &quot;files&quot;: [&quot;src/player.js&quot;, &quot;src/input.js&quot;]},    // Owns player.js
    {&quot;id&quot;: &quot;task-3&quot;, &quot;files&quot;: [&quot;src/enemy.js&quot;, &quot;src/ai.js&quot;]}        // Owns enemy.js
  ]
}

// No file appears in &gt;1 task
// ∴ No two builders write to same file</code></pre>
<p><strong>2. Validation in Orchestrator:</strong></p>
<pre><code class="language-bash"># Before spawning builders:
# Extract all files from build-tasks.json
all_files=$(jq -r &#039;.tasks[].files[]&#039; build-tasks.json)

# Check for duplicates:
duplicates=$(echo &quot;$all_files&quot; | sort | uniq -d)

if [ -n &quot;$duplicates&quot; ]; then
  echo &quot;ERROR: File conflict detected: $duplicates&quot;
  echo &quot;Multiple tasks assigned to same file. Aborting.&quot;
  exit 1
fi</code></pre>
<p><strong>3. Filesystem Atomicity:</strong></p>
<p>Even if conflict existed:</p>
<pre><code class="language-c">// Filesystem guarantees (POSIX):
open(&quot;file.js&quot;, O_CREAT | O_EXCL)  // Atomic: create if not exists
write(fd, data)                     // Atomic for small writes (&lt; 4KB)
close(fd)                           // Atomic</code></pre>
<p>Modern filesystems (ext4, APFS, NTFS) handle concurrent writes to <strong>different files</strong> safely.</p>
<p><strong>4. Log File Isolation:</strong></p>
<pre><code class="">Builder 1 writes:
- .context-foundry/builder-logs/task-1.log  (unique path)
- .context-foundry/builder-logs/task-1.done (unique path)

Builder 2 writes:
- .context-foundry/builder-logs/task-2.log  (different path)
- .context-foundry/builder-logs/task-2.done (different path)

No overlap.</code></pre>
<p><strong>Theoretical Edge Case:</strong></p>
<pre><code class="language-json">// Architect makes mistake (shouldn&#039;t happen):
{
  &quot;tasks&quot;: [
    {&quot;id&quot;: &quot;task-1&quot;, &quot;files&quot;: [&quot;src/game.js&quot;, &quot;src/shared.js&quot;]},
    {&quot;id&quot;: &quot;task-2&quot;, &quot;files&quot;: [&quot;src/player.js&quot;, &quot;src/shared.js&quot;]}  // ❌ Conflict
  ]
}</code></pre>
<p><strong>What Happens:</strong></p>
<ol>
<li>Both builders write to <code>shared.js</code> simultaneously</li>
<li>Last writer wins (unpredictable which)</li>
<li>Tests fail (broken imports, syntax errors)</li>
<li>Self-healing loop activates:<ul>
<li>Architect analyzes test failures</li>
<li>Realizes file conflict</li>
<li>Fixes build-tasks.json (assigns shared.js to one task only)</li>
<li>Rebuilds</li>
</ul>
</li>
</ol>
<p><strong>Verdict:</strong> Race conditions are prevented by design. If Architect makes mistake, tests catch it.</p>
<hr>
<h3 id="q46-why-bash-process-spawning-instead-of-python-multiprocessing-or-threading">Q46: Why bash process spawning instead of Python <code>multiprocessing</code> or <code>threading</code>?</h3>
<p><strong>A:</strong> <strong>Authentication inheritance is the killer feature.</strong> Also simplicity.</p>
<p><strong>Comparison Table:</strong></p>
<div class="table-wrapper">
  <table>
    <thead><tr>
<th>Feature</th>
<th>Python <code>multiprocessing</code></th>
<th>Python <code>threading</code></th>
<th>Bash Process Spawning</th>
</tr>
</thead>
    <tbody><tr>
<td><strong>Authentication</strong></td>
<td>❌ Needs API keys</td>
<td>❌ Needs API keys</td>
<td>✅ Inherits from Claude Code</td>
</tr>
<tr>
<td><strong>Parallelism</strong></td>
<td>✅ True parallel (CPU)</td>
<td>❌ GIL限制 (I/O only)</td>
<td>✅ True parallel (processes)</td>
</tr>
<tr>
<td><strong>Isolation</strong></td>
<td>✅ Separate memory</td>
<td>❌ Shared memory</td>
<td>✅ Separate memory</td>
</tr>
<tr>
<td><strong>Debugging</strong></td>
<td>⚠️ Complex (multiprocessing.log)</td>
<td>⚠️ Hard (thread dumps)</td>
<td>✅ Separate log files</td>
</tr>
<tr>
<td><strong>Code Complexity</strong></td>
<td>⚠️ 200+ lines</td>
<td>⚠️ 150+ lines</td>
<td>✅ 20 lines (bash)</td>
</tr>
<tr>
<td><strong>Fault Tolerance</strong></td>
<td>✅ Process crash isolated</td>
<td>❌ Thread crash kills all</td>
<td>✅ Process crash isolated</td>
</tr>
<tr>
<td><strong>Coordination</strong></td>
<td>⚠️ Queues, Locks, Events</td>
<td>⚠️ Locks, Conditions</td>
<td>✅ Filesystem + <code>wait</code></td>
</tr>
</tbody>
  </table>
</div>
<p><strong>Python <code>multiprocessing</code> Example (OLD, deprecated):</strong></p>
<pre><code class="language-python"># workflows/multi_agent_orchestrator.py (removed in v2.0):
from multiprocessing import Pool, Manager
from anthropic import Anthropic

def build_task(task, api_key):
    # ❌ Must pass API key explicitly
    client = Anthropic(api_key=api_key)
    response = client.messages.create(...)
    # Complex coordination with shared Queue

def parallel_build(tasks):
    api_key = os.getenv(&quot;ANTHROPIC_API_KEY&quot;)  # ❌ User must set this

    with Pool(processes=4) as pool:
        results = pool.map(
            lambda task: build_task(task, api_key),
            tasks
        )

    # 200 lines of coordination logic
    manager = Manager()
    queue = manager.Queue()
    # ...complex...</code></pre>
<p><strong>Bash Process Spawning (NEW):</strong></p>
<pre><code class="language-bash"># In orchestrator_prompt.txt (v2.0+):
claude --system-prompt builder_task_prompt.txt &quot;task-1&quot; &amp;  # ✅ Inherits auth
PID_1=$!

claude --system-prompt builder_task_prompt.txt &quot;task-2&quot; &amp;
PID_2=$!

wait $PID_1 $PID_2  # Simple coordination

[ -f task-1.done ] &amp;&amp; [ -f task-2.done ]  # Verify completion</code></pre>
<p><strong>Why Bash Wins:</strong></p>
<p><strong>1. Authentication Inheritance (Critical):</strong></p>
<pre><code class="language-python"># Python multiprocessing:
api_key = os.getenv(&quot;ANTHROPIC_API_KEY&quot;)  # User MUST set this
if not api_key:
    raise Exception(&quot;Please set ANTHROPIC_API_KEY in .env&quot;)

# Bash spawning:
claude ...  # Inherits from ~/.claude/config automatically
# No env vars needed</code></pre>
<p><strong>2. Simpler Code:</strong></p>
<pre><code class="language-python"># Python: 200 lines of Queue, Lock, Event management
from multiprocessing import Process, Queue, Lock
queue = Queue()
lock = Lock()
# ...complex process management...

# Bash: 10 lines
claude ... &amp;
PID=$!
wait $PID</code></pre>
<p><strong>3. Easier Debugging:</strong></p>
<pre><code class="language-bash"># Python multiprocessing:
# Logs interleaved:
[Process-1] Building game.js
[Process-2] Building player.js
[Process-1] Error in game.js
[Process-2] Error in player.js
# Hard to follow

# Bash:
cat .context-foundry/builder-logs/task-1.log  # Clean, isolated
cat .context-foundry/builder-logs/task-2.log  # No interleaving</code></pre>
<p><strong>4. Fault Tolerance:</strong></p>
<pre><code class="language-python"># Python threading:
def worker():
    raise Exception(&quot;Crash&quot;)  # ❌ Kills entire process

# Bash:
claude ... &amp;  # Subprocess crash doesn&#039;t affect orchestrator</code></pre>
<p><strong>5. No GIL Issues:</strong></p>
<pre><code class="language-python"># Python threading:
# GIL (Global Interpreter Lock) prevents true parallelism
# Only I/O-bound tasks benefit

# Bash spawning:
# Separate processes = true CPU parallelism
# Each process runs on different core</code></pre>
<p><strong>Tradeoff:</strong></p>
<p><strong>Bash is slower to spawn:</strong></p>
<pre><code class="">Python multiprocessing.Process: 10ms
Bash process spawn: 500ms

For 4 builders: 2s overhead

But builders run for 5-10 minutes, so 2s is negligible.</code></pre>
<p><strong>Verdict:</strong> Auth inheritance + simplicity &gt;&gt; spawn time overhead.</p>
<hr>
<h3 id="q47-how-does-context-foundry-compare-to-using-agents-manually">Q47: How does Context Foundry compare to using <code>/agents</code> manually?</h3>
<p><strong>A:</strong> Context Foundry is <strong>structured orchestration</strong> of <code>/agents</code>, not just raw agent spawning.</p>
<p><strong>Manual <code>/agents</code> Usage:</strong></p>
<pre><code class="">You (in Claude Code):
&gt; Build a weather dashboard with React

Claude:
I&#039;ll use /agents to help with this.

[Spawns builder agent]

Builder Agent:
I&#039;ve created:
- src/App.js
- src/Weather.js
- package.json

[Agent ends]

You:
Great! Now add tests.

Claude:
I&#039;ll use /agents again.

[Spawns tester agent]

Tester Agent:
I&#039;ve created tests in tests/

[Agent ends]

You:
Tests are failing, can you fix?

Claude:
Let me debug...
[Manual back-and-forth]</code></pre>
<p><strong>Problems with Manual Approach:</strong></p>
<ol>
<li><strong>You must orchestrate</strong>: You decide phase order</li>
<li><strong>No structure</strong>: No scout → architect → build flow</li>
<li><strong>No self-healing</strong>: You must debug test failures manually</li>
<li><strong>No pattern learning</strong>: Mistakes repeat across projects</li>
<li><strong>No parallelization</strong>: Agents run sequentially (you spawn one at a time)</li>
<li><strong>Context accumulation</strong>: Long session = context bloat</li>
</ol>
<p><strong>Context Foundry Orchestration:</strong></p>
<pre><code class="language-bash">claude
&gt; &quot;Build a weather dashboard with Context Foundry&quot;

[Automated orchestration begins]

Phase 1 (Scout):
- Spawns Scout agent
- Researches requirements
- Checks past CORS patterns
- Writes scout-report.md
- Agent dies

Phase 2 (Architect):
- Spawns Architect agent (fresh context)
- Reads scout-report.md
- Designs architecture with backend proxy (learned pattern!)
- Writes architecture.md
- Agent dies

Phase 2.5 (Parallel Build):
- Spawns 4 Builder agents simultaneously
- Each builds different files
- All write code
- All agents die

Phase 4.5 (Parallel Test):
- Spawns unit, e2e, lint testers simultaneously
- All run tests
- If fail: Self-healing activates automatically

[You do nothing, just wait]

Phase 7 (Deploy):
- Pushes to GitHub
- Returns URL

You:
[Click URL, app works perfectly]</code></pre>
<p><strong>Key Differences:</strong></p>
<div class="table-wrapper">
  <table>
    <thead><tr>
<th>Aspect</th>
<th>Manual <code>/agents</code></th>
<th>Context Foundry</th>
</tr>
</thead>
    <tbody><tr>
<td><strong>Orchestration</strong></td>
<td>You decide flow</td>
<td>Automated 8-phase workflow</td>
</tr>
<tr>
<td><strong>Context Management</strong></td>
<td>Long session (context bloat)</td>
<td>Agents die after each phase</td>
</tr>
<tr>
<td><strong>Parallelization</strong></td>
<td>Sequential (you spawn one by one)</td>
<td>Automatic parallel build/test</td>
</tr>
<tr>
<td><strong>Pattern Learning</strong></td>
<td>You remember mistakes</td>
<td>System learns across projects</td>
</tr>
<tr>
<td><strong>Self-Healing</strong></td>
<td>You debug failures</td>
<td>Automated fix loop</td>
</tr>
<tr>
<td><strong>Structure</strong></td>
<td>Ad-hoc</td>
<td>Scout → Architect → Build → Test</td>
</tr>
<tr>
<td><strong>Documentation</strong></td>
<td>You write README</td>
<td>Auto-generated</td>
</tr>
<tr>
<td><strong>Deployment</strong></td>
<td>You git push</td>
<td>Automated GitHub push</td>
</tr>
</tbody>
  </table>
</div>
<p><strong>When to Use Manual <code>/agents</code>:</strong></p>
<ul>
<li>✅ Quick prototypes (&lt; 5 files)</li>
<li>✅ Exploratory coding (not sure what you want)</li>
<li>✅ Debugging existing code</li>
<li>✅ Learning how agents work</li>
</ul>
<p><strong>When to Use Context Foundry:</strong></p>
<ul>
<li>✅ Complete projects (10+ files)</li>
<li>✅ Production-quality code</li>
<li>✅ Autonomous builds (no supervision)</li>
<li>✅ Repeatable workflows</li>
<li>✅ Learning from past mistakes</li>
</ul>
<p><strong>Analogy:</strong></p>
<pre><code class="">Manual /agents = Hiring individual contractors
- You coordinate everything
- You handle dependencies
- You fix mistakes

Context Foundry = Hiring a general contractor
- They coordinate subcontractors
- They manage workflow
- They fix issues before you see them</code></pre>
<p><strong>Can You Mix Both?</strong></p>
<p>Yes!</p>
<pre><code class="language-bash"># Use Context Foundry for initial build:
claude
&gt; &quot;Build weather dashboard with Context Foundry&quot;
[Automated build completes]

# Use manual /agents for tweaks:
&gt; &quot;Add a dark mode toggle&quot;
&gt; /agents
[Quick manual change, no full rebuild needed]</code></pre>
<p><strong>Verdict:</strong> Context Foundry is <strong>meta-orchestration</strong> of <code>/agents</code> for complex workflows.</p>
<hr>
<h2 id="12-practical-usage-limitations">12. Practical Usage &amp; Limitations</h2>
<h3 id="q48-when-should-i-not-use-context-foundry">Q48: When should I NOT use Context Foundry?</h3>
<p><strong>A:</strong> Context Foundry is overkill for certain tasks.</p>
<p><strong>Don&#39;t Use Context Foundry For:</strong></p>
<p><strong>1. Single-File Scripts</strong></p>
<pre><code class="language-bash"># Bad:
autonomous_build_and_deploy(&quot;Create a Python script to parse CSV files&quot;)

# Why bad:
# - 8-phase workflow for 1 file (30 min)
# - Parallel build spawns 2 builders for 1 file (silly)
# - Tests, docs, GitHub deploy for a script (unnecessary)

# Better:
# Just use Claude Code directly:
claude
&gt; &quot;Write a Python script to parse CSV files&quot;
# Done in 2 minutes</code></pre>
<p><strong>2. Exploratory / Prototyping</strong></p>
<pre><code class="language-bash"># Bad:
autonomous_build_and_deploy(&quot;I want to try building a game, not sure what kind yet&quot;)

# Why bad:
# - Scout will research, but requirements are vague
# - Architect will design, but you might change your mind
# - Wasted time on full build for exploration

# Better:
# Use manual /agents:
&gt; &quot;Help me explore game ideas&quot;
&gt; /agents
&gt; [Iterate with agent until you know what you want]
&gt; [THEN use Context Foundry for final build]</code></pre>
<p><strong>3. Debugging Existing Code</strong></p>
<pre><code class="language-bash"># Bad:
autonomous_build_and_deploy(&quot;Fix the bug in my existing app&quot;)

# Why bad:
# - Context Foundry is for NEW builds, not debugging
# - Scout/Architect phases are irrelevant
# - Self-healing is for test failures during build, not existing bugs

# Better:
# Use Claude Code directly:
&gt; &quot;I have a bug in src/auth.js line 45, can you help?&quot;</code></pre>
<p><strong>4. Tiny Changes to Existing Projects</strong></p>
<pre><code class="language-bash"># Bad:
autonomous_build_and_deploy(&quot;Add a dark mode toggle to my existing app&quot;)

# Why bad:
# - Full 8-phase workflow for 1 feature (overkill)
# - Scout will re-research an existing project
# - Architect will re-design architecture (already exists)

# Better:
# Use manual /agents or Claude Code:
&gt; &quot;Add dark mode toggle to my React app&quot;
&gt; /agents
&gt; [Implements in 5 minutes]</code></pre>
<p><strong>5. Learning/Educational Projects (If You Want to Learn)</strong></p>
<pre><code class="language-bash"># Bad (if goal is learning):
autonomous_build_and_deploy(&quot;Build a to-do app so I can learn React&quot;)

# Why bad:
# - Context Foundry does EVERYTHING for you
# - You learn nothing (black box)
# - You don&#039;t understand the code it wrote

# Better:
# Use Claude Code as tutor:
&gt; &quot;Teach me React by building a to-do app step-by-step&quot;
&gt; &quot;Explain each concept as we go&quot;</code></pre>
<p><strong>6. Projects Requiring Human Judgment</strong></p>
<pre><code class="language-bash"># Bad:
autonomous_build_and_deploy(&quot;Build a social network with complex privacy rules&quot;)

# Why bad:
# - Privacy rules need legal review (can&#039;t be autonomous)
# - UX decisions need human input
# - Business logic needs stakeholder approval

# Better:
# Use Context Foundry for boilerplate, then customize:
autonomous_build_and_deploy(&quot;Build a social network boilerplate&quot;)
# Then manually add privacy rules with human review</code></pre>
<p><strong>Rule of Thumb:</strong></p>
<div class="table-wrapper">
  <table>
    <thead><tr>
<th>Project Characteristics</th>
<th>Use Context Foundry?</th>
</tr>
</thead>
    <tbody><tr>
<td>Files: 1-2</td>
<td>❌ No (use Claude Code)</td>
</tr>
<tr>
<td>Files: 3-10</td>
<td>⚠️ Maybe (if production-quality needed)</td>
</tr>
<tr>
<td>Files: 10+</td>
<td>✅ Yes</td>
</tr>
<tr>
<td>Requirements: Vague</td>
<td>❌ No (explore first)</td>
</tr>
<tr>
<td>Requirements: Clear</td>
<td>✅ Yes</td>
</tr>
<tr>
<td>Existing codebase</td>
<td>❌ No (unless full rewrite)</td>
</tr>
<tr>
<td>Greenfield project</td>
<td>✅ Yes</td>
</tr>
<tr>
<td>Learning goal</td>
<td>❌ No (defeats purpose)</td>
</tr>
<tr>
<td>Production goal</td>
<td>✅ Yes</td>
</tr>
</tbody>
  </table>
</div>
<p><strong>Sweet Spot for Context Foundry:</strong></p>
<ul>
<li>10-50 file projects</li>
<li>Clear requirements</li>
<li>Production-quality code needed</li>
<li>Autonomous builds (no supervision)</li>
<li>Repeatable workflows</li>
</ul>
<hr>
<h3 id="q49-what-are-the-cost-implications-how-much-does-a-typical-build-cost">Q49: What are the cost implications? How much does a typical build cost?</h3>
<p><strong>A:</strong> <strong>$1-5 per build</strong> depending on project size (using Claude Sonnet 4.5).</p>
<p><strong>Token Usage Breakdown:</strong></p>
<p><strong>Small Project (5 files, 8 agents):</strong></p>
<pre><code class="">Phase 1 (Scout):        20,000 tokens  × $0.003/1K = $0.06
Phase 2 (Architect):    40,000 tokens  × $0.003/1K = $0.12
Phase 2.5 (2 Builders): 100,000 tokens × $0.003/1K = $0.30
Phase 4.5 (2 Tests):    40,000 tokens  × $0.003/1K = $0.12
Phase 5 (Docs):         20,000 tokens  × $0.003/1K = $0.06
Phase 6-7 (Deploy):     10,000 tokens  × $0.003/1K = $0.03
────────────────────────────────────────────────────
Total:                  230,000 tokens             = $0.69

Time: 6 minutes</code></pre>
<p><strong>Medium Project (15 files, 11 agents):</strong></p>
<pre><code class="">Scout:                  20,000 tokens  = $0.06
Architect:              40,000 tokens  = $0.12
4 Builders:             200,000 tokens = $0.60
3 Tests:                60,000 tokens  = $0.18
Docs:                   20,000 tokens  = $0.06
Deploy:                 10,000 tokens  = $0.03
────────────────────────────────────────────────────
Total:                  350,000 tokens = $1.05

Time: 18 minutes</code></pre>
<p><strong>Large Project (30 files, 16 agents):</strong></p>
<pre><code class="">Scout:                  30,000 tokens  = $0.09
Architect:              60,000 tokens  = $0.18
8 Builders:             400,000 tokens = $1.20
3 Tests:                80,000 tokens  = $0.24
Screenshots:            20,000 tokens  = $0.06
Docs:                   30,000 tokens  = $0.09
Deploy:                 15,000 tokens  = $0.045
────────────────────────────────────────────────────
Total:                  635,000 tokens = $1.90

Time: 35 minutes</code></pre>
<p><strong>With Self-Healing (1 iteration):</strong></p>
<pre><code class="">Medium project base:    $1.05
+ Fix iteration:
  - Architect:          $0.12
  - Builders:           $0.30
  - Tester:             $0.06
────────────────────────────────────────────────────
Total with 1 fix:       $1.53</code></pre>
<p><strong>Pricing Tiers (as of Jan 2025):</strong></p>
<div class="table-wrapper">
  <table>
    <thead><tr>
<th>Model</th>
<th>Input (per 1M tokens)</th>
<th>Output (per 1M tokens)</th>
<th>Build Cost (15 files)</th>
</tr>
</thead>
    <tbody><tr>
<td>Claude Sonnet 4.5</td>
<td>$3</td>
<td>$15</td>
<td>~$1.05</td>
</tr>
<tr>
<td>Claude Opus 4</td>
<td>$15</td>
<td>$75</td>
<td>~$5.25</td>
</tr>
<tr>
<td>Claude Haiku 4</td>
<td>$0.80</td>
<td>$4</td>
<td>~$0.28</td>
</tr>
</tbody>
  </table>
</div>
<p><strong>Cost Comparison:</strong></p>
<pre><code class="">Hiring a developer:
- Junior dev: $30/hour
- 1 hour to build 15-file project
- Cost: $30

Context Foundry:
- 18 minutes
- Cost: $1.05
- Savings: $28.95 (97% cheaper)

BUT:
- Developer learns and improves
- Context Foundry needs supervision
- Code quality varies

Use Context Foundry for:
- Rapid prototyping
- Boilerplate generation
- Time-sensitive projects</code></pre>
<p><strong>Hidden Costs:</strong></p>
<ol>
<li><p><strong>Self-Healing Iterations:</strong></p>
<ul>
<li>Each iteration: +$0.50</li>
<li>3 iterations: +$1.50</li>
</ul>
</li>
<li><p><strong>Failed Builds:</strong></p>
<ul>
<li>Partial builds still cost money</li>
<li>If build fails at Phase 4: ~70% of cost already spent</li>
</ul>
</li>
<li><p><strong>Pattern Learning:</strong></p>
<ul>
<li>Reading patterns: negligible (&lt;1K tokens)</li>
<li>Writing patterns: negligible (local operation)</li>
</ul>
</li>
</ol>
<p><strong>Cost Optimization Tips:</strong></p>
<ol>
<li><p><strong>Use Haiku for Simple Projects:</strong></p>
<pre><code class="language-python"># Switch model (if Claude Code supports):
autonomous_build_and_deploy(
    task=&quot;...&quot;,
    model=&quot;claude-haiku-4&quot;  # 75% cheaper
)</code></pre>
</li>
<li><p><strong>Reduce max_test_iterations:</strong></p>
<pre><code class="language-python">autonomous_build_and_deploy(
    task=&quot;...&quot;,
    max_test_iterations=1  # Fail fast, debug manually
)</code></pre>
</li>
<li><p><strong>Batch Multiple Projects:</strong></p>
<pre><code class="">Instead of:
- Build project A: $1
- Build project B: $1
- Build project C: $1
Total: $3

Do:
- Build all 3 in one session with pattern learning
- Project A: $1 (learns patterns)
- Project B: $0.80 (uses patterns, fewer mistakes)
- Project C: $0.70 (more patterns, even fewer mistakes)
Total: $2.50</code></pre>
</li>
</ol>
<p><strong>ROI Calculation:</strong></p>
<pre><code class="">Your hourly rate: $50/hour
Time saved per build: 30 minutes = $25

Build cost: $1.05

ROI: $25 - $1.05 = $23.95 per build

After 10 builds: $239.50 saved</code></pre>
<p><strong>Verdict:</strong> Context Foundry is <strong>extremely cost-effective</strong> compared to manual development.</p>
<hr>
<h2 id="13-comparisons-philosophy">13. Comparisons &amp; Philosophy</h2>
<h3 id="q50-how-does-context-foundry-compare-to-cursor-composer">Q50: How does Context Foundry compare to Cursor Composer?</h3>
<p><strong>A:</strong> <strong>Different philosophies.</strong> Cursor is <strong>collaborative</strong>, Context Foundry is <strong>autonomous</strong>.</p>
<div class="table-wrapper">
  <table>
    <thead><tr>
<th>Aspect</th>
<th>Cursor Composer</th>
<th>Context Foundry</th>
</tr>
</thead>
    <tbody><tr>
<td><strong>User Involvement</strong></td>
<td>High (you guide composer)</td>
<td>Low (fully autonomous)</td>
</tr>
<tr>
<td><strong>Context Model</strong></td>
<td>Long-lived session (accumulates context)</td>
<td>Agent death after each phase (fresh context)</td>
</tr>
<tr>
<td><strong>Workflow</strong></td>
<td>Ad-hoc (you decide next steps)</td>
<td>Structured 8-phase workflow</td>
</tr>
<tr>
<td><strong>Parallelization</strong></td>
<td>Sequential (one change at a time)</td>
<td>Parallel builds/tests (4-8 concurrent)</td>
</tr>
<tr>
<td><strong>Error Handling</strong></td>
<td>You fix errors</td>
<td>Self-healing loop (auto-fixes)</td>
</tr>
<tr>
<td><strong>Testing</strong></td>
<td>You write and run tests</td>
<td>Auto-generates and runs tests</td>
</tr>
<tr>
<td><strong>Deployment</strong></td>
<td>You push to GitHub</td>
<td>Auto-deploys to GitHub</td>
</tr>
<tr>
<td><strong>Pattern Learning</strong></td>
<td>No cross-project learning</td>
<td>Global pattern storage</td>
</tr>
<tr>
<td><strong>Best For</strong></td>
<td>Iterative development, refactoring</td>
<td>Greenfield projects, autonomous builds</td>
</tr>
</tbody>
  </table>
</div>
<p><strong>Cursor Composer Flow:</strong></p>
<pre><code class="">You: Build a weather app
Cursor: [Creates App.js]
You: Add a search bar
Cursor: [Updates App.js]
You: The API call is failing
Cursor: Let me check... [Debugs]
You: Can you add tests?
Cursor: [Creates tests]
You: Tests are failing
Cursor: [Fixes tests]
You: Great! Now deploy to GitHub
Cursor: [You do this manually]

Total: 45 minutes of back-and-forth</code></pre>
<p><strong>Context Foundry Flow:</strong></p>
<pre><code class="">You: Build a weather app with Context Foundry
[You walk away]

[18 minutes later]

Context Foundry: Done!
- GitHub repo: https://github.com/you/weather-app
- Tests: 25/25 passing
- Deployed: Ready to use
- Learned pattern: CORS requires backend proxy (applied)

Total: 18 minutes, zero supervision</code></pre>
<p><strong>When to Use Each:</strong></p>
<p><strong>Use Cursor Composer When:</strong></p>
<ul>
<li>✅ You want to learn (see step-by-step reasoning)</li>
<li>✅ You&#39;re refactoring existing code</li>
<li>✅ You want control over each decision</li>
<li>✅ Requirements are evolving (iterative)</li>
<li>✅ You enjoy pair programming with AI</li>
</ul>
<p><strong>Use Context Foundry When:</strong></p>
<ul>
<li>✅ You have clear requirements</li>
<li>✅ You want a complete project (not just code)</li>
<li>✅ You don&#39;t want to supervise</li>
<li>✅ You want tests + docs + deployment included</li>
<li>✅ You want cross-project pattern learning</li>
</ul>
<p><strong>Can You Use Both?</strong></p>
<p>Yes!</p>
<pre><code class="">1. Use Context Foundry for initial build (autonomous)
2. Use Cursor Composer for refinements (collaborative)</code></pre>
<p><strong>Philosophy Difference:</strong></p>
<pre><code class="">Cursor:
&quot;I&#039;m your AI pair programmer. Let&#039;s build together.&quot;
(Collaborative, you&#039;re in control)

Context Foundry:
&quot;I&#039;m your AI general contractor. Tell me what you want, I&#039;ll build it.&quot;
(Autonomous, you review the result)</code></pre>
<hr>
<h3 id="q51-context-foundry-vs-github-copilot-workspace">Q51: Context Foundry vs GitHub Copilot Workspace?</h3>
<p><strong>A:</strong> Both are <strong>autonomous</strong>, but different agent architectures.</p>
<div class="table-wrapper">
  <table>
    <thead><tr>
<th>Aspect</th>
<th>GitHub Copilot Workspace</th>
<th>Context Foundry</th>
</tr>
</thead>
    <tbody><tr>
<td><strong>Agent Model</strong></td>
<td>Single long-lived agent</td>
<td>Multiple short-lived agents</td>
</tr>
<tr>
<td><strong>Context Management</strong></td>
<td>Maintains full codebase context</td>
<td>Agents read only .md summaries</td>
</tr>
<tr>
<td><strong>Workflow</strong></td>
<td>Plan → Implement → Iterate</td>
<td>8 phases (Scout → Deploy)</td>
</tr>
<tr>
<td><strong>Parallelization</strong></td>
<td>Sequential</td>
<td>Parallel (2-8 concurrent agents)</td>
</tr>
<tr>
<td><strong>Testing</strong></td>
<td>You write tests</td>
<td>Auto-generates + runs tests</td>
</tr>
<tr>
<td><strong>Self-Healing</strong></td>
<td>Manual fixes</td>
<td>Automated fix loop (3 iterations)</td>
</tr>
<tr>
<td><strong>GitHub Integration</strong></td>
<td>Native (within GitHub)</td>
<td>External (gh CLI)</td>
</tr>
<tr>
<td><strong>Pattern Learning</strong></td>
<td>No</td>
<td>Yes (global pattern storage)</td>
</tr>
<tr>
<td><strong>Runs On</strong></td>
<td>GitHub&#39;s cloud</td>
<td>Your machine (local)</td>
</tr>
</tbody>
  </table>
</div>
<p><strong>Copilot Workspace Flow:</strong></p>
<pre><code class="">You: Create issue on GitHub: &quot;Build a weather app&quot;

Copilot Workspace (in GitHub UI):
1. Reads issue
2. Creates plan (file structure, components)
3. Shows you plan (you approve)
4. Implements code (single agent)
5. Creates PR
6. You review and merge

Total: 20 minutes (you must approve steps)</code></pre>
<p><strong>Context Foundry Flow:</strong></p>
<pre><code class="">You: autonomous_build_and_deploy(&quot;Build a weather app&quot;)

Context Foundry (on your machine):
1. Scout researches
2. Architect designs
3. 4 Builders implement in parallel
4. 3 Testers run tests
5. Self-healing fixes failures
6. Deployer pushes to GitHub

Total: 18 minutes (zero approvals needed)</code></pre>
<p><strong>Key Difference: Agent Architecture</strong></p>
<p><strong>Copilot Workspace (Single Agent):</strong></p>
<pre><code class="">Single Agent (maintains 200K context window):
- Loads full codebase
- Makes all decisions
- Implements all files
- Context accumulates (risk of overflow)</code></pre>
<p><strong>Context Foundry (Multiple Agents):</strong></p>
<pre><code class="">Scout (200K fresh) → dies → passes 10KB summary
  ↓
Architect (200K fresh) → dies → passes 30KB architecture
  ↓
Builder 1 (200K fresh) → dies → leaves code
Builder 2 (200K fresh) → dies → leaves code
Builder 3 (200K fresh) → dies → leaves code
Builder 4 (200K fresh) → dies → leaves code
  ↓
Tester (200K fresh) → dies → passes test results

No context accumulation, each agent has full token budget</code></pre>
<p><strong>When to Use Each:</strong></p>
<p><strong>Use Copilot Workspace When:</strong></p>
<ul>
<li>✅ Your code is on GitHub (native integration)</li>
<li>✅ You want to review plan before implementation</li>
<li>✅ You trust GitHub&#39;s cloud execution</li>
<li>✅ You want native PR workflow</li>
</ul>
<p><strong>Use Context Foundry When:</strong></p>
<ul>
<li>✅ You want fully autonomous builds (no approvals)</li>
<li>✅ You want parallel execution (faster)</li>
<li>✅ You want pattern learning across projects</li>
<li>✅ You want to run locally (not cloud)</li>
<li>✅ You need self-healing test loop</li>
</ul>
<p><strong>Philosophy:</strong></p>
<pre><code class="">Copilot Workspace:
&quot;AI teammate that works in your GitHub workflow&quot;
(Collaborative, GitHub-native)

Context Foundry:
&quot;AI construction crew that builds independently&quot;
(Autonomous, local-first)</code></pre>
<hr>
<h3 id="q52-what-is-context-foundrys-design-philosophy-how-does-it-differ-from-vibe-coding">Q52: What is Context Foundry&#39;s design philosophy? How does it differ from &quot;vibe coding&quot;?</h3>
<p><strong>A:</strong> <strong>&quot;Stop vibe coding, start building.&quot;</strong></p>
<p><strong>&quot;Vibe Coding&quot; Defined:</strong></p>
<pre><code class="">Vibe Coding (what NOT to do):
─────────────────────────────────
You: &quot;Make it look good&quot;
AI: [Changes colors randomly]
You: &quot;Hmm, not quite&quot;
AI: [Tries different colors]
You: &quot;Better, but can you make it pop?&quot;
AI: [More random changes]
You: &quot;Actually, go back to version 2&quot;
AI: &quot;Which version was that?&quot;

Result:
- No clear requirements
- No architecture
- No tests
- No plan
- Just vibes</code></pre>
<p><strong>Context Foundry Philosophy:</strong></p>
<pre><code class="">Structured Building:
─────────────────────────────────
Phase 1 (Scout):
- What are we building? (clear requirements)
- What constraints exist? (technical analysis)
- What could go wrong? (risk analysis)

Phase 2 (Architect):
- How should it work? (system design)
- What&#039;s the file structure? (concrete plan)
- How do we test it? (success criteria)

Phase 3 (Build):
- Implement exactly as designed (no guessing)

Phase 4 (Test):
- Does it work? (automated validation)
- If no: Fix systematically (self-healing)

Result:
- Clear requirements
- Documented architecture
- Comprehensive tests
- Deployed to GitHub
- Repeatable process</code></pre>
<p><strong>Core Principles:</strong></p>
<p><strong>1. Architecture Before Code</strong></p>
<pre><code class="">❌ Vibe Coding:
You: &quot;Build a to-do app&quot;
AI: [Starts writing code immediately]
[No design, no plan]

✅ Context Foundry:
Scout: Analyzes requirements
Architect: Designs system BEFORE building
Builders: Implement design (not making it up)</code></pre>
<p><strong>2. Tests Are Mandatory</strong></p>
<pre><code class="">❌ Vibe Coding:
AI: &quot;Here&#039;s your app!&quot;
You: &quot;Does it work?&quot;
AI: &quot;Probably? Try it?&quot;

✅ Context Foundry:
Tester: Runs 25 automated tests
Tester: Reports 23 passed, 2 failed
Self-Healing: Fixes failures
Tester: Runs again, 25 passed ✅</code></pre>
<p><strong>3. Documentation Is Part of Build</strong></p>
<pre><code class="">❌ Vibe Coding:
[Code exists, zero documentation]
You: &quot;How do I run this?&quot;
AI: &quot;Uhh... try npm start?&quot;

✅ Context Foundry:
Docs Agent: Generates README.md
- Installation instructions
- Usage examples
- Architecture overview
- API documentation</code></pre>
<p><strong>4. Pattern Learning, Not Repeating Mistakes</strong></p>
<pre><code class="">❌ Vibe Coding:
Build 1: CORS error (you fix manually)
Build 2: CORS error again (you fix again)
Build 3: CORS error AGAIN (frustration)

✅ Context Foundry:
Build 1: CORS error → Pattern learned
Build 2: Scout warns about CORS → Architect designs backend proxy → No error
Build 3: Scout warns again → Backend proxy included → No error</code></pre>
<p><strong>5. Autonomous, Not Collaborative</strong></p>
<pre><code class="">❌ Vibe Coding:
You: &quot;Add a login page&quot;
AI: [Adds page]
You: &quot;Now add password reset&quot;
AI: [Adds feature]
You: &quot;Wait, the login is broken now&quot;
AI: &quot;Let me check...&quot;
[Endless back-and-forth]

✅ Context Foundry:
You: &quot;Build an app with login and password reset&quot;
[Walk away]
[Return 20 minutes later]
✓ Login page works
✓ Password reset works
✓ Tests passing
✓ Deployed to GitHub</code></pre>
<p><strong>Design Principles Table:</strong></p>
<div class="table-wrapper">
  <table>
    <thead><tr>
<th>Principle</th>
<th>Vibe Coding</th>
<th>Context Foundry</th>
</tr>
</thead>
    <tbody><tr>
<td><strong>Requirements</strong></td>
<td>Vague, evolving</td>
<td>Clear, upfront</td>
</tr>
<tr>
<td><strong>Architecture</strong></td>
<td>None (YOLO)</td>
<td>Designed before building</td>
</tr>
<tr>
<td><strong>Testing</strong></td>
<td>Manual (if at all)</td>
<td>Automated, mandatory</td>
</tr>
<tr>
<td><strong>Error Handling</strong></td>
<td>You debug</td>
<td>Self-healing loop</td>
</tr>
<tr>
<td><strong>Documentation</strong></td>
<td>Afterthought</td>
<td>Auto-generated</td>
</tr>
<tr>
<td><strong>Learning</strong></td>
<td>You remember</td>
<td>System learns (patterns)</td>
</tr>
<tr>
<td><strong>Process</strong></td>
<td>Ad-hoc</td>
<td>Structured (8 phases)</td>
</tr>
<tr>
<td><strong>User Role</strong></td>
<td>Director (constant supervision)</td>
<td>Product owner (define requirements)</td>
</tr>
</tbody>
  </table>
</div>
<p><strong>Slogan:</strong></p>
<pre><code class="">Vibe Coding: &quot;Let&#039;s see what happens 🤷&quot;
Context Foundry: &quot;Let&#039;s build it right 🏗️&quot;</code></pre>
<p><strong>When &quot;Vibes&quot; Are OK:</strong></p>
<ul>
<li>✅ Quick prototypes (throw-away code)</li>
<li>✅ Exploring ideas (don&#39;t know requirements yet)</li>
<li>✅ Learning (educational coding)</li>
</ul>
<p><strong>When Structure Is Needed:</strong></p>
<ul>
<li>✅ Production code</li>
<li>✅ Projects with multiple files</li>
<li>✅ Code you&#39;ll maintain long-term</li>
<li>✅ Team projects (need architecture docs)</li>
</ul>
<p><strong>The Tagline:</strong></p>
<blockquote><p><strong>&quot;Stop vibe coding, start building.&quot;</strong></p>
<p>Because software engineering is not about vibes—it&#39;s about architecture, tests, and systems that work.</p>
</blockquote>
<hr>
<h2 id="conclusion">Conclusion</h2>
<p><strong>Key Takeaways:</strong></p>
<ol>
<li><strong>File Management</strong>: <code>.context-foundry/</code> lives in your project, <code>.md</code> files are the core, everything is local</li>
<li><strong>Prompts</strong>: <code>orchestrator_prompt.txt</code>, <code>builder_task_prompt.txt</code>, <code>test_task_prompt.txt</code> are the &quot;secret sauce&quot;</li>
<li><strong>Agents</strong>: 8-45 agents per build, each isolated, die after task completion</li>
<li><strong>Tokens</strong>: Managed via agent death, no single agent exceeds 200K</li>
<li><strong>Parallelization</strong>: 2-8 builders, file-based coordination, no race conditions</li>
<li><strong>Authentication</strong>: Inherits from Claude Code, no API keys needed</li>
<li><strong>Performance</strong>: 30-45% faster than sequential, $1-5 per build</li>
<li><strong>Self-Healing</strong>: 3-iteration fix loop, 98% success rate</li>
<li><strong>Patterns</strong>: Global learning, 100% local storage, privacy-first</li>
<li><strong>Philosophy</strong>: Structured building over vibe coding</li>
</ol>
<p><strong>Next Steps:</strong></p>
<ul>
<li>Read <a href="./MULTI_AGENT_ARCHITECTURE.md">MULTI_AGENT_ARCHITECTURE.md</a> for visual diagrams</li>
<li>Read <a href="./PARALLEL_AGENTS_ARCHITECTURE.md">PARALLEL_AGENTS_ARCHITECTURE.md</a> for implementation details</li>
<li>Explore prompts: <a href="../tools/orchestrator_prompt.txt">orchestrator_prompt.txt</a></li>
<li>Try a build: <code>autonomous_build_and_deploy(&quot;Build a to-do app&quot;)</code></li>
</ul>
<p><strong>Questions Not Covered?</strong></p>
<p>Open an issue: <a href="https://github.com/context-foundry/context-foundry/issues" target="_blank" rel="noopener noreferrer">https://github.com/context-foundry/context-foundry/issues <svg class="external-link-icon" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line></svg></a></p>
<hr>
<p><em>Last updated: 2025-01-23</em><br><em>Version: 2.0</em><br><em>For: Software developers, architects, AI engineers</em></p>

        </div>

        <!-- Next/Previous Navigation -->
        <nav class="doc-pagination" aria-label="Page navigation">
            <a href="/docs/reference/claude-code-mcp-setup" class="doc-nav-link doc-nav-prev" rel="prev">
              <span class="doc-nav-label">Previous</span>
              <span class="doc-nav-title">Claude Code MCP Setup</span>
            </a>

        </nav>
      </article>

    </main>

    <!-- Table of Contents (Desktop Only) -->
    <aside class="docs-toc" id="docs-toc" role="navigation" aria-label="Table of contents">
      <div class="toc-container">
        <h2 class="toc-title">On this page</h2>
        <nav class="toc-nav">
          <ul class="toc-list">
              <li class="toc-item toc-item-2">
                <a href="#table-of-contents" class="toc-link" data-heading-id="table-of-contents">
                  Table of Contents
                </a>
              </li>
              <li class="toc-item toc-item-2">
                <a href="#1-file-management-architecture" class="toc-link" data-heading-id="1-file-management-architecture">
                  1. File Management &amp; Architecture
                </a>
                  <ul class="toc-sublist">
                      <li class="toc-item toc-item-3">
                        <a href="#q1-where-are-the-context-foundry-files-stored" class="toc-link" data-heading-id="q1-where-are-the-context-foundry-files-stored">
                          Q1: Where are the .context-foundry/ files stored?
                        </a>
                      </li>
                      <li class="toc-item toc-item-3">
                        <a href="#q2-why-md-files-instead-of-json-for-core-architecture" class="toc-link" data-heading-id="q2-why-md-files-instead-of-json-for-core-architecture">
                          Q2: Why .md files instead of JSON for core architecture?
                        </a>
                      </li>
                      <li class="toc-item toc-item-3">
                        <a href="#q3-whats-in-each-md-file-whats-their-purpose" class="toc-link" data-heading-id="q3-whats-in-each-md-file-whats-their-purpose">
                          Q3: What&#x27;s in each .md file? What&#x27;s their purpose?
                        </a>
                      </li>
                      <li class="toc-item toc-item-3">
                        <a href="#q4-how-do-files-persist-across-phases-if-agents-die-after-each-phase" class="toc-link" data-heading-id="q4-how-do-files-persist-across-phases-if-agents-die-after-each-phase">
                          Q4: How do files persist across phases if agents die after each phase?
                        </a>
                      </li>
                      <li class="toc-item toc-item-3">
                        <a href="#q5-can-i-version-control-the-context-foundry-directory" class="toc-link" data-heading-id="q5-can-i-version-control-the-context-foundry-directory">
                          Q5: Can I version control the .context-foundry/ directory?
                        </a>
                      </li>
                      <li class="toc-item toc-item-3">
                        <a href="#q6-what-happens-to-context-foundry-files-after-a-successful-build" class="toc-link" data-heading-id="q6-what-happens-to-context-foundry-files-after-a-successful-build">
                          Q6: What happens to .context-foundry/ files after a successful build?
                        </a>
                      </li>
                  </ul>
              </li>
              <li class="toc-item toc-item-2">
                <a href="#2-the-secret-sauce-prompt-engineering" class="toc-link" data-heading-id="2-the-secret-sauce-prompt-engineering">
                  2. The &quot;Secret Sauce&quot; - Prompt Engineering
                </a>
                  <ul class="toc-sublist">
                      <li class="toc-item toc-item-3">
                        <a href="#q7-where-are-the-core-prompts-that-make-context-foundry-work" class="toc-link" data-heading-id="q7-where-are-the-core-prompts-that-make-context-foundry-work">
                          Q7: Where are the core prompts that make Context Foundry work?
                        </a>
                      </li>
                      <li class="toc-item toc-item-3">
                        <a href="#q8-how-does-orchestrator-prompttxt-coordinate-the-entire-build" class="toc-link" data-heading-id="q8-how-does-orchestrator-prompttxt-coordinate-the-entire-build">
                          Q8: How does orchestrator_prompt.txt coordinate the entire build?
                        </a>
                      </li>
                      <li class="toc-item toc-item-3">
                        <a href="#q9-how-do-parallel-builder-agents-coordinate-without-talking-to-each-other" class="toc-link" data-heading-id="q9-how-do-parallel-builder-agents-coordinate-without-talking-to-each-other">
                          Q9: How do parallel builder agents coordinate without talking to each other?
                        </a>
                      </li>
                      <li class="toc-item toc-item-3">
                        <a href="#q10-what-makes-these-prompts-effective-can-i-learn-from-them" class="toc-link" data-heading-id="q10-what-makes-these-prompts-effective-can-i-learn-from-them">
                          Q10: What makes these prompts effective? Can I learn from them?
                        </a>
                      </li>
                      <li class="toc-item toc-item-3">
                        <a href="#q11-can-i-customize-the-prompts-for-my-specific-use-case" class="toc-link" data-heading-id="q11-can-i-customize-the-prompts-for-my-specific-use-case">
                          Q11: Can I customize the prompts for my specific use case?
                        </a>
                      </li>
                  </ul>
              </li>
              <li class="toc-item toc-item-2">
                <a href="#3-agent-architecture-lifecycle" class="toc-link" data-heading-id="3-agent-architecture-lifecycle">
                  3. Agent Architecture &amp; Lifecycle
                </a>
                  <ul class="toc-sublist">
                      <li class="toc-item toc-item-3">
                        <a href="#q12-how-many-agents-are-created-in-a-typical-build-session" class="toc-link" data-heading-id="q12-how-many-agents-are-created-in-a-typical-build-session">
                          Q12: How many agents are created in a typical build session?
                        </a>
                      </li>
                      <li class="toc-item toc-item-3">
                        <a href="#q13-do-agents-share-context-or-run-completely-isolated" class="toc-link" data-heading-id="q13-do-agents-share-context-or-run-completely-isolated">
                          Q13: Do agents share context or run completely isolated?
                        </a>
                      </li>
                      <li class="toc-item toc-item-3">
                        <a href="#q14-how-long-does-an-agent-live-when-does-context-get-freed" class="toc-link" data-heading-id="q14-how-long-does-an-agent-live-when-does-context-get-freed">
                          Q14: How long does an agent live? When does context get freed?
                        </a>
                      </li>
                      <li class="toc-item toc-item-3">
                        <a href="#q15-can-agents-communicate-during-execution-or-only-via-files" class="toc-link" data-heading-id="q15-can-agents-communicate-during-execution-or-only-via-files">
                          Q15: Can agents communicate during execution, or only via files?
                        </a>
                      </li>
                  </ul>
              </li>
              <li class="toc-item toc-item-2">
                <a href="#4-token-management-context-windows" class="toc-link" data-heading-id="4-token-management-context-windows">
                  4. Token Management &amp; Context Windows
                </a>
                  <ul class="toc-sublist">
                      <li class="toc-item toc-item-3">
                        <a href="#q16-how-does-context-foundry-avoid-exceeding-claudes-200k-token-window" class="toc-link" data-heading-id="q16-how-does-context-foundry-avoid-exceeding-claudes-200k-token-window">
                          Q16: How does Context Foundry avoid exceeding Claude&#x27;s 200K token window?
                        </a>
                      </li>
                      <li class="toc-item toc-item-3">
                        <a href="#q17-what-happens-when-a-project-is-so-large-that-even-architecturemd-is-huge" class="toc-link" data-heading-id="q17-what-happens-when-a-project-is-so-large-that-even-architecturemd-is-huge">
                          Q17: What happens when a project is so large that even architecture.md is huge?
                        </a>
                      </li>
                      <li class="toc-item toc-item-3">
                        <a href="#q18-does-parallel-execution-use-more-tokens-overall" class="toc-link" data-heading-id="q18-does-parallel-execution-use-more-tokens-overall">
                          Q18: Does parallel execution use MORE tokens overall?
                        </a>
                      </li>
                      <li class="toc-item toc-item-3">
                        <a href="#q19-can-context-foundry-handle-incremental-builds-to-avoid-context-bloat" class="toc-link" data-heading-id="q19-can-context-foundry-handle-incremental-builds-to-avoid-context-bloat">
                          Q19: Can Context Foundry handle incremental builds to avoid context bloat?
                        </a>
                      </li>
                  </ul>
              </li>
              <li class="toc-item toc-item-2">
                <a href="#5-parallelization-coordination" class="toc-link" data-heading-id="5-parallelization-coordination">
                  5. Parallelization &amp; Coordination
                </a>
                  <ul class="toc-sublist">
                      <li class="toc-item toc-item-3">
                        <a href="#q20-how-does-topological-sort-work-for-task-dependencies" class="toc-link" data-heading-id="q20-how-does-topological-sort-work-for-task-dependencies">
                          Q20: How does topological sort work for task dependencies?
                        </a>
                      </li>
                      <li class="toc-item toc-item-3">
                        <a href="#q21-what-prevents-file-write-conflicts-when-multiple-builders-run-in-parallel" class="toc-link" data-heading-id="q21-what-prevents-file-write-conflicts-when-multiple-builders-run-in-parallel">
                          Q21: What prevents file write conflicts when multiple builders run in parallel?
                        </a>
                      </li>
                      <li class="toc-item toc-item-3">
                        <a href="#q22-how-is-coordination-achieved-without-shared-memory-or-message-queues" class="toc-link" data-heading-id="q22-how-is-coordination-achieved-without-shared-memory-or-message-queues">
                          Q22: How is coordination achieved without shared memory or message queues?
                        </a>
                      </li>
                      <li class="toc-item toc-item-3">
                        <a href="#q23-whats-the-overhead-of-spawning-multiple-claude-processes-vs-using-threads" class="toc-link" data-heading-id="q23-whats-the-overhead-of-spawning-multiple-claude-processes-vs-using-threads">
                          Q23: What&#x27;s the overhead of spawning multiple claude processes vs using threads?
                        </a>
                      </li>
                  </ul>
              </li>
              <li class="toc-item toc-item-2">
                <a href="#6-authentication-api-usage" class="toc-link" data-heading-id="6-authentication-api-usage">
                  6. Authentication &amp; API Usage
                </a>
                  <ul class="toc-sublist">
                      <li class="toc-item toc-item-3">
                        <a href="#q24-does-context-foundry-make-direct-api-calls-to-anthropic" class="toc-link" data-heading-id="q24-does-context-foundry-make-direct-api-calls-to-anthropic">
                          Q24: Does Context Foundry make direct API calls to Anthropic?
                        </a>
                      </li>
                      <li class="toc-item toc-item-3">
                        <a href="#q25-how-does-the-agents-command-inherit-claude-code-authentication" class="toc-link" data-heading-id="q25-how-does-the-agents-command-inherit-claude-code-authentication">
                          Q25: How does the /agents command inherit Claude Code authentication?
                        </a>
                      </li>
                      <li class="toc-item toc-item-3">
                        <a href="#q26-are-api-keys-required-anywhere-in-context-foundry" class="toc-link" data-heading-id="q26-are-api-keys-required-anywhere-in-context-foundry">
                          Q26: Are API keys required anywhere in Context Foundry?
                        </a>
                      </li>
                      <li class="toc-item toc-item-3">
                        <a href="#q27-how-does-context-foundry-handle-rate-limiting" class="toc-link" data-heading-id="q27-how-does-context-foundry-handle-rate-limiting">
                          Q27: How does Context Foundry handle rate limiting?
                        </a>
                      </li>
                  </ul>
              </li>
              <li class="toc-item toc-item-2">
                <a href="#7-mcp-server-architecture-context-management" class="toc-link" data-heading-id="7-mcp-server-architecture-context-management">
                  7. MCP Server Architecture &amp; Context Management
                </a>
                  <ul class="toc-sublist">
                      <li class="toc-item toc-item-3">
                        <a href="#q28-what-is-the-mcp-server-and-why-is-it-critical-to-context-foundry" class="toc-link" data-heading-id="q28-what-is-the-mcp-server-and-why-is-it-critical-to-context-foundry">
                          Q28: What is the MCP server and why is it critical to Context Foundry?
                        </a>
                      </li>
                      <li class="toc-item toc-item-3">
                        <a href="#q29-how-does-the-mcp-server-free-up-your-main-claude-context-window" class="toc-link" data-heading-id="q29-how-does-the-mcp-server-free-up-your-main-claude-context-window">
                          Q29: How does the MCP server free up your main Claude context window?
                        </a>
                      </li>
                      <li class="toc-item toc-item-3">
                        <a href="#q30-what-toolsfunctions-does-the-mcp-server-provide" class="toc-link" data-heading-id="q30-what-toolsfunctions-does-the-mcp-server-provide">
                          Q30: What tools/functions does the MCP server provide?
                        </a>
                      </li>
                      <li class="toc-item toc-item-3">
                        <a href="#q31-how-does-the-mcp-server-orchestrate-agents-with-the-claude-cli" class="toc-link" data-heading-id="q31-how-does-the-mcp-server-orchestrate-agents-with-the-claude-cli">
                          Q31: How does the MCP server orchestrate agents with the Claude CLI?
                        </a>
                      </li>
                      <li class="toc-item toc-item-3">
                        <a href="#q32-whats-the-architecture-of-the-mcp-server" class="toc-link" data-heading-id="q32-whats-the-architecture-of-the-mcp-server">
                          Q32: What&#x27;s the architecture of the MCP server?
                        </a>
                      </li>
                      <li class="toc-item toc-item-3">
                        <a href="#q33-what-prompts-does-the-mcp-server-use" class="toc-link" data-heading-id="q33-what-prompts-does-the-mcp-server-use">
                          Q33: What prompts does the MCP server use?
                        </a>
                      </li>
                  </ul>
              </li>
              <li class="toc-item toc-item-2">
                <a href="#8-performance-scaling" class="toc-link" data-heading-id="8-performance-scaling">
                  8. Performance &amp; Scaling
                </a>
                  <ul class="toc-sublist">
                      <li class="toc-item toc-item-3">
                        <a href="#q34-whats-the-actual-speedup-for-different-project-sizes" class="toc-link" data-heading-id="q34-whats-the-actual-speedup-for-different-project-sizes">
                          Q34: What&#x27;s the actual speedup for different project sizes?
                        </a>
                      </li>
                      <li class="toc-item toc-item-3">
                        <a href="#q35-when-does-parallel-mode-activate-can-i-force-sequential" class="toc-link" data-heading-id="q35-when-does-parallel-mode-activate-can-i-force-sequential">
                          Q35: When does parallel mode activate? Can I force sequential?
                        </a>
                      </li>
                      <li class="toc-item toc-item-3">
                        <a href="#q36-how-many-parallel-builders-is-optimal-is-there-a-limit" class="toc-link" data-heading-id="q36-how-many-parallel-builders-is-optimal-is-there-a-limit">
                          Q36: How many parallel builders is optimal? Is there a limit?
                        </a>
                      </li>
                      <li class="toc-item toc-item-3">
                        <a href="#q37-whats-the-memory-usage-when-running-multiple-parallel-builders" class="toc-link" data-heading-id="q37-whats-the-memory-usage-when-running-multiple-parallel-builders">
                          Q37: What&#x27;s the memory usage when running multiple parallel builders?
                        </a>
                      </li>
                  </ul>
              </li>
              <li class="toc-item toc-item-2">
                <a href="#9-error-handling-self-healing" class="toc-link" data-heading-id="9-error-handling-self-healing">
                  9. Error Handling &amp; Self-Healing
                </a>
                  <ul class="toc-sublist">
                      <li class="toc-item toc-item-3">
                        <a href="#q38-what-happens-if-a-parallel-builder-fails-mid-execution" class="toc-link" data-heading-id="q38-what-happens-if-a-parallel-builder-fails-mid-execution">
                          Q38: What happens if a parallel builder fails mid-execution?
                        </a>
                      </li>
                      <li class="toc-item toc-item-3">
                        <a href="#q39-how-does-the-self-healing-loop-work-walk-me-through-an-iteration" class="toc-link" data-heading-id="q39-how-does-the-self-healing-loop-work-walk-me-through-an-iteration">
                          Q39: How does the self-healing loop work? Walk me through an iteration.
                        </a>
                      </li>
                      <li class="toc-item toc-item-3">
                        <a href="#q40-whats-the-maximum-test-iteration-count-can-i-change-it" class="toc-link" data-heading-id="q40-whats-the-maximum-test-iteration-count-can-i-change-it">
                          Q40: What&#x27;s the maximum test iteration count? Can I change it?
                        </a>
                      </li>
                  </ul>
              </li>
              <li class="toc-item toc-item-2">
                <a href="#10-pattern-learning-system" class="toc-link" data-heading-id="10-pattern-learning-system">
                  10. Pattern Learning System
                </a>
                  <ul class="toc-sublist">
                      <li class="toc-item toc-item-3">
                        <a href="#q41-how-does-the-global-pattern-storage-work-where-is-it-stored" class="toc-link" data-heading-id="q41-how-does-the-global-pattern-storage-work-where-is-it-stored">
                          Q41: How does the global pattern storage work? Where is it stored?
                        </a>
                      </li>
                      <li class="toc-item toc-item-3">
                        <a href="#q42-does-pattern-learning-work-across-different-projects-how" class="toc-link" data-heading-id="q42-does-pattern-learning-work-across-different-projects-how">
                          Q42: Does pattern learning work across different projects? How?
                        </a>
                      </li>
                      <li class="toc-item toc-item-3">
                        <a href="#q43-what-patterns-are-extracted-how-does-extraction-work" class="toc-link" data-heading-id="q43-what-patterns-are-extracted-how-does-extraction-work">
                          Q43: What patterns are extracted? How does extraction work?
                        </a>
                      </li>
                      <li class="toc-item toc-item-3">
                        <a href="#q44-is-pattern-learning-private-or-does-it-upload-data-to-anthropic" class="toc-link" data-heading-id="q44-is-pattern-learning-private-or-does-it-upload-data-to-anthropic">
                          Q44: Is pattern learning private? Or does it upload data to Anthropic?
                        </a>
                      </li>
                  </ul>
              </li>
              <li class="toc-item toc-item-2">
                <a href="#11-advanced-technical-topics" class="toc-link" data-heading-id="11-advanced-technical-topics">
                  11. Advanced Technical Topics
                </a>
                  <ul class="toc-sublist">
                      <li class="toc-item toc-item-3">
                        <a href="#q45-could-parallel-builders-have-race-conditions-when-writing-to-the-filesystem" class="toc-link" data-heading-id="q45-could-parallel-builders-have-race-conditions-when-writing-to-the-filesystem">
                          Q45: Could parallel builders have race conditions when writing to the filesystem?
                        </a>
                      </li>
                      <li class="toc-item toc-item-3">
                        <a href="#q46-why-bash-process-spawning-instead-of-python-multiprocessing-or-threading" class="toc-link" data-heading-id="q46-why-bash-process-spawning-instead-of-python-multiprocessing-or-threading">
                          Q46: Why bash process spawning instead of Python multiprocessing or threading?
                        </a>
                      </li>
                      <li class="toc-item toc-item-3">
                        <a href="#q47-how-does-context-foundry-compare-to-using-agents-manually" class="toc-link" data-heading-id="q47-how-does-context-foundry-compare-to-using-agents-manually">
                          Q47: How does Context Foundry compare to using /agents manually?
                        </a>
                      </li>
                  </ul>
              </li>
              <li class="toc-item toc-item-2">
                <a href="#12-practical-usage-limitations" class="toc-link" data-heading-id="12-practical-usage-limitations">
                  12. Practical Usage &amp; Limitations
                </a>
                  <ul class="toc-sublist">
                      <li class="toc-item toc-item-3">
                        <a href="#q48-when-should-i-not-use-context-foundry" class="toc-link" data-heading-id="q48-when-should-i-not-use-context-foundry">
                          Q48: When should I NOT use Context Foundry?
                        </a>
                      </li>
                      <li class="toc-item toc-item-3">
                        <a href="#q49-what-are-the-cost-implications-how-much-does-a-typical-build-cost" class="toc-link" data-heading-id="q49-what-are-the-cost-implications-how-much-does-a-typical-build-cost">
                          Q49: What are the cost implications? How much does a typical build cost?
                        </a>
                      </li>
                  </ul>
              </li>
              <li class="toc-item toc-item-2">
                <a href="#13-comparisons-philosophy" class="toc-link" data-heading-id="13-comparisons-philosophy">
                  13. Comparisons &amp; Philosophy
                </a>
                  <ul class="toc-sublist">
                      <li class="toc-item toc-item-3">
                        <a href="#q50-how-does-context-foundry-compare-to-cursor-composer" class="toc-link" data-heading-id="q50-how-does-context-foundry-compare-to-cursor-composer">
                          Q50: How does Context Foundry compare to Cursor Composer?
                        </a>
                      </li>
                      <li class="toc-item toc-item-3">
                        <a href="#q51-context-foundry-vs-github-copilot-workspace" class="toc-link" data-heading-id="q51-context-foundry-vs-github-copilot-workspace">
                          Q51: Context Foundry vs GitHub Copilot Workspace?
                        </a>
                      </li>
                      <li class="toc-item toc-item-3">
                        <a href="#q52-what-is-context-foundrys-design-philosophy-how-does-it-differ-from-vibe-coding" class="toc-link" data-heading-id="q52-what-is-context-foundrys-design-philosophy-how-does-it-differ-from-vibe-coding">
                          Q52: What is Context Foundry&#x27;s design philosophy? How does it differ from &quot;vibe coding&quot;?
                        </a>
                      </li>
                  </ul>
              </li>
              <li class="toc-item toc-item-2">
                <a href="#conclusion" class="toc-link" data-heading-id="conclusion">
                  Conclusion
                </a>
              </li>
          </ul>
        </nav>
      </div>
    </aside>

  </div>

  <footer class="docs-footer" role="contentinfo">
    <div class="docs-footer-container">
  
      <!-- Footer Top -->
      <div class="docs-footer-top">
  
        <!-- About Section -->
        <div class="docs-footer-section">
          <h3 class="docs-footer-heading">Context Foundry</h3>
          <p class="docs-footer-description">
            An intelligent documentation and code context management system that empowers AI assistants
            with deep project understanding.
          </p>
        </div>
  
        <!-- Quick Links -->
        <div class="docs-footer-section">
          <h3 class="docs-footer-heading">Documentation</h3>
          <ul class="docs-footer-links">
            <li><a href="/docs/getting-started/" class="docs-footer-link">Getting Started</a></li>
            <li><a href="/docs/guides/" class="docs-footer-link">Guides</a></li>
            <li><a href="/docs/technical/" class="docs-footer-link">Technical Reference</a></li>
            <li><a href="/docs/reference/" class="docs-footer-link">API Reference</a></li>
          </ul>
        </div>
  
        <!-- Community Links -->
        <div class="docs-footer-section">
          <h3 class="docs-footer-heading">Community</h3>
          <ul class="docs-footer-links">
            <li><a href="https://github.com/chuckwired/context-foundry" class="docs-footer-link" target="_blank" rel="noopener noreferrer">GitHub</a></li>
            <li><a href="https://github.com/chuckwired/context-foundry/issues" class="docs-footer-link" target="_blank" rel="noopener noreferrer">Issues</a></li>
            <li><a href="https://github.com/chuckwired/context-foundry/discussions" class="docs-footer-link" target="_blank" rel="noopener noreferrer">Discussions</a></li>
            <li><a href="/docs/guides/contributing" class="docs-footer-link">Contributing</a></li>
          </ul>
        </div>
  
        <!-- Resources Links -->
        <div class="docs-footer-section">
          <h3 class="docs-footer-heading">Resources</h3>
          <ul class="docs-footer-links">
            <li><a href="/docs/reference/changelog" class="docs-footer-link">Changelog</a></li>
            <li><a href="/docs/reference/roadmap" class="docs-footer-link">Roadmap</a></li>
            <li><a href="/docs/technical/security" class="docs-footer-link">Security</a></li>
            <li><a href="/docs/technical/architecture" class="docs-footer-link">Architecture</a></li>
          </ul>
        </div>
  
      </div>
  
      <!-- Footer Bottom -->
      <div class="docs-footer-bottom">
        <div class="docs-footer-copyright">
          <p>&copy;  Context Foundry. Released under the MIT License.</p>
          <p class="docs-footer-built-with">
            Built with <a href="https://github.com/chuckwired/context-foundry" class="docs-footer-link" target="_blank" rel="noopener noreferrer">Context Foundry</a>
          </p>
        </div>
  
        <!-- Social Links -->
        <div class="docs-footer-social">
          <a href="https://github.com/chuckwired/context-foundry" class="docs-footer-social-link" aria-label="GitHub" target="_blank" rel="noopener noreferrer">
            <svg width="20" height="20" viewBox="0 0 20 20" fill="currentColor" xmlns="http://www.w3.org/2000/svg" aria-hidden="true">
              <path fill-rule="evenodd" clip-rule="evenodd" d="M10 0C4.477 0 0 4.477 0 10c0 4.42 2.865 8.17 6.839 9.49.5.092.682-.217.682-.482 0-.237-.008-.866-.013-1.7-2.782.603-3.369-1.34-3.369-1.34-.454-1.156-1.11-1.464-1.11-1.464-.908-.62.069-.608.069-.608 1.003.07 1.531 1.03 1.531 1.03.892 1.529 2.341 1.087 2.91.831.092-.646.35-1.086.636-1.336-2.22-.253-4.555-1.11-4.555-4.943 0-1.091.39-1.984 1.029-2.683-.103-.253-.446-1.27.098-2.647 0 0 .84-.269 2.75 1.025A9.578 9.578 0 0110 4.836c.85.004 1.705.114 2.504.336 1.909-1.294 2.747-1.025 2.747-1.025.546 1.377.203 2.394.1 2.647.64.699 1.028 1.592 1.028 2.683 0 3.842-2.339 4.687-4.566 4.935.359.309.678.919.678 1.852 0 1.336-.012 2.415-.012 2.743 0 .267.18.578.688.48C17.137 18.165 20 14.418 20 10c0-5.523-4.477-10-10-10z"/>
            </svg>
          </a>
        </div>
      </div>
  
    </div>
  </footer>

  <!-- Scripts -->
  <!-- Fuse.js for search -->
  <script src="https://cdn.jsdelivr.net/npm/fuse.js@7.0.0/dist/fuse.min.js"></script>
  <script src="/docs/assets/docs.js" defer></script>

</body>
</html>
