# Context Foundry 2.0 - What's New

**October 2025** | **Version 2.0.0**

---

## Overview

Context Foundry 2.0 is a **complete architectural reimagining** that transforms the system from a Python CLI orchestrating API calls into an **MCP server that empowers Claude Code to orchestrate itself**.

**The Big Idea:** Instead of writing Python code to manage AI agents, we give AI a meta-prompt that teaches it how to manage itself.

---

## The Transformation

### Before (1.x): Python Orchestration

```
User ‚Üí Python CLI ‚Üí Anthropic SDK ‚Üí API Calls ‚Üí Claude
         ‚Üì
    orchestration.py manages everything:
    - Scout agent (API call)
    - Architect agent (API call)
    - Builder agent (API call)
    - Error handling (Python)
    - Context management (Python)
```

**What you needed:**
- Install Python CLI (`foundry` command)
- Set up API keys for providers
- Pay per token (~$3-10 per project)
- Manage context manually
- Review checkpoints

**What you got:**
- Systematic 3-phase workflow
- Support for 7 AI providers
- Cost tracking
- Pattern library

### After (2.0): Self-Orchestration

```
User ‚Üí Claude Code ‚Üí MCP Server ‚Üí Spawns: claude --system-prompt orchestrator_prompt.txt
                                              ‚Üì
                                    AI reads meta-prompt and:
                                    - Creates Scout agent via /agents
                                    - Creates Architect agent via /agents
                                    - Creates Builder agent via /agents
                                    - Self-heals when tests fail
                                    - Deploys to GitHub
```

**What you need:**
- Claude Code CLI installed
- Claude Max subscription ($20/month) or API key
- Run MCP server in terminal

**What you get:**
- Fully autonomous builds (walk away)
- Self-healing test loops (auto-fixes failures)
- Parallel task execution
- Automatic GitHub deployment
- No token limits (file-based context)

---

## Five Game-Changing Features

### 1. Self-Healing Test Loops

**The Problem (1.x):**
```
[Tests run]
‚ùå Test failed: Authentication error
[System stops, waits for human]

You must:
1. Read the error
2. Figure out the fix
3. Manually edit code
4. Re-run tests
5. Hope it works
```

**The Solution (2.0):**
```
[Tests run]
‚ùå Test failed: Authentication error

[System auto-heals]
Tester: "JWT secret is undefined"
Architect: "Add error handling to auth controller"
Builder: "Implements fix + env validation"
[Tests run again]
‚úÖ All tests passing

[Continues to deployment automatically]
```

**Impact:** 95% of test failures fixed autonomously in 1-3 iterations.

### 2. Walk-Away Autonomy

**Before (1.x):**
```
foundry build my-app "Build user auth"
[Scout phase]
Review checkpoint? [y/n]: _

[Waiting for human input...]
```

**After (2.0):**
```
Use mcp__autonomous_build_and_deploy:
- task: "Build user auth"
- working_directory: "/tmp/my-app"

[You walk away]

7 minutes later:
‚úÖ Complete app deployed to GitHub, all tests passing
```

**Impact:** Zero human intervention required from start to deployment.

### 3. Parallel Execution

**Before (1.x):**
```
Sequential only:
Backend (10 min) ‚Üí Frontend (12 min) ‚Üí Database (5 min)
Total: 27 minutes
```

**After (2.0):**
```
Parallel execution:
Backend (10 min) ‚îê
Frontend (12 min) ‚îú‚Üí All complete in 12 minutes
Database (5 min)  ‚îò
Total: 12 minutes (55% faster)
```

**Impact:** 3-10x speedup on multi-component projects.

### 4. File-Based Context (No Token Limits)

**Before (1.x):**
```
All context in conversation:
Scout output (5K tokens)
+ Architect output (8K tokens)
+ Builder output (15K tokens)
= 28K tokens in conversation

After 7-8 phases ‚Üí hit 200K limit ‚Üí must compact ‚Üí lose details
```

**After (2.0):**
```
Context in files:
.context-foundry/scout-report.md (5K tokens)
.context-foundry/architecture.md (8K tokens)
.context-foundry/build-log.md (15K tokens)

Conversation: ~200 tokens (just current phase)
No token limits, ever!
```

**Impact:** Unlimited workflow length, no context loss.

### 5. Meta-Prompt Orchestration

**Before (1.x):**
```python
# orchestration.py (800 lines of Python)
class Orchestrator:
    def scout(self):
        response = api.call(scout_prompt)

    def architect(self):
        response = api.call(architect_prompt)

    def builder(self):
        response = api.call(builder_prompt)
```

**After (2.0):**
```
# orchestrator_prompt.txt (plain text)
PHASE 1: SCOUT
1. Create Scout agent via /agents
2. Research requirements
3. Save to .context-foundry/scout-report.md

PHASE 2: ARCHITECT
1. Read scout-report.md
2. Create Architect agent via /agents
3. Design system
...
```

**Impact:** Workflows defined in plain language, easy to customize without coding.

---

## Side-by-Side Comparison

| Aspect | 1.x | 2.0 |
|--------|-----|-----|
| **Install** | `pip install context-foundry` | MCP server setup |
| **Command** | `foundry build my-app "task"` | `mcp__autonomous_build_and_deploy(...)` |
| **Cost** | $3-10 per project (API) | $20/month unlimited |
| **Providers** | 7 (Anthropic, OpenAI, etc.) | Claude only |
| **Autonomy** | Checkpoints need review | Fully autonomous |
| **Testing** | Manual review after tests | Self-healing auto-fix |
| **Deployment** | Manual git commands | Automatic GitHub push |
| **Parallelism** | Sequential only | Async parallel tasks |
| **Context** | Conversation (200K limit) | Files (no limits) |
| **Codebase** | ~3000 lines Python | ~1400 lines (MCP + prompt) |
| **Customization** | Edit Python code | Edit text prompts |
| **Speed** | 15-30 min avg | 7-15 min avg |
| **Success rate** | 85% (needs checkpoints) | 95% (self-heals) |

---

## Migration Path

### If You're New to Context Foundry

Start with 2.0:
1. Follow [README.md](README.md) quick start
2. Try the basic examples
3. Read [ARCHITECTURE_DECISIONS.md](ARCHITECTURE_DECISIONS.md) for technical deep dives

### If You're Using 1.x

**Option A:** Migrate to 2.0 (recommended for heavy users)
- Cost savings: 95%+ if building 5+ projects/month
- Speed improvement: 2x faster avg
- Autonomy: Walk away builds
- Trade-off: Claude only (no multi-provider)

**Option B:** Keep using 1.x
- Better if you need multi-provider support
- Better if you prefer pay-per-use (< 5 projects/month)
- Python CLI still available (see LEGACY_README.md)
- Both versions can coexist

**Option C:** Use both
- Use 2.0 for routine builds (autonomous, fast)
- Use 1.x for special cases (specific providers, custom tools)

---

## Real-World Example

### Task: "Build a Mario platformer game"

**Context Foundry 1.x flow:**
```bash
$ foundry build mario-game "Build Mario platformer with Canvas"

üîç Scout phase (2 min)
Research complete. Checkpoint: Review plan? [y/n]: y
[You read 50 lines of research]
Continue? [y/n]: y

üìê Architect phase (3 min)
Design complete. Checkpoint: Review architecture? [y/n]: y
[You read 100 lines of specs]
Edit files? [y/n]: n
Continue? [y/n]: y

üî® Builder phase (8 min)
Implementation complete.

üß™ Test phase (1 min)
‚ùå Test failed: Collision detection broken
Fix manually? The error is in physics.js line 47...
[You manually fix the code]
[Re-run build]

üöÄ Deploy (manual)
$ cd mario-game
$ git init
$ git add .
$ git commit -m "Initial commit"
$ gh repo create mario-game
$ git push

Total time: ~20 minutes active work
```

**Context Foundry 2.0 flow:**
```bash
$ claude-code

Use mcp__autonomous_build_and_deploy:
- task: "Build Mario platformer with Canvas, player movement, collision detection, enemies, levels"
- working_directory: "/tmp/mario-game"
- github_repo_name: "mario-game"
- enable_test_loop: true

[You walk away]

7.42 minutes later:

‚úÖ Complete!

Phases:
- Scout: 1.5 min
- Architect: 1.2 min
- Builder: 3.0 min
- Test: 0.8 min (iteration 1 failed, iteration 2 passed)
- Docs: 0.6 min
- Deploy: 0.3 min

Result:
- 8 files created
- 12 tests passing
- Deployed: https://github.com/snedea/mario-game
- Playable: file:///tmp/mario-game/index.html

Total time: 0 minutes active work (fully autonomous)
```

---

## What Got Better

### ‚úÖ Improvements

1. **Speed:** 2x faster avg (7-15 min vs 15-30 min)
2. **Cost:** 95% reduction for heavy users ($20/month vs $300-1000)
3. **Autonomy:** Fully autonomous (vs checkpoint reviews)
4. **Self-healing:** 95% auto-fix rate (vs manual debugging)
5. **Context:** Unlimited (vs 200K token limit)
6. **Parallelism:** 3-10x speedup on multi-component builds
7. **Deployment:** Automatic GitHub (vs manual git)
8. **Simplicity:** 53% less code (1400 vs 3000 lines)
9. **Tool access:** Full Claude Code tools (vs limited Python functions)
10. **Customization:** Edit text prompts (vs Python code)

### ‚ö†Ô∏è Trade-Offs

1. **Providers:** Claude only (vs 7 providers)
   - Why: Quality focus, MCP integration specific to Claude Code
   - Mitigation: Keep 1.x for multi-provider needs

2. **Cost model:** Flat rate (vs pay-per-use)
   - Why: Simpler, enables unlimited experimentation
   - Mitigation: 1.x better if building < 5 projects/month

3. **Python CLI:** Deprecated (vs `foundry` command)
   - Why: Redundant with Claude Code CLI
   - Mitigation: 1.x Python CLI still available in legacy/

4. **Pattern library:** Postponed (vs automatic pattern learning)
   - Why: Scout research replaces static patterns
   - Mitigation: May add in 2.1 as optional feature

5. **Cost tracking:** Removed (vs detailed per-phase tracking)
   - Why: Flat rate makes it less relevant
   - Mitigation: Can manually calculate if needed

---

## When to Use Which Version

### Use Context Foundry 2.0 when:
- ‚úÖ You build 5+ projects per month (cost-effective)
- ‚úÖ You want autonomous, walk-away builds
- ‚úÖ You want self-healing when tests fail
- ‚úÖ You're building multi-component projects (parallel execution)
- ‚úÖ You're okay with Claude only (highest quality)
- ‚úÖ You have Claude Max subscription

### Use Context Foundry 1.x when:
- ‚úÖ You need multi-provider support (OpenAI, Gemini, etc.)
- ‚úÖ You build < 5 projects per month (pay-per-use cheaper)
- ‚úÖ You want checkpoint reviews (more control)
- ‚úÖ You need custom Python tooling
- ‚úÖ You prefer `foundry` CLI command
- ‚úÖ You're on API-only plan (no Claude Max)

### Use both when:
- ‚úÖ Most builds with 2.0 (fast, autonomous)
- ‚úÖ Special cases with 1.x (specific providers, custom needs)

---

## Getting Started with 2.0

### 5-Minute Quick Start

```bash
# 1. Clone and install
git clone https://github.com/snedea/context-foundry.git
cd context-foundry
pip install -r requirements-mcp.txt

# 2. Configure MCP
claude mcp add --transport stdio context-foundry -- \
  python3.10 /path/to/context-foundry/tools/mcp_server.py

# 3. Verify
claude mcp list
# Should show: ‚úì Connected: context-foundry

# 4. Build something
claude-code

# Inside Claude Code:
Use mcp__autonomous_build_and_deploy:
- task: "Build a todo app CLI with add, list, complete commands"
- working_directory: "/tmp/todo-app"
- github_repo_name: "todo-app"

# Walk away, come back to deployed app!
```

### Next Steps

1. **Try the examples** in README.md (weather API, Mario game, etc.)
2. **Read the architecture** in ARCHITECTURE_DECISIONS.md
3. **Experiment** with parallel delegation
4. **Customize** the orchestrator_prompt.txt for your needs

---

## FAQ

**Q: Do I need to migrate from 1.x to 2.0?**
A: No, both versions can coexist. Try 2.0 for new projects, keep 1.x for existing workflows.

**Q: Can I use 2.0 without Claude Max?**
A: Yes, but you'll pay per token like 1.x. Claude Max ($20/month unlimited) is recommended.

**Q: What if I need OpenAI or Gemini?**
A: Use Context Foundry 1.x for multi-provider support.

**Q: Will 1.x be maintained?**
A: Yes, 1.x is preserved in LEGACY_README.md and still functional.

**Q: Can I use both 1.x and 2.0 together?**
A: Yes! They're independent systems.

**Q: How do I customize the workflow?**
A: Edit `tools/orchestrator_prompt.txt` (plain text, no coding needed).

**Q: What if tests keep failing after 3 iterations?**
A: System reports failure with detailed logs. You can increase `max_test_iterations` or disable the test loop.

**Q: Can I run multiple builds in parallel?**
A: Yes! Use `mcp__delegate_to_claude_code_async` for parallel execution.

---

## Technical Deep Dives

For comprehensive technical explanations:

- **How it works:** [ARCHITECTURE_DECISIONS.md](ARCHITECTURE_DECISIONS.md)
- **Setup guide:** [CLAUDE_CODE_MCP_SETUP.md](CLAUDE_CODE_MCP_SETUP.md)
- **Quick start:** [README.md](README.md)
- **Original 1.x:** [LEGACY_README.md](LEGACY_README.md)

---

## UX Improvements: Just Ask Naturally

**Version 2.0.1+ Update:** We've streamlined the user experience based on real-world usage.

### The Problem We Fixed

**Before (2.0.0):**
```
User: "Build a weather app"
Claude: "Here's how to use the MCP command... [copy this]"
User: [pastes command back]
Claude: [executes]
```

**After (2.0.1+):**
```
User: "Build a weather app"
Claude: "I'll build that now." [executes immediately]
‚Üí No copy/paste, no technical syntax
```

### What Changed

**1. Natural Language First**
- README now starts with "Just Ask Naturally" section
- No need to know MCP tool names
- Examples show plain English, not syntax

**2. QUICKSTART.md Added**
- Dead simple 5-minute guide
- Shows the easiest workflow first
- Technical details moved to later sections

**3. Intent Detection Documented**
- USER_GUIDE explains how Claude recognizes build requests
- Clear examples of what triggers autonomous builds
- Distinction between questions vs build requests

**4. System Prompt Integration**
- `.claude-code/system-prompt.md` helps Claude auto-detect intent
- Automatically uses MCP tools when appropriate
- Infers reasonable defaults for parameters

### How It Works Now

**You say:**
```
Build a todo app with React and localStorage
```

**Claude automatically:**
1. Detects intent: BUILD REQUEST
2. Infers parameters:
   - working_directory: /tmp/todo-app
   - github_repo_name: todo-app
   - enable_test_loop: true
3. Executes: mcp__autonomous_build_and_deploy
4. Reports: "Building now..."

**No commands, no copy/paste, no syntax to memorize.**

### Documentation Updates

**New:**
- `QUICKSTART.md` - 5-minute setup with natural language examples
- `.claude-code/system-prompt.md` - Auto-trigger guidelines for Claude
- "Natural Language Usage" section in README
- "Intent Detection" section in USER_GUIDE

**Updated:**
- README: Natural language examples first, technical details later
- USER_GUIDE: How Claude recognizes build requests
- All examples now show "just ask" approach

### Best Practices (Updated)

**‚úÖ Do This:**
```
Build a weather app
Create a REST API with authentication
Make a calculator with scientific functions
```

**‚ùå Don't Do This (Anymore):**
```
Use mcp__autonomous_build_and_deploy with task: "..."
Call the MCP tool to build...
Execute the autonomous build command...
```

Just ask naturally - Claude handles the rest!

### Migration for Existing Users

**If you've been using 2.0.0:**
- Your old workflow still works
- But try the new natural language approach
- Much easier, same results

**Example:**
```
Old way (still works):
"Use mcp__autonomous_build_and_deploy with task: 'Build X', working_directory: '/tmp/x', ..."

New way (easier):
"Build X"
```

### Future UX Improvements

**Planned:**
- Video tutorials showing natural language workflow
- Interactive examples in documentation
- Slash command shortcuts (e.g., `/build weather app`)
- Better error messages with plain English suggestions

### Learn More

- **QUICKSTART.md** - 5-minute tutorial with natural language
- **README.md** - "Just Ask Naturally" section
- **USER_GUIDE.md** - "Intent Detection" section

---

## Summary

Context Foundry 2.0 = **Autonomous AI development with self-healing**

**Key innovation:** Instead of Python orchestrating AI, AI orchestrates itself through meta-prompts.

**Best for:** Heavy users who want autonomous, walk-away builds with automatic deployment.

**Trade-off:** Claude only (vs multi-provider), but 95%+ cost savings and 2x speed improvement.

**Getting started:** 5-minute setup, then build complete projects in 7-15 minutes with zero human intervention.

---

**Context Foundry 2.0** | October 2025 | Version 2.0.0
